{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumkh/ITI110_AgenticRAG/blob/main/LangGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVfMT6l1cobl"
      },
      "source": [
        "## PRE-PRODUCTION - AI Tutor Chatbot (Version 2.17)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmeoL-_lcs8Y"
      },
      "source": [
        "### Setting Up - Install Requirements (Restart Session after installation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MkI4XOWxSXvl"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -qU vllm accelerate bitsandbytes langchain-openai langchain-groq huggingface_hub transformers langchain langchain_huggingface langgraph langchain-core langchain-text-splitters langchain-community chromadb langchain-chroma langsmith docling langchain-docling sentence_transformers gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_2h8tWUc9yA"
      },
      "source": [
        "### Load Packages and Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lzrhAq9cbbU",
        "outputId": "b4609655-cc2a-4688-d6bf-ac6114dc15f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-21 05:00:20--  https://github.com/sumkh/NYP_Dataset/raw/refs/heads/main/Documents.zip\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/sumkh/NYP_Dataset/refs/heads/main/Documents.zip [following]\n",
            "--2025-02-21 05:00:20--  https://raw.githubusercontent.com/sumkh/NYP_Dataset/refs/heads/main/Documents.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18510909 (18M) [application/zip]\n",
            "Saving to: ‘Documents.zip’\n",
            "\n",
            "Documents.zip       100%[===================>]  17.65M  54.5MB/s    in 0.3s    \n",
            "\n",
            "2025-02-21 05:00:21 (54.5 MB/s) - ‘Documents.zip’ saved [18510909/18510909]\n",
            "\n",
            "Archive:  /content/Documents.zip\n",
            "   creating: Documents/\n",
            "   creating: Documents/general/\n",
            "  inflating: Documents/general/Topic 1 Introduction to AI and AI on Azure.pdf  \n",
            "  inflating: Documents/general/deeplearningreview.docx  \n",
            "  inflating: Documents/general/slide_1.pptx  \n",
            "   creating: Documents/mcq/\n",
            "  inflating: Documents/mcq/mcq.csv   \n",
            "  inflating: Documents/mcq/mcq2.csv  \n",
            "   creating: general_db/\n",
            "   creating: general_db/0ab351f4-2d03-423f-bbf2-093d3b8eba80/\n",
            "  inflating: general_db/0ab351f4-2d03-423f-bbf2-093d3b8eba80/data_level0.bin  \n",
            "  inflating: general_db/0ab351f4-2d03-423f-bbf2-093d3b8eba80/header.bin  \n",
            "  inflating: general_db/0ab351f4-2d03-423f-bbf2-093d3b8eba80/length.bin  \n",
            " extracting: general_db/0ab351f4-2d03-423f-bbf2-093d3b8eba80/link_lists.bin  \n",
            "  inflating: general_db/chroma.sqlite3  \n",
            "   creating: mcq_db/\n",
            "  inflating: mcq_db/chroma.sqlite3   \n",
            "   creating: mcq_db/d897d22c-91fc-4db5-8a6b-aacbd9c5f57d/\n",
            "  inflating: mcq_db/d897d22c-91fc-4db5-8a6b-aacbd9c5f57d/data_level0.bin  \n",
            "  inflating: mcq_db/d897d22c-91fc-4db5-8a6b-aacbd9c5f57d/header.bin  \n",
            "  inflating: mcq_db/d897d22c-91fc-4db5-8a6b-aacbd9c5f57d/length.bin  \n",
            " extracting: mcq_db/d897d22c-91fc-4db5-8a6b-aacbd9c5f57d/link_lists.bin  \n",
            "  inflating: requirements.txt        \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "LANGSMITH_API_KEY=userdata.get(\"LANGSMITH_API_KEY\")\n",
        "HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" # Disable tokenizers parallelism, as it causes issues with multiprocessing\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\" # LangSmith for Observability\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"AgenticRAG\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = LANGSMITH_API_KEY # Optional\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token=HF_TOKEN) # May be optional for getting model download from Huggingface\n",
        "\n",
        "# Download required files from Github repo\n",
        "!wget https://github.com/sumkh/NYP_Dataset/raw/refs/heads/main/Documents.zip\n",
        "!unzip -o /content/Documents.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Znk0gm1ce67",
        "outputId": "5540ae30-2805-4a09-fcee-60dc73171be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "import json\n",
        "import hashlib\n",
        "import uuid\n",
        "import logging\n",
        "from typing import List, Optional, Union, Literal, Dict\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "# LangChain & related imports\n",
        "from langchain_core.tools import tool, StructuredTool\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever\n",
        "\n",
        "# Extraction for Documents\n",
        "from langchain_docling.loader import ExportType\n",
        "from langchain_docling import DoclingLoader\n",
        "from docling.chunking import HybridChunker\n",
        "\n",
        "# Extraction for HTML\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Configurations and Get the API key from the environment variable\n",
        "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2SDpdN9Yck4w",
        "outputId": "d7f5469a-4c5b-46b1-d07f-8f03b62c933c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "6afe1e6ac2e643f59eddd484f10368e4",
            "d1549f73024f41a3aff059cdc23facdd",
            "47f9e15ca49c44ca88535f75f10a4b50",
            "d0142f770cd848ee9c9e3f4d17495ed5",
            "0c0dd17f179540dfb7a9a7c9b852eaf3",
            "de4e44deaa2840a6a5951f2211d68b21",
            "2a85723232e841d08e2fe1e31dbac1a7",
            "b8739b7a267a48ab8c0a51b2630cc457",
            "ee82235ac82c47ffa88fa6a1fade8e52",
            "7a16055e6e604c49b8f9e4f8722597ff",
            "e7b490a3fdca466fa8c5f4b1a82eaec0",
            "f04899fa87b948b3b0158c7856800736",
            "829deb1aa5fc4e62b1ba01530b4c9243",
            "88852e7e97f744109748324b1fc2b8e0",
            "a192016aebd943b8b1b44973248b50d5",
            "ddfc394e88ee4f87a5df986ccbc6b344",
            "f83da10809fa48c79d40da1555ecf696",
            "b0f234845f514e3ab7dcaf5dea36134b",
            "2694f77db7dd402a8382f5ebd2ed3010",
            "071a9e5fe8284a4b857e6f489da1037d",
            "c5b6b41ea8b54409ac5886c0ce698683",
            "4ad1c346a498430ea46f49cbe06b0e47",
            "e1bc37bd46c44a23877daf1f0e5981a9",
            "63d7a619b96c4af59f8706bc499afc1a",
            "bf5a761df0ed4e40aa0610a7b9148485",
            "ac789c364c44400d823d77daa0265ec6",
            "3be7499afecc42498af58e9fa5b040c3",
            "53e87132a5ea4ee3948dde0ff000c8c0",
            "35c367606a5c400f93105a4cfa28c63f",
            "ddab6fb65ae948a0b8e2a88db7532342",
            "9ce70e7b7a164163a5c1b53495ed8408",
            "a8d1ed04fb964b3bb29633c7860a8ddd",
            "41a1cc22eb504954adaa6bc365ababdf",
            "5c2c37f9c9c147c5bc17b9b08c408ca6",
            "611265e20d7f48faba589a69bb8c77d2",
            "028fbc9a98c44f8a97a04ec4db28b2ff",
            "38942f9de2524362adaaf70d3f2b391e",
            "9449caaa34a44ae59f8e3b03bd5599bf",
            "d2f69ab506fd4935abffa618c408e823",
            "8b75801f080a4260a0e9158feb124d3d",
            "9d7189377f17442b96671c9a06a275ea",
            "d5854c2dd1714cf6bb9c877c95ea0ce6",
            "215d670cf53f40b8b6b1812fdd091307",
            "f5480b0158404681a84ca60480e6d390",
            "93bf6000677f4ffea642ab7cddb6763e",
            "8aa9bc3b7916477f94c5ef7834960416",
            "5c4b0210e46040b88c7cfbbdec0c3a19",
            "2d8562546ae74aa9bafc4b915051ef0d",
            "9cd2b020af4648f8a740812bd51a57c4",
            "347c084ab38e407c8437de8f5907bceb",
            "a2a4ba7e868a4d489017c8c22a51cf75",
            "8089128cb7f44ae3ba6bccd97ad3e068",
            "48ec3ef7665e472395cebc00db2102f5",
            "3d2ec4f5e6ad4c75894baa88b4dd0b3d",
            "cc38a5a56e3f4d65a57eb06657422268",
            "75a7847ee65a42369a4703ef45563941",
            "a162b8b521e14d42a473aff19719115f",
            "ad44880e770b4f3ba1144446159679de",
            "c51a4ae703f1462ebab2a4f85ed12690",
            "6529c8033b754d8484bbc59f821554ad",
            "ef8922d6666c48889b956d9f351dbd7b",
            "076bcd68ab4d46cc8c1f8cb36131b3ba",
            "f17b731396994e99976848416c61b34c",
            "1abcaa4f6bc2477d9732952c9eadc0c0",
            "2c069d611d594decb74a8875c6541da2",
            "78f856c1184b4f4485673b83519cc811",
            "f3ad73577f6345e2b182a98617796163",
            "e9f6b956ca8a46d39ffb16e3c1b887df",
            "4e10d825c2744d41aca6deb318157d6a",
            "48a22237d53244248af5418ca567767a",
            "60ecd9753ec14f1687dd58268dda7980",
            "3736e92b01084352914504b27e5847f8",
            "3a19c4a112154e90b889f4e585cb6a0d",
            "321b903024e74f329719013e10926601",
            "6b3d9bc841e74444aef8f3b13a469269",
            "7855bf0314524a9e974d3e495cef1dd0",
            "94ab280109184ddca428a59a63ef6300",
            "eb0c6272e20d47d4b4558923738fe335",
            "a65ddad54fcf44f0a3dde215b8e4bc5f",
            "c4ef0a7ce7a04b09b28298cf1541ae4f",
            "fff05f34c21a488f8c53904fe6571a6a",
            "0bc88cb8510749c49be69eacd4ba709b",
            "d1313875850a4f40915c7a7c8e15c492",
            "f6e83b0fd1104ca89544f54bae663a4e",
            "c8a5e24932554f2a9fe26eb8cbaa3f51",
            "64b6d248f26040ccb4a27dd76a7e9755",
            "a4a8f095092c44d593051c44f141436e",
            "484cec3204e54b049b2006dbb9b3f4bd",
            "8f2b58239a4e484ab32b1129a860ca2a",
            "844a6c3b6f8d4e5b9589b01d5bec4b6f",
            "304c61f86d204d428fe54244076d5dcb",
            "90da32e41b78436dadff45e332968111",
            "204c1321920d4abeb9525a9369f209ad",
            "ea8b68ada4dc448da92077892e77ff4a",
            "a3f55b2fdac5483cbe3ef13deeebbe6b",
            "d0c40a99f31b43339e9a008d6c09b3d8",
            "8f2051fe56d8444e8bb3fbdfc4fbf44a",
            "e720cd14e1844a4da24d9d0b06383f2d",
            "dc265d845ab84bfcab7df0b20f592827",
            "4f4a2a8c9ffa4695beb261ca5cbb1516",
            "d6a9ed06aac441009ba7b9e1ecd58a50",
            "0569f34c935243c88985f213fe9957f0",
            "c6627d0e9b2840d4bf5248fefe0e346a",
            "311a4278152c4abfab3baa5eacab30f1",
            "c931eb29ff674932905793056fac3b7e",
            "059510aa283a4a8490c2994037b3756c",
            "d10fb30ef462485fb45a0c8bae52cae9",
            "501d22f40f3e481ea80946d5ba8863eb",
            "fe3dca3e670f4f9992485f189d517838",
            "35bd01b0f0564b598c2f3c9dca75d012",
            "7439d8cc949144f191f5b5c488080ee0",
            "08401b8dc90a4ff7879a78694f128843",
            "3536f62921934f2aa4477c92e275d89e",
            "42ced05be3ae4c769c35f4edd25597d1",
            "633579902f644b9eb3039e0426a6c6ef",
            "67ad733a039b4a478e0997e81554dc53",
            "79d4279601ec48e9853453a5c0028783",
            "b03095f53e8d4c80a82092c2aa16122a",
            "4a4c84bb97734a06beb1bd6ed63cf8e1",
            "979fe0dfc77a4149b997d0f1d78f57de",
            "a29933c104a244779dc49979efbe6a4b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6afe1e6ac2e643f59eddd484f10368e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f04899fa87b948b3b0158c7856800736"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1bc37bd46c44a23877daf1f0e5981a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c2c37f9c9c147c5bc17b9b08c408ca6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93bf6000677f4ffea642ab7cddb6763e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75a7847ee65a42369a4703ef45563941"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3ad73577f6345e2b182a98617796163"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb0c6272e20d47d4b4558923738fe335"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f2b58239a4e484ab32b1129a860ca2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f4a2a8c9ffa4695beb261ca5cbb1516"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7439d8cc949144f191f5b5c488080ee0"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# =============================================================================\n",
        "#                         Document Extraction Functions\n",
        "# =============================================================================\n",
        "\n",
        "def extract_documents(doc_path: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Recursively collects all file paths from folder 'doc_path'.\n",
        "    Used by ExtractDocument.load_files() to find documents to parse.\n",
        "    \"\"\"\n",
        "    extracted_docs = []\n",
        "\n",
        "    for root, _, files in os.walk(doc_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            extracted_docs.append(file_path)\n",
        "    return extracted_docs\n",
        "\n",
        "\n",
        "def _generate_uuid(page_content: str) -> str:\n",
        "    \"\"\"Generate a UUID for a chunk of text using MD5 hashing.\"\"\"\n",
        "    md5_hash = hashlib.md5(page_content.encode()).hexdigest()\n",
        "    return str(uuid.UUID(md5_hash[0:32]))\n",
        "\n",
        "\n",
        "def load_file(file_path: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Load a file from the given path and return a list of Document objects.\n",
        "    \"\"\"\n",
        "    _documents = []\n",
        "\n",
        "    # Load the file and extract the text chunks\n",
        "    try:\n",
        "        loader = DoclingLoader(\n",
        "            file_path = file_path,\n",
        "            export_type = ExportType.DOC_CHUNKS,\n",
        "            chunker = HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
        "        )\n",
        "        docs = loader.load()\n",
        "        logger.info(f\"Total parsed doc-chunks: {len(docs)} from Source: {file_path}\")\n",
        "\n",
        "        for d in docs:\n",
        "            # Tag each document's chunk with the source file and a unique ID\n",
        "            doc = Document(\n",
        "                page_content=d.page_content,\n",
        "                metadata={\n",
        "                    \"source\": file_path,\n",
        "                    \"doc_id\": _generate_uuid(d.page_content),\n",
        "                    \"source_type\": \"file\",\n",
        "                }\n",
        "            )\n",
        "            _documents.append(doc)\n",
        "        logger.info(f\"Total generated LangChain document chunks: {len(_documents)}\\n.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading file: {file_path}. Exception: {e}\\n.\")\n",
        "\n",
        "    return _documents\n",
        "\n",
        "\n",
        "# Define function to load documents from a folder\n",
        "def load_files_from_folder(doc_path: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Load documents from the given folder path and return a list of Document objects.\n",
        "    \"\"\"\n",
        "    _documents = []\n",
        "    # Extract all files path from the given folder\n",
        "    extracted_docs = extract_documents(doc_path)\n",
        "\n",
        "    # Iterate through each document and extract the text chunks\n",
        "    for file_path in extracted_docs:\n",
        "        _documents.extend(load_file(file_path))\n",
        "\n",
        "    return _documents\n",
        "\n",
        "# =============================================================================\n",
        "# Load structured data in csv file to LangChain Document format\n",
        "def load_mcq_csvfiles(file_path: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Load structured data in mcq csv file from the given file path and return a list of Document object.\n",
        "    Expected format: each row of csv is comma separated into \"mcq_number\", \"mcq_type\", \"text_content\"\n",
        "    \"\"\"\n",
        "    _documents = []\n",
        "\n",
        "    # iterate through each csv file and load each row into _dict_per_question format\n",
        "    # Ensure we process only CSV files\n",
        "    if not file_path.endswith(\".csv\"):\n",
        "        return _documents  # Skip non-CSV files\n",
        "    try:\n",
        "        # Open and read the CSV file\n",
        "        with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "            reader = csv.DictReader(file)\n",
        "            for row in reader:\n",
        "                # Ensure required columns exist in the row\n",
        "                if not all(k in row for k in [\"mcq_number\", \"mcq_type\", \"text_content\"]): # Ensure required columns exist and exclude header\n",
        "                    logger.error(f\"Skipping row due to missing fields: {row}\")\n",
        "                    continue\n",
        "                # Tag each row of csv is comma separated into \"mcq_number\", \"mcq_type\", \"text_content\"\n",
        "                doc = Document(\n",
        "                    page_content = row[\"text_content\"], # text_content segment is separated by \"|\"\n",
        "                    metadata={\n",
        "                        \"source\": f\"{file_path}_{row['mcq_number']}\",  # file_path + mcq_number\n",
        "                        \"doc_id\": _generate_uuid(f\"{file_path}_{row['mcq_number']}\"),  # Unique ID\n",
        "                        \"source_type\": row[\"mcq_type\"],  # MCQ type\n",
        "                    }\n",
        "                )\n",
        "                _documents.append(doc)\n",
        "            logger.info(f\"Successfully loaded {len(_documents)} LangChain document chunks from {file_path}.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading file: {file_path}. Exception: {e}\\n.\")\n",
        "\n",
        "    return _documents\n",
        "\n",
        "# Define function to load documents from a folder for structured data in csv file\n",
        "def load_files_from_folder_mcq(doc_path: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Load mcq csv file from the given folder path and return a list of Document objects.\n",
        "    \"\"\"\n",
        "    _documents = []\n",
        "    # Extract all files path from the given folder\n",
        "    extracted_docs = [\n",
        "        os.path.join(doc_path, file) for file in os.listdir(doc_path)\n",
        "        if file.endswith(\".csv\")  # Process only CSV files\n",
        "    ]\n",
        "\n",
        "    # Iterate through each document and extract the text chunks\n",
        "    for file_path in extracted_docs:\n",
        "        _documents.extend(load_mcq_csvfiles(file_path))\n",
        "\n",
        "    return _documents\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "#                         Website Extraction Functions\n",
        "# =============================================================================\n",
        "def _generate_uuid(page_content: str) -> str:\n",
        "    \"\"\"Generate a UUID for a chunk of text using MD5 hashing.\"\"\"\n",
        "    md5_hash = hashlib.md5(page_content.encode()).hexdigest()\n",
        "    return str(uuid.UUID(md5_hash[0:32]))\n",
        "\n",
        "def ensure_scheme(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    if not parsed_url.scheme:\n",
        "        return 'http://' + url  # Default to http, or use 'https://' if preferred\n",
        "    return url\n",
        "\n",
        "def extract_html(url: List[str]) -> List[Document]:\n",
        "    if isinstance(url, str):\n",
        "        url = [url]\n",
        "    \"\"\"\n",
        "    Extracts text from the HTML content of web pages listed in 'web_path'.\n",
        "    Returns a list of LangChain 'Document' objects.\n",
        "    \"\"\"\n",
        "    # Ensure all URLs have a scheme\n",
        "    web_paths = [ensure_scheme(u) for u in url]\n",
        "\n",
        "    loader = WebBaseLoader(web_paths)\n",
        "    loader.requests_per_second = 1\n",
        "    docs = loader.load()\n",
        "\n",
        "    # Iterate through each document, clean the content, removing excessive line return and store it in a LangChain Document\n",
        "    _documents = []\n",
        "    for doc in docs:\n",
        "        # Clean the concent\n",
        "        doc.page_content = doc.page_content.strip()\n",
        "        doc.page_content = doc.page_content.replace(\"\\n\", \" \")\n",
        "        doc.page_content = doc.page_content.replace(\"\\r\", \" \")\n",
        "        doc.page_content = doc.page_content.replace(\"\\t\", \" \")\n",
        "        doc.page_content = doc.page_content.replace(\"  \", \" \")\n",
        "        doc.page_content = doc.page_content.replace(\"   \", \" \")\n",
        "\n",
        "        # Store it in a LangChain Document\n",
        "        web_doc = Document(\n",
        "            page_content=doc.page_content,\n",
        "            metadata={\n",
        "                \"source\": doc.metadata.get(\"source\"),\n",
        "                \"doc_id\": _generate_uuid(doc.page_content),\n",
        "                \"source_type\": \"web\"\n",
        "            }\n",
        "        )\n",
        "        _documents.append(web_doc)\n",
        "    return _documents\n",
        "\n",
        "# =============================================================================\n",
        "#                         Vector Store Initialisation\n",
        "# =============================================================================\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=EMBED_MODEL_ID)\n",
        "\n",
        "# Initialise vector stores\n",
        "general_vs = Chroma(\n",
        "    collection_name=\"general_vstore\",\n",
        "    embedding_function=embedding_model,\n",
        "    persist_directory=\"./general_db\"\n",
        ")\n",
        "\n",
        "mcq_vs = Chroma(\n",
        "    collection_name=\"mcq_vstore\",\n",
        "    embedding_function=embedding_model,\n",
        "    persist_directory=\"./mcq_db\"\n",
        ")\n",
        "\n",
        "in_memory_vs = Chroma(\n",
        "    collection_name=\"in_memory_vstore\",\n",
        "    embedding_function=embedding_model\n",
        ")\n",
        "\n",
        "# Split the documents into smaller chunks for better embedding coverage\n",
        "def split_text_into_chunks(docs: List[Document]) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Splits a list of Documents into smaller text chunks using\n",
        "    RecursiveCharacterTextSplitter while preserving metadata.\n",
        "    Returns a list of Document objects.\n",
        "    \"\"\"\n",
        "    if not docs:\n",
        "        return []\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000, # Split into chunks of 1000 characters\n",
        "        chunk_overlap=200, # Overlap by 200 characters\n",
        "        add_start_index=True\n",
        "    )\n",
        "    chunked_docs = splitter.split_documents(docs)\n",
        "    return chunked_docs # List of Document objects\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "#                         Retrieval Tools\n",
        "# =============================================================================\n",
        "\n",
        "# Define a simple similarity search retrieval tool on msq_vs\n",
        "class MCQRetrievalTool(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"Search topic.\")\n",
        "    k: int = Field(2, title=\"Number of Results\", description=\"The number of results to retrieve.\")\n",
        "\n",
        "def mcq_retriever(input: str, k: int = 2) -> List[str]:\n",
        "    # Retrieve the top k most similar mcq question documents from the vector store\n",
        "    docs_func = mcq_vs.as_retriever(\n",
        "        search_type=\"similarity\",\n",
        "        search_kwargs={\n",
        "        'k': k,\n",
        "        'filter':{\"source_type\": \"mcq_question\"}\n",
        "    },\n",
        "    )\n",
        "    docs_qns = docs_func.invoke(input, k=k)\n",
        "\n",
        "    # Extract the document IDs from the retrieved documents\n",
        "    doc_ids = [d.metadata.get(\"doc_id\") for d in docs_qns if \"doc_id\" in d.metadata]\n",
        "\n",
        "    # Retrieve full documents based on the doc_ids\n",
        "    docs = mcq_vs.get(where = {'doc_id': {\"$in\":doc_ids}})\n",
        "\n",
        "    qns_list = {}\n",
        "    for i, d in enumerate(docs['metadatas']):\n",
        "        qns_list[d['source'] + \" \" + d['source_type']] = docs['documents'][i]\n",
        "\n",
        "    return qns_list\n",
        "\n",
        "# Create a StructuredTool from the function\n",
        "mcq_retriever_tool = StructuredTool.from_function(\n",
        "    func = mcq_retriever,\n",
        "    name = \"MCQ Retrieval Tool\",\n",
        "    description = (\n",
        "    \"\"\"\n",
        "    Use this tool to retrieve MCQ questions set when Human asks to generate a quiz related to a topic.\n",
        "    DO NOT GIVE THE ANSWERS to Human before Human has answered all the questions.\n",
        "\n",
        "    If Human give answers for questions you do not know, SAY you do not have the questions for the answer\n",
        "    and ASK if the Human want you to generate a new quiz and then SAVE THE QUIZ with Summary Tool before ending the conversation.\n",
        "\n",
        "\n",
        "    Input must be a JSON string with the schema:\n",
        "        - input (str): The search topic to retrieve MCQ questions set related to the topic.\n",
        "        - k (int): Number of question set to retrieve.\n",
        "        Example usage: input='What is AI?', k=5\n",
        "\n",
        "    Returns:\n",
        "    - A dict of MCQ questions:\n",
        "    Key: 'metadata of question' e.g. './Documents/mcq/mcq.csv_Qn31 mcq_question' with suffix ['question', 'answer', 'answer_reason', 'options', 'wrong_options_reason']\n",
        "    Value: Text Content\n",
        "\n",
        "    \"\"\"\n",
        "    ),\n",
        "    args_schema = MCQRetrievalTool,\n",
        "    response_format=\"content\",\n",
        "    return_direct = False, # Return the response as a list of strings\n",
        "    verbose = False  # To log tool's progress\n",
        "    )\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Retrieve more documents with higher diversity using MMR (Maximal Marginal Relevance) from the general vector store\n",
        "# Useful if the dataset has many similar documents\n",
        "class GenRetrievalTool(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"User query.\")\n",
        "    k: int = Field(2, title=\"Number of Results\", description=\"The number of results to retrieve.\")\n",
        "\n",
        "def gen_retriever(input: str, k: int = 2) -> List[str]:\n",
        "    # Use retriever of vector store to retrieve documents\n",
        "    docs_func = general_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs = {'k': k, 'lambda_mult': 0.25}\n",
        "    )\n",
        "    docs = docs_func.invoke(input, k=k)\n",
        "    return [d.page_content for d in docs]\n",
        "\n",
        "# Create a StructuredTool from the function\n",
        "general_retriever_tool = StructuredTool.from_function(\n",
        "    func = gen_retriever,\n",
        "    name = \"Assistant References Retrieval Tool\",\n",
        "    description = (\n",
        "    \"\"\"\n",
        "    Use this tool to retrieve reference information from Assistant reference database for Human queries related to a topic or\n",
        "    and when Human asked to generate guides to learn or study about a topic.\n",
        "\n",
        "    Input must be a JSON string with the schema:\n",
        "        - input (str): The user query.\n",
        "        - k (int): Number of results to retrieve.\n",
        "        Example usage: input='What is AI?', k=5\n",
        "    Returns:\n",
        "    - A list of retrieved document's content string.\n",
        "    \"\"\"\n",
        "    ),\n",
        "    args_schema = GenRetrievalTool,\n",
        "    response_format=\"content\",\n",
        "    return_direct = False, # Return the content of the documents\n",
        "    verbose = False  # To log tool's progress\n",
        "    )\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Retrieve more documents with higher diversity using MMR (Maximal Marginal Relevance) from the in-memory vector store\n",
        "# Query in-memory vector store only\n",
        "class InMemoryRetrievalTool(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"User query.\")\n",
        "    k: int = Field(2, title=\"Number of Results\", description=\"The number of results to retrieve.\")\n",
        "\n",
        "def in_memory_retriever(input: str, k: int = 2) -> List[str]:\n",
        "    # Use retriever of vector store to retrieve documents\n",
        "    docs_func = in_memory_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs = {'k': k, 'lambda_mult': 0.25}\n",
        "    )\n",
        "    docs = docs_func.invoke(input, k=k)\n",
        "    return [d.page_content for d in docs]\n",
        "\n",
        "# Create a StructuredTool from the function\n",
        "in_memory_retriever_tool = StructuredTool.from_function(\n",
        "    func = in_memory_retriever,\n",
        "    name = \"In-Memory Retrieval Tool\",\n",
        "    description = (\n",
        "    \"\"\"\n",
        "    Use this tool when Human ask Assistant to retrieve information from documents that Human has uploaded.\n",
        "\n",
        "    Input must be a JSON string with the schema:\n",
        "        - input (str): The user query.\n",
        "        - k (int): Number of results to retrieve.\n",
        "    \"\"\"\n",
        "    ),\n",
        "    args_schema = InMemoryRetrievalTool,\n",
        "    response_format=\"content\",\n",
        "    return_direct = False, # Whether to return the tool’s output directly\n",
        "    verbose = False  # To log tool's progress\n",
        "    )\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Web Extraction Tool\n",
        "class WebExtractionRequest(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"Search text.\")\n",
        "    url: str = Field(\n",
        "        ...,\n",
        "        title=\"url\",\n",
        "        description=\"Web URL(s) to extract content from. If multiple URLs, separate them with a comma.\"\n",
        "    )\n",
        "    k: int = Field(5, title=\"Number of Results\", description=\"The number of results to retrieve.\")\n",
        "\n",
        "# Extract content from a web URL, load into in_memory_vstore\n",
        "def extract_web_path_tool(input: str, url: str, k: int = 5) -> List[str]:\n",
        "    if isinstance(url, str):\n",
        "        url = [url]\n",
        "    \"\"\"\n",
        "    Extract content from the web URLs based on user's input.\n",
        "    Args:\n",
        "    - input: The input text to search for.\n",
        "    - url: URLs to extract content from.\n",
        "    - k: Number of results to retrieve.\n",
        "    Returns:\n",
        "     - A list of retrieved document's content string.\n",
        "    \"\"\"\n",
        "    # Extract content from the web\n",
        "    html_docs = extract_html(url)\n",
        "    if not html_docs:\n",
        "        return f\"No content extracted from {url}.\"\n",
        "\n",
        "    # Split the documents into smaller chunks for better embedding coverage\n",
        "    chunked_texts = split_text_into_chunks(html_docs)\n",
        "    in_memory_vs.add_documents(chunked_texts) # Add the chunked texts to the in-memory vector store\n",
        "\n",
        "    # Extract content from the in-memory vector store\n",
        "    # Use retriever of vector store to retrieve documents\n",
        "    docs_func = in_memory_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={\n",
        "        'k': k,\n",
        "        'lambda_mult': 0.25,\n",
        "        'filter':{\"source\": {\"$in\": url}}\n",
        "    },\n",
        "    )\n",
        "    docs = docs_func.invoke(input, k=k)\n",
        "    return [d.page_content for d in docs]\n",
        "\n",
        "# Create a StructuredTool from the function\n",
        "web_extraction_tool = StructuredTool.from_function(\n",
        "    func = extract_web_path_tool,\n",
        "    name = \"Web Extraction Tool\",\n",
        "    description = (\n",
        "        \"Assistant should use this tool to extract content from web URLs based on user's input, \"\n",
        "        \"Web extraction is initially load into database and then return k: Number of results to retrieve\"\n",
        "    ),\n",
        "    args_schema = WebExtractionRequest,\n",
        "    return_direct = False, # Whether to return the tool’s output directly\n",
        "    verbose = False  # To log tool's progress\n",
        "    )\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Ensemble Retrieval from General and In-Memory Vector Stores\n",
        "class EnsembleRetrievalTool(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"User query.\")\n",
        "    k: int = Field(5, title=\"Number of Results\", description=\"Number of results.\")\n",
        "\n",
        "def ensemble_retriever(input: str, k: int = 5) -> List[str]:\n",
        "    # Use retriever of vector store to retrieve documents\n",
        "    general_retrieval = general_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs = {'k': k, 'lambda_mult': 0.25}\n",
        "    )\n",
        "    in_memory_retrieval = in_memory_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs = {'k': k, 'lambda_mult': 0.25}\n",
        "    )\n",
        "\n",
        "    ensemble_retriever = EnsembleRetriever(\n",
        "        retrievers=[general_retrieval, in_memory_retrieval],\n",
        "        weights=[0.5, 0.5]\n",
        "    )\n",
        "    docs = ensemble_retriever.invoke(input)\n",
        "    return [d.page_content for d in docs]\n",
        "\n",
        "# Create a StructuredTool from the function\n",
        "ensemble_retriever_tool = StructuredTool.from_function(\n",
        "    func = ensemble_retriever,\n",
        "    name = \"Ensemble Retriever Tool\",\n",
        "    description = (\n",
        "    \"\"\"\n",
        "    Use this tool to retrieve information from reference database and\n",
        "    extraction of documents that Human has uploaded.\n",
        "\n",
        "    Input must be a JSON string with the schema:\n",
        "        - input (str): The user query.\n",
        "        - k (int): Number of results to retrieve.\n",
        "    \"\"\"\n",
        "    ),\n",
        "    args_schema = EnsembleRetrievalTool,\n",
        "    response_format=\"content\",\n",
        "    return_direct = False\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuhaRfR6dLno"
      },
      "source": [
        "### Load vLLM Model and Serving Online using OpenAI Wrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upf7Jhj5KkIZ"
      },
      "source": [
        "#### Run vLLM SubProcess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "226HJOl4KmWc",
        "outputId": "c2ca8009-23a9-4e8f-ffaa-5b21e37b35b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nohup: redirecting stderr to stdout\n"
          ]
        }
      ],
      "source": [
        "# https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_1/#-tool-calling-(8b/70b/405b)-\n",
        "# https://medium.com/@hakimnaufal/trying-out-vllm-deepseek-r1-in-google-colab-a-quick-guide-a4fe682b8665\n",
        "# https://github.com/naufalhakim23/deepseek-r1-playground/blob/main/deepseek_r1_distill_qwen_fast_api.ipynb\n",
        "# https://colab.research.google.com/github/deepset-ai/haystack-cookbook/blob/main/notebooks/vllm_inference_engine.ipynb\n",
        "# https://docs.vllm.ai/_/downloads/en/v0.4.2/pdf/\n",
        "# https://docs.vllm.ai/en/latest/serving/openai_compatible_server.html\n",
        "# https://docs.vllm.ai/en/latest/serving/env_vars.html\n",
        "# https://docs.vllm.ai/en/latest/deployment/docker.html\n",
        "# https://docs.vllm.ai/en/latest/features/quantization/bnb.html\n",
        "\n",
        "# https://huggingface.co/casperhansen/llama-3-8b-instruct-awq/tree/main\n",
        "# https://huggingface.co/unsloth/llama-3-8b-Instruct-bnb-4bit\n",
        "\n",
        "!wget -q -P examples/ https://github.com/vllm-project/vllm/raw/refs/heads/main/examples/tool_chat_template_llama3.1_json.jinja\n",
        "\n",
        "# we prepend \"nohup\" and postpend \"&\" to make the Colab cell run in background\n",
        "! nohup python -m vllm.entrypoints.openai.api_server \\\n",
        "                  --model unsloth/llama-3-8b-Instruct-bnb-4bit \\\n",
        "                  --enable-auto-tool-choice \\\n",
        "                  --tool-call-parser llama3_json \\\n",
        "                  --chat-template examples/tool_chat_template_llama3.1_json.jinja \\\n",
        "                  --quantization bitsandbytes \\\n",
        "                  --load-format bitsandbytes \\\n",
        "                  --dtype half \\\n",
        "                  --max-model-len 8192 \\\n",
        "                  --download-dir models/vllm \\\n",
        "                  > vllm.log &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Eis09vLIyZ",
        "outputId": "2f4019a7-6237-405d-a493-cb961762c516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-19 17:24:35 api_server.py:206] Started engine process with PID 3503\n",
            "WARNING 02-19 17:24:37 config.py:2386] Casting torch.bfloat16 to torch.float16.\n",
            "E0000 00:00:1739985883.719463    3503 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "WARNING 02-19 17:24:50 config.py:2386] Casting torch.bfloat16 to torch.float16.\n",
            "WARNING 02-19 17:24:50 config.py:2386] Casting torch.bfloat16 to torch.float16.\n",
            "WARNING 02-19 17:24:59 config.py:621] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n",
            "INFO 02-19 17:25:05 config.py:542] This model supports multiple tasks: {'reward', 'score', 'classify', 'embed', 'generate'}. Defaulting to 'generate'.\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "INFO 02-19 17:25:09 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "INFO 02-19 17:28:13 model_runner.py:1115] Loading model weights took 5.3131 GB\n",
            "INFO 02-19 17:28:13 model_runner.py:1115] Loading model weights took 5.3131 GB\n",
            "INFO 02-19 17:28:13 model_runner.py:1115] Loading model weights took 5.3131 GB\n",
            "INFO 02-19 17:28:13 model_runner.py:1115] Loading model weights took 5.3131 GB\n",
            "INFO 02-19 17:28:13 model_runner.py:1115] Loading model weights took 5.3131 GB\n",
            "INFO 02-19 17:28:13 model_runner.py:1115] Loading model weights took 5.3131 GB\n",
            "INFO 02-19 17:28:13 model_runner.py:1115] Loading model weights took 5.3131 GB\n",
            "INFO 02-19 17:28:13 model_runner.py:1115] Loading model weights took 5.3131 GB\n",
            "INFO 02-19 17:28:56 worker.py:267] model weights take 5.31GiB; non_torch_memory takes 0.05GiB; PyTorch activation peak memory takes 1.23GiB; the rest of the memory reserved for KV Cache is 6.67GiB.\n",
            "Capturing CUDA graph shapes:  97%|█████████▋| 34/35 [01:41<00:02,  2.14s/it]"
          ]
        }
      ],
      "source": [
        "# we check the logs until the server has been started correctly\n",
        "!while ! grep -q \"Application startup complete\" vllm.log; do tail -n 1 vllm.log; sleep 5; done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlJpisBPGUsC"
      },
      "source": [
        "find the process ID (PID) using a command like ps aux | grep vllm and then kill it using kill -9 <PID>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaqw6s9FETtA",
        "outputId": "459fd40a-7dae-45cb-c340-7c86bd5c74a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        3440  3.5  8.5 6548852 1130792 ?     Sl   17:24   0:13 python3 -m vllm.entrypoints.opena\n",
            "root        5378  0.0  0.0   7376  3452 ?        S    17:30   0:00 /bin/bash -c ps aux | grep vllm\n",
            "root        5380  0.0  0.0   6484  2280 ?        S    17:30   0:00 grep vllm\n"
          ]
        }
      ],
      "source": [
        "# Find the process ID (PID)\n",
        "!ps aux | grep vllm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMDeFYy0Gjlt"
      },
      "outputs": [],
      "source": [
        "# To kill the process, look for the first set of digits\n",
        "#!kill -9 2120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k-GdaBnm2W6",
        "outputId": "8a1ae65d-d123-447b-fb58-eef9ae06f2c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vllm server is running\n",
            "The vllm server is ready to serve.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "def check_vllm_status():\n",
        "    try:\n",
        "        response = requests.get(\"http://localhost:8000/health\")\n",
        "        if response.status_code == 200:\n",
        "            print(\"vllm server is running\")\n",
        "            return True\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        print(\"vllm server is not running\")\n",
        "        return False\n",
        "\n",
        "try:\n",
        "    # Monitor the process\n",
        "    while True:\n",
        "        if check_vllm_status() == True:\n",
        "            print(\"The vllm server is ready to serve.\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"The vllm server has stopped.\")\n",
        "            stdout, stderr = vllm_process.communicate(timeout=10)\n",
        "            print(f\"STDOUT: {stdout.decode('utf-8')}\")\n",
        "            print(f\"STDERR: {stderr.decode('utf-8')}\")\n",
        "            break\n",
        "        time.sleep(5)  # Check every second\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopping the check of vllm...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23Gn89-wNN4b",
        "outputId": "fb08174c-36c4-4ca6-c332-ccec3918ff10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Why did the neural network go to therapy?\\n\\nBecause it had a lot of \"hidden layers\" and was struggling to \"backpropagate\" its emotions!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 52, 'total_tokens': 84, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'unsloth/llama-3-8b-Instruct-bnb-4bit', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-31488c76-daeb-4a16-a5fb-e222675c6d39-0', usage_metadata={'input_tokens': 52, 'output_tokens': 32, 'total_tokens': 84, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(\n",
        "    model=\"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
        "    temperature=0.5,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    api_key=\"not_required\",\n",
        "    base_url=\"http://localhost:8000/v1\",\n",
        "    # organization=\"...\",\n",
        "    # other params...\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant and study companion.\",\n",
        "    ),\n",
        "    (\"human\", \"Tell me a joke about Deep Learning.\"),\n",
        "]\n",
        "ai_msg = model.invoke(messages)\n",
        "ai_msg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnyb6pAxLmzj"
      },
      "source": [
        "### Using Docker Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rcpGtb3uAB5"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "docker run \\\n",
        "  --runtime nvidia --gpus all \\\n",
        "  --name ITI110_vllm_container \\\n",
        "  -v ~/.cache/huggingface:/root/.cache/huggingface \\\n",
        "  --env \"HUGGING_FACE_HUB_TOKEN=$SECRETS/HF_TOKEN\" \\\n",
        "  -p 8000:8000 \\\n",
        "  --ipc=host \\\n",
        "  -v /content/examples:/examples \\ # Mount the directory\n",
        "  vllm/vllm-openai:latest \\\n",
        "  vllm.entrypoints.openai.api_server \\  # Start the vllm server explicitly\n",
        "    --model unsloth/llama-3-8b-Instruct-bnb-4bit \\\n",
        "    --enable-auto-tool-choice \\\n",
        "    --tool-call-parser llama3_json \\\n",
        "    --chat-template examples/tool_chat_template_llama3.1_json.jinja \\\n",
        "    --quantization bitsandbytes \\\n",
        "    --load-format bitsandbytes \\\n",
        "    --dtype half \\\n",
        "    --max-model-len 8192 \\\n",
        "    --download-dir models/vllm \\\n",
        "    > vllm.log &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiWuRZp3LrT2"
      },
      "outputs": [],
      "source": [
        "# Load and run the model:\n",
        "!docker exec -it my_vllm_container bash -c \"vllm serve unsloth/llama-3-8b-Instruct-bnb-4bit\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77OsFI4ULvID"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Call the server using curl:\n",
        "curl -X POST \"http://localhost:8000/v1/chat/completions\" \\\n",
        "\t-H \"Content-Type: application/json\" \\\n",
        "\t--data {\n",
        "\t\t\"model\": \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
        "\t\t\"messages\": [\n",
        "\t\t\t{\n",
        "\t\t\t\t\"role\": \"user\",\n",
        "\t\t\t\t\"content\": \"What is the capital of France?\"\n",
        "\t\t\t}\n",
        "\t\t]\n",
        "\t}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7soxxBDs_qr"
      },
      "source": [
        "### GROQ Serving (For Test References)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyup3FLGDE34",
        "outputId": "0533a4c7-954a-44ed-8eab-8b74f7d57f01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"<think>\\n\\n</think>\\n\\nGreetings! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 7, 'total_tokens': 51, 'completion_time': 0.16, 'prompt_time': 0.00358776, 'queue_time': 0.236025766, 'total_time': 0.16358776}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_3de5b607fa', 'finish_reason': 'stop', 'logprobs': None} id='run-f9e2908f-1eef-4acd-9c1d-b301939402ae-0' usage_metadata={'input_tokens': 7, 'output_tokens': 44, 'total_tokens': 51}\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initialize Groq LLM\n",
        "model = ChatGroq(\n",
        "    model_name=\"deepseek-r1-distill-llama-70b\",   #\"llama-3.2-3b-preview\", \"deepseek-r1-distill-llama-70b\"\n",
        "    temperature=0.6,\n",
        "    api_key=GROQ_API_KEY,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(model.invoke(\"Who are you?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4cHTN0bHivs"
      },
      "source": [
        "### LangGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "SXMyAFM6bSiz",
        "outputId": "1696e3e0-ecd6-462f-b85d-82024eda3b4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-b1f15ce53ebc>:36: LangChainBetaWarning: The function `init_embeddings` is in beta. It is actively being worked on, so the API may change.\n",
            "  \"embed\": init_embeddings(\"huggingface:sentence-transformers/all-MiniLM-L6-v2\"),\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import json\n",
        "from typing import (\n",
        "    Annotated,\n",
        "    Sequence,\n",
        "    TypedDict,\n",
        "    List,\n",
        ")\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# LangChain / LangGraph imports\n",
        "from langchain_core.messages import (\n",
        "    SystemMessage,\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    BaseMessage,\n",
        "    ToolMessage,\n",
        ")\n",
        "from langchain_core.tools import StructuredTool\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "from langgraph.prebuilt import InjectedStore\n",
        "from langgraph.store.base import BaseStore\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain.embeddings import init_embeddings\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "###############################################################################\n",
        "# 1. Initialize memory + config\n",
        "###############################################################################\n",
        "in_memory_store = InMemoryStore(\n",
        "    index={\n",
        "        \"embed\": init_embeddings(\"huggingface:sentence-transformers/all-MiniLM-L6-v2\"),\n",
        "        \"dims\": 384,  # Embedding dimensions\n",
        "    }\n",
        ")\n",
        "\n",
        "# A memory saver to checkpoint conversation states\n",
        "checkpointer = MemorySaver()\n",
        "\n",
        "# Initialize config with user & thread info\n",
        "config = {}\n",
        "config[\"configurable\"] = {\n",
        "    \"user_id\": \"user_1\",\n",
        "    \"thread_id\": 0,\n",
        "}\n",
        "\n",
        "###############################################################################\n",
        "# 2. Define MessagesState\n",
        "###############################################################################\n",
        "class MessagesState(TypedDict):\n",
        "    \"\"\"The state of the agent.\n",
        "\n",
        "    The key 'messages' uses add_messages as a reducer,\n",
        "    so each time this state is updated, new messages are appended.\n",
        "    # See https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers\n",
        "    \"\"\"\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 3. Memory Tools\n",
        "###############################################################################\n",
        "def save_memory(summary_text: str, *, config: RunnableConfig, store: BaseStore) -> str:\n",
        "    \"\"\"Save the given memory for the current user and return the key.\"\"\"\n",
        "    user_id = config.get(\"configurable\", {}).get(\"user_id\")\n",
        "    thread_id = config.get(\"configurable\", {}).get(\"thread_id\")\n",
        "    namespace = (user_id, \"memories\")\n",
        "    memory_id = thread_id\n",
        "    store.put(namespace, memory_id, {\"memory\": summary_text})\n",
        "    return f\"Saved to memory key: {memory_id}\"\n",
        "\n",
        "def update_memory(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
        "    # Extract the messages list from the event, handling potential missing key\n",
        "    messages = state[\"messages\"]\n",
        "    # Convert LangChain messages to dictionaries before storing\n",
        "    messages_dict = [{\"role\": msg.type, \"content\": msg.content} for msg in messages]\n",
        "\n",
        "    # Get the user id from the config\n",
        "    user_id = config.get(\"configurable\", {}).get(\"user_id\")\n",
        "    thread_id = config.get(\"configurable\", {}).get(\"thread_id\")\n",
        "    # Namespace the memory\n",
        "    namespace = (user_id, \"memories\")\n",
        "    # Create a new memory ID\n",
        "    memory_id = f\"{thread_id}\"\n",
        "    store.put(namespace, memory_id, {\"memory\": messages_dict})\n",
        "    return f\"Saved to memory key: {memory_id}\"\n",
        "\n",
        "\n",
        "# Define a Pydantic schema for the save_memory tool (if needed elsewhere)\n",
        "# https://langchain-ai.github.io/langgraphjs/reference/classes/checkpoint.InMemoryStore.html\n",
        "class RecallMemory(BaseModel):\n",
        "    query_text: str = Field(..., title=\"Search Text\", description=\"The text to search from memories for similar records.\")\n",
        "    k: int = Field(5, title=\"Number of Results\", description=\"Number of results to retrieve.\")\n",
        "\n",
        "def recall_memory(query_text: str, k: int = 5) -> str:\n",
        "    \"\"\"Retrieve user memories from in_memory_store.\"\"\"\n",
        "    user_id = config.get(\"configurable\", {}).get(\"user_id\")\n",
        "    memories = [\n",
        "        m.value[\"memory\"] for m in in_memory_store.search((user_id, \"memories\"), query=query_text, limit=k)\n",
        "        if \"memory\" in m.value\n",
        "    ]\n",
        "    return f\"User memories: {memories}\"\n",
        "\n",
        "# Create a StructuredTool from the function\n",
        "recall_memory_tool = StructuredTool.from_function(\n",
        "    func=recall_memory,\n",
        "    name=\"Recall Memory Tool\",\n",
        "    description=\"\"\"\n",
        "      Retrieve memories relevant to the user's query.\n",
        "      \"\"\",\n",
        "    args_schema=RecallMemory,\n",
        "    response_format=\"content\",\n",
        "    return_direct=False,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "###############################################################################\n",
        "# 4. Summarize Node (using StructuredTool)\n",
        "###############################################################################\n",
        "# Define a Pydantic schema for the Summary tool\n",
        "class SummariseConversation(BaseModel):\n",
        "    summary_text: str = Field(..., title=\"text\", description=\"Write a summary of entire conversation here\")\n",
        "\n",
        "def summarise_node(summary_text: str):\n",
        "    \"\"\"\n",
        "    Final node that summarizes the entire conversation for the current thread,\n",
        "    saves it in memory, increments the thread_id, and ends the conversation.\n",
        "    Returns a confirmation string.\n",
        "    \"\"\"\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    current_thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "    new_thread_id = str(int(current_thread_id) + 1)\n",
        "\n",
        "    # Prepare configuration for saving memory with updated thread id\n",
        "    config_for_saving = {\n",
        "        \"configurable\": {\n",
        "            \"user_id\": user_id,\n",
        "            \"thread_id\": new_thread_id\n",
        "        }\n",
        "    }\n",
        "    key = save_memory(summary_text, config=config_for_saving, store=in_memory_store)\n",
        "    #return f\"Summary saved under key: {key}\"\n",
        "\n",
        "# Create a StructuredTool from the function (this wraps summarise_node)\n",
        "summarise_tool = StructuredTool.from_function(\n",
        "    func=summarise_node,\n",
        "    name=\"Summary Tool\",\n",
        "    description=\"\"\"\n",
        "      Summarize the current conversation in no more than\n",
        "      1000 words. Also retain any unanswered quiz questions along with\n",
        "      your internal answers so the next conversation thread can continue.\n",
        "      Do not reveal solutions to the user yet. Use this tool to save\n",
        "      the current conversation to memory and then end the conversation.\n",
        "      \"\"\",\n",
        "    args_schema=SummariseConversation,\n",
        "    response_format=\"content\",\n",
        "    return_direct=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "def call_summary(state: MessagesState, config: RunnableConfig):\n",
        "    # Convert message dicts to HumanMessage instances if needed.\n",
        "    system_message=\"\"\"\n",
        "      Summarize the current conversation in no more than\n",
        "      1000 words. Also retain any unanswered quiz questions along with\n",
        "      your internal answers.\n",
        "      \"\"\"\n",
        "    messages = []\n",
        "    for m in state[\"messages\"]:\n",
        "        if isinstance(m, dict):\n",
        "            # Use role from dict (defaulting to 'user' if missing)\n",
        "            messages.append(AIMessage(content=system_message, role=m.get(\"role\", \"assistant\")))\n",
        "        else:\n",
        "            messages.append(m)\n",
        "\n",
        "    summaries = llm_with_tools.invoke(messages)\n",
        "\n",
        "    summary_content = summaries.content\n",
        "\n",
        "    # Call Tool Manually\n",
        "    message_with_single_tool_call = AIMessage(\n",
        "        content=\"\",\n",
        "        tool_calls=[\n",
        "            {\n",
        "                \"name\": \"Summary Tool\",\n",
        "                \"args\": {\"summary_text\": summary_content},\n",
        "                \"id\": \"tool_call_id\",\n",
        "                \"type\": \"tool_call\",\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    tool_node.invoke({\"messages\": [message_with_single_tool_call]})\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 5. Build the Graph\n",
        "###############################################################################\n",
        "graph_builder = StateGraph(MessagesState)\n",
        "\n",
        "# Use the built-in ToolNode from langgraph that calls any declared tools.\n",
        "tools = [\n",
        "    mcq_retriever_tool,\n",
        "    web_extraction_tool,\n",
        "    ensemble_retriever_tool,\n",
        "    general_retriever_tool,\n",
        "    in_memory_retriever_tool,\n",
        "    recall_memory_tool,\n",
        "    summarise_tool,\n",
        "]\n",
        "\n",
        "tool_node = ToolNode(tools=tools)\n",
        "#end_node = ToolNode(tools=[summarise_tool])\n",
        "\n",
        "# Wrap your model with tools\n",
        "llm_with_tools = model.bind_tools(tools)\n",
        "\n",
        "###############################################################################\n",
        "# 6. The agent's main node: call_model\n",
        "###############################################################################\n",
        "def call_model(state: MessagesState, config: RunnableConfig):\n",
        "    \"\"\"\n",
        "    The main agent node that calls the LLM with the user + system messages.\n",
        "    Since our vLLM chat wrapper expects a list of BaseMessage objects,\n",
        "    we convert any dict messages to HumanMessage objects.\n",
        "    If the LLM requests a tool call, we'll route to the 'tools' node next\n",
        "    (depending on the condition).\n",
        "    \"\"\"\n",
        "    # Convert message dicts to HumanMessage instances if needed.\n",
        "    messages = []\n",
        "    for m in state[\"messages\"]:\n",
        "        if isinstance(m, dict):\n",
        "            # Use role from dict (defaulting to 'user' if missing)\n",
        "            messages.append(HumanMessage(content=m.get(\"content\", \"\"), role=m.get(\"role\", \"user\")))\n",
        "        else:\n",
        "            messages.append(m)\n",
        "\n",
        "    # Invoke the LLM (with tools) using the converted messages.\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "\n",
        "def call_summary(state: MessagesState, config: RunnableConfig):\n",
        "    # Convert message dicts to HumanMessage instances if needed.\n",
        "    system_message=\"\"\"\n",
        "      Summarize the current conversation in no more than\n",
        "      1000 words. Also retain any unanswered quiz questions along with\n",
        "      your internal answers.\n",
        "      \"\"\"\n",
        "    messages = []\n",
        "    for m in state[\"messages\"]:\n",
        "        if isinstance(m, dict):\n",
        "            # Use role from dict (defaulting to 'user' if missing)\n",
        "            messages.append(AIMessage(content=system_message, role=m.get(\"role\", \"assistant\")))\n",
        "        else:\n",
        "            messages.append(m)\n",
        "\n",
        "    summaries = llm_with_tools.invoke(messages)\n",
        "\n",
        "    summary_content = summaries.content\n",
        "\n",
        "    # Call Tool Manually\n",
        "    message_with_single_tool_call = AIMessage(\n",
        "        content=\"\",\n",
        "        tool_calls=[\n",
        "            {\n",
        "                \"name\": \"Summary Tool\",\n",
        "                \"args\": {\"summary_text\": summary_content},\n",
        "                \"id\": \"tool_call_id\",\n",
        "                \"type\": \"tool_call\",\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    tool_node.invoke({\"messages\": [message_with_single_tool_call]})\n",
        "\n",
        "###############################################################################\n",
        "# 7. Add Nodes & Edges, Then Compile\n",
        "###############################################################################\n",
        "graph_builder.add_node(\"agent\", call_model)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "#graph_builder.add_node(\"summary\", call_summary)\n",
        "\n",
        "# Entry point\n",
        "graph_builder.set_entry_point(\"agent\")\n",
        "\n",
        "# def custom_tools_condition(llm_output: dict) -> str:\n",
        "#     \"\"\"Return which node to go to next based on the LLM output.\"\"\"\n",
        "\n",
        "#     # The LLM's JSON might have a field like {\"name\": \"Recall Memory Tool\", \"arguments\": {...}}.\n",
        "#     tool_name = llm_output.get(\"name\", None)\n",
        "\n",
        "#     # If the LLM calls \"Summary Tool\", jump directly to the 'summary' node\n",
        "#     if tool_name == \"Summary Tool\":\n",
        "#         return \"summary\"\n",
        "\n",
        "#     # If the LLM calls any other recognized tool, go to 'tools'\n",
        "#     valid_tool_names = [t.name for t in tools]  # all tools in the main tool_node\n",
        "#     if tool_name in valid_tool_names:\n",
        "#         return \"tools\"\n",
        "\n",
        "#     # If there's no recognized tool name, assume we're done => go to summary\n",
        "#     return \"__end__\"\n",
        "\n",
        "# graph_builder.add_conditional_edges(\n",
        "#     \"agent\",\n",
        "#     custom_tools_condition,\n",
        "#     {\n",
        "#         \"tools\": \"tools\",\n",
        "#         \"summary\": \"summary\",\n",
        "#         \"__end__\": \"summary\",\n",
        "#     }\n",
        "# )\n",
        "\n",
        "# If LLM requests a tool, go to \"tools\", otherwise go to \"summary\"\n",
        "graph_builder.add_conditional_edges(\"agent\", tools_condition)\n",
        "#graph_builder.add_conditional_edges(\"agent\", tools_condition, {\"tools\": \"tools\", \"__end__\": \"summary\"})\n",
        "#graph_builder.add_conditional_edges(\"agent\", lambda llm_output: \"tools\" if llm_output.get(\"name\", None) in [t.name for t in tools] else \"summary\", {\"tools\": \"tools\", \"__end__\": \"summary\"}\n",
        "\n",
        "# If we used a tool, return to the agent for final answer or more tools\n",
        "graph_builder.add_edge(\"tools\", \"agent\")\n",
        "#graph_builder.add_edge(\"agent\", \"summary\")\n",
        "#graph_builder.set_finish_point(\"summary\")\n",
        "\n",
        "# Compile the graph with checkpointing and persistent store\n",
        "graph = graph_builder.compile(checkpointer=checkpointer, store=in_memory_store)\n",
        "\n",
        "#from langgraph.prebuilt import create_react_agent\n",
        "#graph = create_react_agent(llm_with_tools, tools=tool_node, checkpointer=checkpointer, store=in_memory_store)\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F17kNlhSHivw"
      },
      "source": [
        "### Testing with Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5K-VIAskyrtM",
        "outputId": "e2f7697e-a98c-4e96-8b60-f3ecc82a1db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation Thread ID: 0 -> 1\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Find out about Deep Learning from databases. Using Web Extraction Tool, search from website: https://www.ibm.com/think/topics/artificial-intelligence and https://www.ibm.com/think/topics/machine-learning to provide the context\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  Web Extraction Tool (call_js9t)\n",
            " Call ID: call_js9t\n",
            "  Args:\n",
            "    input: Deep Learning\n",
            "    k: 5\n",
            "    url: https://www.ibm.com/think/topics/artificial-intelligence, https://www.ibm.com/think/topics/machine-learning\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: Web Extraction Tool\n",
            "\n",
            "[\"like humans, explore its history and the types of AI, and uncover the ways it impacts our lives.     What is machine learning?   Gain insight into how ML leverages data and algorithms, its use cases and associated concerns to empower responsible and innovative use of the technology.    What is deep learning?   Discover how deep learning simulates our brain, helping systems learn to identify and perform complex tasks with increasing accuracy unsupervised.    What is the k-nearest neighbors algorithm?   Learn about the k-nearest neighbors algorithm, one of the popular and simplest classification and regression classifiers used in machine learning today.     What is natural language processing (NLP)?   Dive into how NLP enables machines to understand and respond to text or voice data and learn about various NLP tasks to obtain optimal results.    What are neural networks?   Learn how neural networks allow programs to recognize patterns and solve common problems in artificial\", \"era of quantum computing with quantum-safe cryptography.     What is a qubit?   Encode data with a qubit, the basic unit of information in quantum computing, which serves as the quantum equivalent of the traditional bit in classical computers.    What is quantum-centric supercomputing?   Leverage quantum-centric supercomputing to combine quantum and traditional high-performance computing (HPC), enabling solutions for complex real-world problems.    What is neuromorphic computing?  Understand how neuromorphic computing, also known as neuromorphic engineering, mimics the way the human brain works.     What is supercomputing?   Explore how supercomputing uses high-performance computing systems to determine or calculate, reducing the overall time to a solution.           Security and identity        View all security topics     What is cybersecurity?   Stay informed about cybersecurity technology, types of threats and best practices to protect your critical systems and sensitive\", \"Explore how energy management helps businesses proactively monitor, control and optimize energy consumption to converse use and reduce energy costs.     What is electronic data interchange (EDI)?   Learn how electronic data interchange (EDI) is used to exchange business information, saving time and eliminating costly errors caused by manual processing.    What is managed file transfer?   Facilitate secure, reliable and automated exchange of file-based data over the internet with managed file transfer (MFT) technology to meet compliance needs.    What is the TCFD?   Find out how the Task Force on Climate-related Financial Disclosures (TCFD) seeks to keep investors better-informed about companies' climate-related risks.     Explore more ways to learn      Stay ahead with the latest tech news     Weekly insights, research and expert views on AI, security, cloud and more in the Think Newsletter  Sign up now         Videos     Elevate your understanding with our expert-led educational\", \"down a monolithic application into smaller deployable services, enabling agility and scalability.    What is mobile application development?   Gain an introductory understanding of mobile application development, which involves making software for smartphones, tablets and digital assistants.    What is Java Spring Boot?   Learn how Java Spring Boot simplifies development of web applications and microservices with an open-source framework referred to as the Java Spring Framework.     What is three-tier architecture?   Separate applications into three logical and physical computing tiers, making it easy to maintain and scale each tier as needed without impacting the other tiers.           Network        View all network topics     What is network security?   Use network security solutions to protect network infrastructure, resources and traffic from internal and external security threats and cyberattacks.     What is load balancing?   Understand how to distribute network traffic\", \"backbone for Kubernetes and other distributed platform.    What is a relational database?   Use a relational database which provides a structured way to organize data in rows and columns that form a table, maintaining data consistency and integrity.           DevOps        View all DevOps topics     What is DevOps?   Learn how DevOps combines and automates software tasks to speed the delivery of high-quality software, and its synergy with site reliability engineering (SRE).    What is DevSecOps?   Automate the integration of security at every phase of the software development lifecycle, with DevSecOps, short for development, security, and operations.     What is software development?   See how software is developed and how it can help your business compete. Discover software development essentials, innovations and technologies.     What is software testing?   Find software errors and verify that an application or system is fit for use, preventing bugs, reducing development costs and\"]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  Web Extraction Tool (call_75ge)\n",
            " Call ID: call_75ge\n",
            "  Args:\n",
            "    input: Deep Learning\n",
            "    k: 5\n",
            "    url: https://www.ibm.com/think/topics/artificial-intelligence, https://www.ibm.com/think/topics/machine-learning\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: Web Extraction Tool\n",
            "\n",
            "[\"like humans, explore its history and the types of AI, and uncover the ways it impacts our lives.     What is machine learning?   Gain insight into how ML leverages data and algorithms, its use cases and associated concerns to empower responsible and innovative use of the technology.    What is deep learning?   Discover how deep learning simulates our brain, helping systems learn to identify and perform complex tasks with increasing accuracy unsupervised.    What is the k-nearest neighbors algorithm?   Learn about the k-nearest neighbors algorithm, one of the popular and simplest classification and regression classifiers used in machine learning today.     What is natural language processing (NLP)?   Dive into how NLP enables machines to understand and respond to text or voice data and learn about various NLP tasks to obtain optimal results.    What are neural networks?   Learn how neural networks allow programs to recognize patterns and solve common problems in artificial\", \"news     Weekly insights, research and expert views on AI, security, cloud and more in the Think Newsletter  Sign up now         Videos     Elevate your understanding with our expert-led educational videos and YouTube playlists on the biggest topics and trends in tech. Master the basics, enhance your skill set or acquire real-world strategies for leveraging technology.  Watch the videos         Podcasts     Explore our diverse podcast series, featuring expert discussions on top tech topics, real-world application of our products and a look at our culture of diversity, learning and agility.  Tune in to our podcasts\", \"era of quantum computing with quantum-safe cryptography.     What is a qubit?   Encode data with a qubit, the basic unit of information in quantum computing, which serves as the quantum equivalent of the traditional bit in classical computers.    What is quantum-centric supercomputing?   Leverage quantum-centric supercomputing to combine quantum and traditional high-performance computing (HPC), enabling solutions for complex real-world problems.    What is neuromorphic computing?  Understand how neuromorphic computing, also known as neuromorphic engineering, mimics the way the human brain works.     What is supercomputing?   Explore how supercomputing uses high-performance computing systems to determine or calculate, reducing the overall time to a solution.           Security and identity        View all security topics     What is cybersecurity?   Stay informed about cybersecurity technology, types of threats and best practices to protect your critical systems and sensitive\", \"regression method and by knowing which type of logistic regression to use.    What is Monte Carlo simulation?   Learn how to run a Monte Carlo Simulation, a computational algorithm, by using repeated random sampling to estimate the possible outcomes of an uncertain event.    What is exploratory data analysis?   Know about exploratory data analysis to effectively analyze and summarize data sets, helping one to discover patterns and anomalies, and generate a hypothesis.    What is data science?   Leverage data science to unlock business insights from an increasing amount of data, accelerate digital transformation and data-driven decision making.    Asset management View all asset management topics     What is visual inspection?   Master visual inspection of equipments to detect defects both in person and remotely using digital images to maintain quality and safety standards.     What is preventive maintenance?   Implement preventive maintenance by combining regular maintenance tasks\", \"Explore how energy management helps businesses proactively monitor, control and optimize energy consumption to converse use and reduce energy costs.     What is electronic data interchange (EDI)?   Learn how electronic data interchange (EDI) is used to exchange business information, saving time and eliminating costly errors caused by manual processing.    What is managed file transfer?   Facilitate secure, reliable and automated exchange of file-based data over the internet with managed file transfer (MFT) technology to meet compliance needs.    What is the TCFD?   Find out how the Task Force on Climate-related Financial Disclosures (TCFD) seeks to keep investors better-informed about companies' climate-related risks.     Explore more ways to learn      Stay ahead with the latest tech news     Weekly insights, research and expert views on AI, security, cloud and more in the Think Newsletter  Sign up now         Videos     Elevate your understanding with our expert-led educational\"]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  Web Extraction Tool (call_chm4)\n",
            " Call ID: call_chm4\n",
            "  Args:\n",
            "    input: Deep Learning\n",
            "    k: 5\n",
            "    url: https://www.ibm.com/think/topics/artificial-intelligence, https://www.ibm.com/think/topics/machine-learning\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: Web Extraction Tool\n",
            "\n",
            "[\"like humans, explore its history and the types of AI, and uncover the ways it impacts our lives.     What is machine learning?   Gain insight into how ML leverages data and algorithms, its use cases and associated concerns to empower responsible and innovative use of the technology.    What is deep learning?   Discover how deep learning simulates our brain, helping systems learn to identify and perform complex tasks with increasing accuracy unsupervised.    What is the k-nearest neighbors algorithm?   Learn about the k-nearest neighbors algorithm, one of the popular and simplest classification and regression classifiers used in machine learning today.     What is natural language processing (NLP)?   Dive into how NLP enables machines to understand and respond to text or voice data and learn about various NLP tasks to obtain optimal results.    What are neural networks?   Learn how neural networks allow programs to recognize patterns and solve common problems in artificial\", \"Think Topics | IBM             Home Think  Topics      Explainers            Become an expert on emerging and fundamental tech topics            Featured topics  Demystify transformative technologies. Decode tech topics with content crafted by IBM experts.        What is data mining?  Learn how data mining combines statistics and artificial intelligence to analyze large data sets to discover meaningful insights and useful information.        What is a vector database?  Use a vector database for storing, managing and indexing huge quantities of high-dimensional vector data efficiently for generative AI use cases and applications.        What is a chatbot?  Explore chatbot technology to understand how chatbots simulate human conversation, often using NLP to parse inputs and generative AI to automate responses.        What is a DDoS (distributed denial of service) attack?  Find out how a DDoS attack floods websites and other network resources with malicious traffic, disrupting normal\", \"news     Weekly insights, research and expert views on AI, security, cloud and more in the Think Newsletter  Sign up now         Videos     Elevate your understanding with our expert-led educational videos and YouTube playlists on the biggest topics and trends in tech. Master the basics, enhance your skill set or acquire real-world strategies for leveraging technology.  Watch the videos         Podcasts     Explore our diverse podcast series, featuring expert discussions on top tech topics, real-world application of our products and a look at our culture of diversity, learning and agility.  Tune in to our podcasts\", \"era of quantum computing with quantum-safe cryptography.     What is a qubit?   Encode data with a qubit, the basic unit of information in quantum computing, which serves as the quantum equivalent of the traditional bit in classical computers.    What is quantum-centric supercomputing?   Leverage quantum-centric supercomputing to combine quantum and traditional high-performance computing (HPC), enabling solutions for complex real-world problems.    What is neuromorphic computing?  Understand how neuromorphic computing, also known as neuromorphic engineering, mimics the way the human brain works.     What is supercomputing?   Explore how supercomputing uses high-performance computing systems to determine or calculate, reducing the overall time to a solution.           Security and identity        View all security topics     What is cybersecurity?   Stay informed about cybersecurity technology, types of threats and best practices to protect your critical systems and sensitive\", \"in person and remotely using digital images to maintain quality and safety standards.     What is preventive maintenance?   Implement preventive maintenance by combining regular maintenance tasks with ML, data analytics and predictive asset health monitoring to prevent downtime.    What is a CMMS?   Enhance maintenance efforts with a computerized maintenance management system (CMMS) for efficient scheduling, managing, and tracking of maintenance tasks.    What is a digital twin?   Explore how digital twins create a virtual copy of an object or system by integrating real-time data, simulation, ML and reasoning to support decision-making.    What is field service management?   Learn field service management to effectively coordinate resources, employees and equipment, in work activities and operations off company property.           Business operations        View all business automation topics     What is business automation?   Explore what business automation is, why it matters and\"]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Deep Learning is a subset of machine learning that utilizes neural networks with multiple layers to learn complex patterns in data. These networks, inspired by the human brain, consist of an input layer, several hidden layers, and an output layer, allowing them to handle unstructured data like images, speech, and text more effectively than traditional machine learning methods.\n",
            "\n",
            "**Key Points:**\n",
            "\n",
            "1. **Structure and Function:**\n",
            "   - Deep Learning uses deep neural networks with many layers, enabling the learning of intricate data patterns.\n",
            "   - Techniques include convolutional neural networks (CNNs) for image recognition and recurrent neural networks (RNNs) for sequence data.\n",
            "\n",
            "2. **Applications:**\n",
            "   - Used in self-driving cars for object recognition, virtual assistants for speech understanding, and recommendation systems for personalized suggestions.\n",
            "\n",
            "3. **Challenges:**\n",
            "   - Requires large datasets and significant computational resources for training.\n",
            "   - Issues include data bias, resource intensity, and the difficulty of interpreting model decisions.\n",
            "\n",
            "4. **Frameworks and Tools:**\n",
            "   - Utilizes frameworks like TensorFlow and PyTorch for building and training models.\n",
            "\n",
            "5. **Future Directions:**\n",
            "   - Potential advancements with quantum computing and edge computing to enhance efficiency and accessibility.\n",
            "\n",
            "6. **Ethical Considerations:**\n",
            "   - Concerns about privacy, especially in facial recognition, and the need for careful data curation to avoid bias.\n",
            "\n",
            "In summary, Deep Learning is a powerful tool with diverse applications, offering capabilities beyond traditional machine learning but requiring careful consideration of its challenges and ethical implications.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Saved to memory key: 1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# URL\n",
        "url1 = \"https://www.ibm.com/think/topics/artificial-intelligence\"\n",
        "url2 = \"https://www.ibm.com/think/topics/machine-learning\"\n",
        "\n",
        "question_1 = (f\"Find out about Deep Learning from databases. Using Web Extraction Tool, search from website: {url1} and {url2} to provide the context\")\n",
        "question_2 = \"Provide 5 MCQ questions on Artificial Intelligence to help me with practice.\"\n",
        "question_3 = \"Here are my answers: 1. A, 2. B, 3. C, 4. D, 5. E. Please check mu answer, provide reasons for my wrong answers and provide the correct answers with explanations.\"\n",
        "question_4 = \"Provide another 5 MCQ questions on Artificial Intelligence to help me with practice.\"\n",
        "question_5 = \"Here are my answers: 1. A, 2. B, 3. C, 4. D, 5. E. Please check mu answer, provide reasons for my wrong answers and provide the correct answers with explanations.\"\n",
        "question_6 = \"Provide a study quide to help me learn for my wrong answers for the MCQ questions.\"\n",
        "question_7 = \"Based on your reference databases only, provide a study quide on Deep Learning.\"\n",
        "question_8 = \"Based on your memory, provide a summary of our conversation.\"\n",
        "question_9 = \"Summarise the conversation so far.\"\n",
        "\n",
        "\n",
        "# Grab the current user_id and thread_id from config\n",
        "user_id = \"user_1\"\n",
        "\n",
        "# Get last thread_id\n",
        "last_thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "thread_id = str(int(last_thread_id) + 1)\n",
        "\n",
        "# Print Config\n",
        "print(f\"Conversation Thread ID: {last_thread_id} -> {thread_id}\")\n",
        "\n",
        "# Update the config with the new thread_id\n",
        "config = {\"configurable\": {\"thread_id\": thread_id, \"user_id\": user_id}}\n",
        "\n",
        "# Create a system prompt (your overall instructions to the AI)\n",
        "system_prompt = (f\"\"\"\n",
        "You are a helpful AI Tutor assistant.\n",
        "\"\"\")\n",
        "\n",
        "#The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [\n",
        "        #{\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": question_1}]},\n",
        "    config, # Pass the thread-level persistence to the graph\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    response = event[\"messages\"][-1]\n",
        "    response.pretty_print()\n",
        "\n",
        "update_memory(event, config, store=in_memory_store) # Update Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4rZtd4vjRJYG"
      },
      "outputs": [],
      "source": [
        "# Function for user to input their query and system prompt to the agent\n",
        "def submit_query(user_query, temperature, config: RunnableConfig):\n",
        "    # 'user_1' from the config in utils.\n",
        "    USER_ID = config[\"configurable\"][\"user_id\"]\n",
        "    # Get last thread_id\n",
        "    last_thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "    thread_id = str(int(last_thread_id) + 1)\n",
        "\n",
        "    # Update the config with the new thread_id\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id, \"user_id\": USER_ID}}\n",
        "\n",
        "    # 1) Call query_agent as before to get the streaming generator.\n",
        "    events = graph.stream(\n",
        "        {\n",
        "            \"messages\": [\n",
        "                #{\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_query}\n",
        "            ]\n",
        "        },\n",
        "        config,  # user_id, thread_id, etc.\n",
        "        stream_mode=\"values\",\n",
        "    )\n",
        "\n",
        "    # 2) We'll capture each message's pretty_print() into a list for the console.\n",
        "    from io import StringIO\n",
        "    import sys\n",
        "\n",
        "    message_stream = []\n",
        "    final_response = \"\"\n",
        "    for event in events:\n",
        "        # Each event is a dict with \"messages\" as a list of BaseMessage objects.\n",
        "        for msg in event[\"messages\"]:\n",
        "            # If for some reason the msg doesn't support pretty_print, we fallback to .content\n",
        "            captured_output = StringIO()\n",
        "            original_stdout = sys.stdout\n",
        "            try:\n",
        "                sys.stdout = captured_output\n",
        "                # If it's an AI/Tool message with pretty_print(), call it:\n",
        "                if hasattr(msg, \"pretty_print\"):\n",
        "                    msg.pretty_print()\n",
        "                else:\n",
        "                    # Otherwise, just print its content\n",
        "                    print(msg.content)\n",
        "            finally:\n",
        "                sys.stdout = original_stdout\n",
        "\n",
        "            # Store the captured text into our message_stream\n",
        "            pretty_text = captured_output.getvalue()\n",
        "            message_stream.append(pretty_text.strip())\n",
        "\n",
        "        # If this event had at least one message, the last is presumably the LLM's response\n",
        "        if event[\"messages\"]:\n",
        "            final_response = event[\"messages\"][-1].content\n",
        "\n",
        "    update_memory(event, config, store=in_memory_store) # Update Memory\n",
        "\n",
        "    # 3) Return final response for the chatbot's main window\n",
        "    #    and the entire stream for the console output.\n",
        "    return final_response, \"\\n\".join(message_stream), config\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzcOcBWOmWiP"
      },
      "source": [
        "#### Accessing and Testing LLM Chat Model Memory Persistence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DtldTWDfRJYG",
        "outputId": "af3065b8-8fb5-4297-a1df-240b669fbb85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation History:\n",
            "[\n",
            "  [\n",
            "    {\n",
            "      \"role\": \"human\",\n",
            "      \"content\": \"Find out about Deep Learning from databases. Using Web Extraction Tool, search from website: https://www.ibm.com/think/topics/artificial-intelligence and https://www.ibm.com/think/topics/machine-learning to provide the context\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"ai\",\n",
            "      \"content\": \"\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"tool\",\n",
            "      \"content\": \"[\\\"like humans, explore its history and the types of AI, and uncover the ways it impacts our lives.     What is machine learning?   Gain insight into how ML leverages data and algorithms, its use cases and associated concerns to empower responsible and innovative use of the technology.    What is deep learning?   Discover how deep learning simulates our brain, helping systems learn to identify and perform complex tasks with increasing accuracy unsupervised.    What is the k-nearest neighbors algorithm?   Learn about the k-nearest neighbors algorithm, one of the popular and simplest classification and regression classifiers used in machine learning today.     What is natural language processing (NLP)?   Dive into how NLP enables machines to understand and respond to text or voice data and learn about various NLP tasks to obtain optimal results.    What are neural networks?   Learn how neural networks allow programs to recognize patterns and solve common problems in artificial\\\", \\\"era of quantum computing with quantum-safe cryptography.     What is a qubit?   Encode data with a qubit, the basic unit of information in quantum computing, which serves as the quantum equivalent of the traditional bit in classical computers.    What is quantum-centric supercomputing?   Leverage quantum-centric supercomputing to combine quantum and traditional high-performance computing (HPC), enabling solutions for complex real-world problems.    What is neuromorphic computing?  Understand how neuromorphic computing, also known as neuromorphic engineering, mimics the way the human brain works.     What is supercomputing?   Explore how supercomputing uses high-performance computing systems to determine or calculate, reducing the overall time to a solution.           Security and identity        View all security topics     What is cybersecurity?   Stay informed about cybersecurity technology, types of threats and best practices to protect your critical systems and sensitive\\\", \\\"Explore how energy management helps businesses proactively monitor, control and optimize energy consumption to converse use and reduce energy costs.     What is electronic data interchange (EDI)?   Learn how electronic data interchange (EDI) is used to exchange business information, saving time and eliminating costly errors caused by manual processing.    What is managed file transfer?   Facilitate secure, reliable and automated exchange of file-based data over the internet with managed file transfer (MFT) technology to meet compliance needs.    What is the TCFD?   Find out how the Task Force on Climate-related Financial Disclosures (TCFD) seeks to keep investors better-informed about companies' climate-related risks.     Explore more ways to learn      Stay ahead with the latest tech news     Weekly insights, research and expert views on AI, security, cloud and more in the Think Newsletter  Sign up now         Videos     Elevate your understanding with our expert-led educational\\\", \\\"down a monolithic application into smaller deployable services, enabling agility and scalability.    What is mobile application development?   Gain an introductory understanding of mobile application development, which involves making software for smartphones, tablets and digital assistants.    What is Java Spring Boot?   Learn how Java Spring Boot simplifies development of web applications and microservices with an open-source framework referred to as the Java Spring Framework.     What is three-tier architecture?   Separate applications into three logical and physical computing tiers, making it easy to maintain and scale each tier as needed without impacting the other tiers.           Network        View all network topics     What is network security?   Use network security solutions to protect network infrastructure, resources and traffic from internal and external security threats and cyberattacks.     What is load balancing?   Understand how to distribute network traffic\\\", \\\"backbone for Kubernetes and other distributed platform.    What is a relational database?   Use a relational database which provides a structured way to organize data in rows and columns that form a table, maintaining data consistency and integrity.           DevOps        View all DevOps topics     What is DevOps?   Learn how DevOps combines and automates software tasks to speed the delivery of high-quality software, and its synergy with site reliability engineering (SRE).    What is DevSecOps?   Automate the integration of security at every phase of the software development lifecycle, with DevSecOps, short for development, security, and operations.     What is software development?   See how software is developed and how it can help your business compete. Discover software development essentials, innovations and technologies.     What is software testing?   Find software errors and verify that an application or system is fit for use, preventing bugs, reducing development costs and\\\"]\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"ai\",\n",
            "      \"content\": \"\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"tool\",\n",
            "      \"content\": \"[\\\"like humans, explore its history and the types of AI, and uncover the ways it impacts our lives.     What is machine learning?   Gain insight into how ML leverages data and algorithms, its use cases and associated concerns to empower responsible and innovative use of the technology.    What is deep learning?   Discover how deep learning simulates our brain, helping systems learn to identify and perform complex tasks with increasing accuracy unsupervised.    What is the k-nearest neighbors algorithm?   Learn about the k-nearest neighbors algorithm, one of the popular and simplest classification and regression classifiers used in machine learning today.     What is natural language processing (NLP)?   Dive into how NLP enables machines to understand and respond to text or voice data and learn about various NLP tasks to obtain optimal results.    What are neural networks?   Learn how neural networks allow programs to recognize patterns and solve common problems in artificial\\\", \\\"news     Weekly insights, research and expert views on AI, security, cloud and more in the Think Newsletter  Sign up now         Videos     Elevate your understanding with our expert-led educational videos and YouTube playlists on the biggest topics and trends in tech. Master the basics, enhance your skill set or acquire real-world strategies for leveraging technology.  Watch the videos         Podcasts     Explore our diverse podcast series, featuring expert discussions on top tech topics, real-world application of our products and a look at our culture of diversity, learning and agility.  Tune in to our podcasts\\\", \\\"era of quantum computing with quantum-safe cryptography.     What is a qubit?   Encode data with a qubit, the basic unit of information in quantum computing, which serves as the quantum equivalent of the traditional bit in classical computers.    What is quantum-centric supercomputing?   Leverage quantum-centric supercomputing to combine quantum and traditional high-performance computing (HPC), enabling solutions for complex real-world problems.    What is neuromorphic computing?  Understand how neuromorphic computing, also known as neuromorphic engineering, mimics the way the human brain works.     What is supercomputing?   Explore how supercomputing uses high-performance computing systems to determine or calculate, reducing the overall time to a solution.           Security and identity        View all security topics     What is cybersecurity?   Stay informed about cybersecurity technology, types of threats and best practices to protect your critical systems and sensitive\\\", \\\"regression method and by knowing which type of logistic regression to use.    What is Monte Carlo simulation?   Learn how to run a Monte Carlo Simulation, a computational algorithm, by using repeated random sampling to estimate the possible outcomes of an uncertain event.    What is exploratory data analysis?   Know about exploratory data analysis to effectively analyze and summarize data sets, helping one to discover patterns and anomalies, and generate a hypothesis.    What is data science?   Leverage data science to unlock business insights from an increasing amount of data, accelerate digital transformation and data-driven decision making.    Asset management View all asset management topics     What is visual inspection?   Master visual inspection of equipments to detect defects both in person and remotely using digital images to maintain quality and safety standards.     What is preventive maintenance?   Implement preventive maintenance by combining regular maintenance tasks\\\", \\\"Explore how energy management helps businesses proactively monitor, control and optimize energy consumption to converse use and reduce energy costs.     What is electronic data interchange (EDI)?   Learn how electronic data interchange (EDI) is used to exchange business information, saving time and eliminating costly errors caused by manual processing.    What is managed file transfer?   Facilitate secure, reliable and automated exchange of file-based data over the internet with managed file transfer (MFT) technology to meet compliance needs.    What is the TCFD?   Find out how the Task Force on Climate-related Financial Disclosures (TCFD) seeks to keep investors better-informed about companies' climate-related risks.     Explore more ways to learn      Stay ahead with the latest tech news     Weekly insights, research and expert views on AI, security, cloud and more in the Think Newsletter  Sign up now         Videos     Elevate your understanding with our expert-led educational\\\"]\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"ai\",\n",
            "      \"content\": \"\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"tool\",\n",
            "      \"content\": \"[\\\"like humans, explore its history and the types of AI, and uncover the ways it impacts our lives.     What is machine learning?   Gain insight into how ML leverages data and algorithms, its use cases and associated concerns to empower responsible and innovative use of the technology.    What is deep learning?   Discover how deep learning simulates our brain, helping systems learn to identify and perform complex tasks with increasing accuracy unsupervised.    What is the k-nearest neighbors algorithm?   Learn about the k-nearest neighbors algorithm, one of the popular and simplest classification and regression classifiers used in machine learning today.     What is natural language processing (NLP)?   Dive into how NLP enables machines to understand and respond to text or voice data and learn about various NLP tasks to obtain optimal results.    What are neural networks?   Learn how neural networks allow programs to recognize patterns and solve common problems in artificial\\\", \\\"Think Topics | IBM             Home Think  Topics      Explainers            Become an expert on emerging and fundamental tech topics            Featured topics  Demystify transformative technologies. Decode tech topics with content crafted by IBM experts.        What is data mining?  Learn how data mining combines statistics and artificial intelligence to analyze large data sets to discover meaningful insights and useful information.        What is a vector database?  Use a vector database for storing, managing and indexing huge quantities of high-dimensional vector data efficiently for generative AI use cases and applications.        What is a chatbot?  Explore chatbot technology to understand how chatbots simulate human conversation, often using NLP to parse inputs and generative AI to automate responses.        What is a DDoS (distributed denial of service) attack?  Find out how a DDoS attack floods websites and other network resources with malicious traffic, disrupting normal\\\", \\\"news     Weekly insights, research and expert views on AI, security, cloud and more in the Think Newsletter  Sign up now         Videos     Elevate your understanding with our expert-led educational videos and YouTube playlists on the biggest topics and trends in tech. Master the basics, enhance your skill set or acquire real-world strategies for leveraging technology.  Watch the videos         Podcasts     Explore our diverse podcast series, featuring expert discussions on top tech topics, real-world application of our products and a look at our culture of diversity, learning and agility.  Tune in to our podcasts\\\", \\\"era of quantum computing with quantum-safe cryptography.     What is a qubit?   Encode data with a qubit, the basic unit of information in quantum computing, which serves as the quantum equivalent of the traditional bit in classical computers.    What is quantum-centric supercomputing?   Leverage quantum-centric supercomputing to combine quantum and traditional high-performance computing (HPC), enabling solutions for complex real-world problems.    What is neuromorphic computing?  Understand how neuromorphic computing, also known as neuromorphic engineering, mimics the way the human brain works.     What is supercomputing?   Explore how supercomputing uses high-performance computing systems to determine or calculate, reducing the overall time to a solution.           Security and identity        View all security topics     What is cybersecurity?   Stay informed about cybersecurity technology, types of threats and best practices to protect your critical systems and sensitive\\\", \\\"in person and remotely using digital images to maintain quality and safety standards.     What is preventive maintenance?   Implement preventive maintenance by combining regular maintenance tasks with ML, data analytics and predictive asset health monitoring to prevent downtime.    What is a CMMS?   Enhance maintenance efforts with a computerized maintenance management system (CMMS) for efficient scheduling, managing, and tracking of maintenance tasks.    What is a digital twin?   Explore how digital twins create a virtual copy of an object or system by integrating real-time data, simulation, ML and reasoning to support decision-making.    What is field service management?   Learn field service management to effectively coordinate resources, employees and equipment, in work activities and operations off company property.           Business operations        View all business automation topics     What is business automation?   Explore what business automation is, why it matters and\\\"]\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"ai\",\n",
            "      \"content\": \"Deep Learning is a subset of machine learning that utilizes neural networks with multiple layers to learn complex patterns in data. These networks, inspired by the human brain, consist of an input layer, several hidden layers, and an output layer, allowing them to handle unstructured data like images, speech, and text more effectively than traditional machine learning methods.\\n\\n**Key Points:**\\n\\n1. **Structure and Function:**\\n   - Deep Learning uses deep neural networks with many layers, enabling the learning of intricate data patterns.\\n   - Techniques include convolutional neural networks (CNNs) for image recognition and recurrent neural networks (RNNs) for sequence data.\\n\\n2. **Applications:**\\n   - Used in self-driving cars for object recognition, virtual assistants for speech understanding, and recommendation systems for personalized suggestions.\\n\\n3. **Challenges:**\\n   - Requires large datasets and significant computational resources for training.\\n   - Issues include data bias, resource intensity, and the difficulty of interpreting model decisions.\\n\\n4. **Frameworks and Tools:**\\n   - Utilizes frameworks like TensorFlow and PyTorch for building and training models.\\n\\n5. **Future Directions:**\\n   - Potential advancements with quantum computing and edge computing to enhance efficiency and accessibility.\\n\\n6. **Ethical Considerations:**\\n   - Concerns about privacy, especially in facial recognition, and the need for careful data curation to avoid bias.\\n\\nIn summary, Deep Learning is a powerful tool with diverse applications, offering capabilities beyond traditional machine learning but requiring careful consideration of its challenges and ethical implications.\"\n",
            "    }\n",
            "  ]\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# Define function to download the entire conversation history from the memory store and save it to a file\n",
        "def download_conversation_history(user_id: str, store: BaseStore = in_memory_store) -> str:\n",
        "    \"\"\"\n",
        "    Download the entire conversation history from memory store and save it to a JSON file.\n",
        "    \"\"\"\n",
        "    memories = store.search((user_id, \"memories\"))\n",
        "    conversation_history = [m.value.get(\"memory\") for m in memories if \"memory\" in m.value]\n",
        "    filename = f\"{user_id}_conversation_history.json\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(conversation_history, f, indent=2)\n",
        "    return f\"Conversation history saved to {filename}\"\n",
        "\n",
        "# Download the conversation history\n",
        "download_conversation_history(user_id, in_memory_store)\n",
        "\n",
        "# Print the conversation history\n",
        "with open(f\"{user_id}_conversation_history.json\", \"r\") as f:\n",
        "    conversation_history = json.load(f)\n",
        "    print(\"Conversation History:\")\n",
        "    print(json.dumps(conversation_history, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xgiL2CJRJYJ"
      },
      "source": [
        "## App Development"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTL9JhvhRJYJ"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AqPpud8wRJYJ"
      },
      "outputs": [],
      "source": [
        "from io import StringIO\n",
        "import sys\n",
        "\n",
        "import os\n",
        "from huggingface_hub import login\n",
        "import gradio as gr\n",
        "import json\n",
        "import hashlib\n",
        "import uuid\n",
        "import logging\n",
        "from typing import List, Dict, Sequence, TypedDict\n",
        "\n",
        "# LangChain & related imports\n",
        "from langchain_core.tools import tool, StructuredTool\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "# Extraction for Documents\n",
        "from langchain_docling.loader import ExportType\n",
        "from langchain_docling import DoclingLoader\n",
        "from docling.chunking import HybridChunker\n",
        "\n",
        "# Extraction for HTML\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.prebuilt import InjectedStore\n",
        "from langgraph.store.base import BaseStore\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain.embeddings import init_embeddings\n",
        "from langgraph.graph import StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langchain_core.messages import (\n",
        "    SystemMessage,\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    BaseMessage,\n",
        "    ToolMessage,\n",
        ")\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get(\"HF_TOKEN\")\n",
        "login(token=HF_TOKEN)\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "# HF_TOKEN = os.getenv(\"HF_TOKEN\")  # Read from environment variable\n",
        "# if HF_TOKEN:\n",
        "#     login(token=HF_TOKEN)  # Log in to Hugging Face Hub\n",
        "# else:\n",
        "#     print(\"Warning: HF_TOKEN not found in environment variables.\")\n",
        "\n",
        "# GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")  # Read from environment variable\n",
        "\n",
        "# =============================================================================\n",
        "# Configurations\n",
        "# =============================================================================\n",
        "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "\n",
        "# Initialize the in-memory store for conversation threads\n",
        "in_memory_store = InMemoryStore(\n",
        "    index={\n",
        "        \"embed\": init_embeddings(\"huggingface:sentence-transformers/all-MiniLM-L6-v2\"),\n",
        "        \"dims\": 384,\n",
        "    }\n",
        ")\n",
        "checkpointer = MemorySaver()\n",
        "\n",
        "# Global config for user ID and conversation thread ID\n",
        "config = {\n",
        "    \"configurable\": {\n",
        "        \"user_id\": \"user_1\",  # Hard-coded user ID\n",
        "        \"thread_id\": 0\n",
        "    }\n",
        "}\n",
        "\n",
        "###############################################################################\n",
        "# Document Extraction and Utility Functions\n",
        "###############################################################################\n",
        "\n",
        "def extract_documents(doc_path: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Recursively collects all file paths from folder 'doc_path'.\n",
        "    \"\"\"\n",
        "    extracted_docs = []\n",
        "    for root, _, files in os.walk(doc_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            extracted_docs.append(file_path)\n",
        "    return extracted_docs\n",
        "\n",
        "\n",
        "def _generate_uuid(page_content: str) -> str:\n",
        "    \"\"\"Generate a UUID for a chunk of text using MD5 hashing.\"\"\"\n",
        "    md5_hash = hashlib.md5(page_content.encode()).hexdigest()\n",
        "    return str(uuid.UUID(md5_hash[0:32]))\n",
        "\n",
        "\n",
        "def load_file(file_path: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Load a file from the given path and return a list of Document objects.\n",
        "    \"\"\"\n",
        "    _documents = []\n",
        "    try:\n",
        "        loader = DoclingLoader(\n",
        "            file_path=file_path,\n",
        "            export_type=ExportType.DOC_CHUNKS,\n",
        "            chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
        "        )\n",
        "        docs = loader.load()\n",
        "        logger.info(f\"Total parsed doc-chunks: {len(docs)} from Source: {file_path}\")\n",
        "\n",
        "        for d in docs:\n",
        "            doc = Document(\n",
        "                page_content=d.page_content,\n",
        "                metadata={\n",
        "                    \"source\": file_path,\n",
        "                    \"doc_id\": _generate_uuid(d.page_content),\n",
        "                    \"source_type\": \"file\",\n",
        "                }\n",
        "            )\n",
        "            _documents.append(doc)\n",
        "        logger.info(f\"Total generated LangChain document chunks: {len(_documents)}\\n.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading file: {file_path}. Exception: {e}\\n.\")\n",
        "\n",
        "    return _documents\n",
        "\n",
        "\n",
        "def load_files_from_folder(doc_path: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Load documents from the given folder path and return a list of Document objects.\n",
        "    \"\"\"\n",
        "    _documents = []\n",
        "    extracted_docs = extract_documents(doc_path)\n",
        "    for file_path in extracted_docs:\n",
        "        _documents.extend(load_file(file_path))\n",
        "    return _documents\n",
        "\n",
        "\n",
        "def ensure_scheme(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    if not parsed_url.scheme:\n",
        "        return 'http://' + url\n",
        "    return url\n",
        "\n",
        "\n",
        "def extract_html(urls):\n",
        "    \"\"\"\n",
        "    Extract text from the HTML content of web pages.\n",
        "    \"\"\"\n",
        "    if isinstance(urls, str):\n",
        "        urls = [urls]\n",
        "    web_paths = [ensure_scheme(u) for u in urls]\n",
        "    loader = WebBaseLoader(web_paths)\n",
        "    loader.requests_per_second = 1\n",
        "    docs = loader.load()\n",
        "    _documents = []\n",
        "    for doc in docs:\n",
        "        cleaned = doc.page_content.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
        "        cleaned = cleaned.replace(\"\\t\", \" \").replace(\"  \", \" \").replace(\"   \", \" \")\n",
        "        web_doc = Document(\n",
        "            page_content=cleaned,\n",
        "            metadata={\n",
        "                \"source\": doc.metadata.get(\"source\"),\n",
        "                \"doc_id\": _generate_uuid(cleaned),\n",
        "                \"source_type\": \"web\"\n",
        "            }\n",
        "        )\n",
        "        _documents.append(web_doc)\n",
        "    return _documents\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# Vector Stores and Document Splitting\n",
        "###############################################################################\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=EMBED_MODEL_ID)\n",
        "\n",
        "general_vs = Chroma(\n",
        "    collection_name=\"general_vstore\",\n",
        "    embedding_function=embedding_model,\n",
        "    persist_directory=\"./general_db\"\n",
        ")\n",
        "mcq_vs = Chroma(\n",
        "    collection_name=\"mcq_vstore\",\n",
        "    embedding_function=embedding_model,\n",
        "    persist_directory=\"./mcq_db\"\n",
        ")\n",
        "in_memory_vs = Chroma(\n",
        "    collection_name=\"in_memory_vstore\",\n",
        "    embedding_function=embedding_model\n",
        ")\n",
        "\n",
        "\n",
        "def split_text_into_chunks(docs: List[Document]) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Splits Documents into smaller text chunks for better embedding coverage.\n",
        "    \"\"\"\n",
        "    if not docs:\n",
        "        return []\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000,\n",
        "        chunk_overlap=200,\n",
        "        add_start_index=True\n",
        "    )\n",
        "    chunked_docs = splitter.split_documents(docs)\n",
        "    return chunked_docs\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# Retrieval Tools (MCQ, general, in-memory, web extraction, ensemble)\n",
        "###############################################################################\n",
        "class MCQRetrievalTool(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"Search topic.\")\n",
        "    k: int = Field(2, title=\"Number of Results\", description=\"Number of question sets to retrieve.\")\n",
        "\n",
        "\n",
        "def mcq_retriever(input: str, k: int = 2) -> Dict[str, str]:\n",
        "    docs_func = mcq_vs.as_retriever(\n",
        "        search_type=\"similarity\",\n",
        "        search_kwargs={'k': k, 'filter': {\"source_type\": {\"$eq\": \"mcq_question\"}}},\n",
        "    )\n",
        "    docs_qns = docs_func.invoke(input, k=k)\n",
        "    doc_ids = [d.metadata.get(\"doc_id\") for d in docs_qns if \"doc_id\" in d.metadata]\n",
        "    docs = mcq_vs.get(where={'doc_id': {\"$in\": doc_ids}})\n",
        "    qns_list = {}\n",
        "    for i, d in enumerate(docs['metadatas']):\n",
        "        qns_list[d['source'] + \" \" + d['source_type']] = docs['documents'][i]\n",
        "    return qns_list\n",
        "\n",
        "\n",
        "mcq_retriever_tool = StructuredTool.from_function(\n",
        "    func=mcq_retriever,\n",
        "    name=\"MCQ Retrieval Tool\",\n",
        "    description=(\n",
        "    \"\"\"\n",
        "    Use this tool to retrieve MCQ questions set when Human asks to generate a quiz related to a topic.\n",
        "    DO NOT GIVE THE ANSWERS to Human before Human has answered all the questions.\n",
        "\n",
        "    If Human give answers for questions you do not know, SAY you do not have the questions for the answer\n",
        "    and ASK if the Human want you to generate a new quiz and then SAVE THE QUIZ with Summary Tool before ending the conversation.\n",
        "\n",
        "\n",
        "    Input must be a JSON string with the schema:\n",
        "        - input (str): The search topic to retrieve MCQ questions set related to the topic.\n",
        "        - k (int): Number of question set to retrieve.\n",
        "        Example usage: input='What is AI?', k=5\n",
        "\n",
        "    Returns:\n",
        "    - A dict of MCQ questions:\n",
        "    Key: 'metadata of question' e.g. './Documents/mcq/mcq.csv_Qn31 mcq_question' with suffix ['question', 'answer', 'answer_reason', 'options', 'wrong_options_reason']\n",
        "    Value: Text Content\n",
        "\n",
        "    \"\"\"\n",
        "    ),\n",
        "    args_schema=MCQRetrievalTool,\n",
        "    response_format=\"content\",\n",
        "    return_direct=False,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "\n",
        "class GenRetrievalTool(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"User query.\")\n",
        "    k: int = Field(2, title=\"Number of Results\", description=\"Number of documents to retrieve.\")\n",
        "\n",
        "\n",
        "def gen_retriever(input: str, k: int = 2) -> List[str]:\n",
        "    docs_func = general_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={'k': k, 'lambda_mult': 0.25}\n",
        "    )\n",
        "    docs = docs_func.invoke(input, k=k)\n",
        "    return [d.page_content for d in docs]\n",
        "\n",
        "\n",
        "general_retriever_tool = StructuredTool.from_function(\n",
        "    func=gen_retriever,\n",
        "    name=\"Assistant References Retrieval Tool\",\n",
        "    description = (\n",
        "    \"\"\"\n",
        "    Use this tool to retrieve reference information from Assistant reference database for Human queries related to a topic or\n",
        "    and when Human asked to generate guides to learn or study about a topic.\n",
        "\n",
        "    Input must be a JSON string with the schema:\n",
        "        - input (str): The user query.\n",
        "        - k (int): Number of results to retrieve.\n",
        "        Example usage: input='What is AI?', k=5\n",
        "    Returns:\n",
        "    - A list of retrieved document's content string.\n",
        "    \"\"\"\n",
        "    ),\n",
        "    args_schema=GenRetrievalTool,\n",
        "    response_format=\"content\",\n",
        "    return_direct=False,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "\n",
        "class InMemoryRetrievalTool(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"User query.\")\n",
        "    k: int = Field(2, title=\"Number of Results\", description=\"Number of documents to retrieve.\")\n",
        "\n",
        "\n",
        "def in_memory_retriever(input: str, k: int = 2) -> List[str]:\n",
        "    docs_func = in_memory_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={'k': k, 'lambda_mult': 0.25}\n",
        "    )\n",
        "    docs = docs_func.invoke(input, k=k)\n",
        "    return [d.page_content for d in docs]\n",
        "\n",
        "\n",
        "in_memory_retriever_tool = StructuredTool.from_function(\n",
        "    func=in_memory_retriever,\n",
        "    name=\"In-Memory Retrieval Tool\",\n",
        "    description = (\n",
        "    \"\"\"\n",
        "    Use this tool when Human ask Assistant to retrieve information from documents that Human has uploaded.\n",
        "\n",
        "    Input must be a JSON string with the schema:\n",
        "        - input (str): The user query.\n",
        "        - k (int): Number of results to retrieve.\n",
        "    \"\"\"\n",
        "    ),\n",
        "    args_schema=InMemoryRetrievalTool,\n",
        "    response_format=\"content\",\n",
        "    return_direct=False,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "\n",
        "class WebExtractionRequest(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"Search text.\")\n",
        "    url: str = Field(..., title=\"url\", description=\"Web URL(s) to extract content from. If multiple URLs, separate them with a comma.\")\n",
        "    k: int = Field(5, title=\"Number of Results\", description=\"Number of documents to retrieve.\")\n",
        "\n",
        "\n",
        "def extract_web_path_tool(input: str, url: str, k: int = 5) -> List[str]:\n",
        "    if isinstance(url, str):\n",
        "        url = [url]\n",
        "    html_docs = extract_html(url)\n",
        "    if not html_docs:\n",
        "        return [f\"No content extracted from {url}.\"]\n",
        "    chunked_texts = split_text_into_chunks(html_docs)\n",
        "    in_memory_vs.add_documents(chunked_texts)\n",
        "    docs_func = in_memory_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={'k': k, 'lambda_mult': 0.25, 'filter': {\"source\": {\"$in\": url}}},\n",
        "    )\n",
        "    docs = docs_func.invoke(input, k=k)\n",
        "    return [d.page_content for d in docs]\n",
        "\n",
        "\n",
        "web_extraction_tool = StructuredTool.from_function(\n",
        "    func=extract_web_path_tool,\n",
        "    name=\"Web Extraction Tool\",\n",
        "    description = (\n",
        "        \"Assistant should use this tool to extract content from web URLs based on user's input, \"\n",
        "        \"Web extraction is initially load into database and then return k: Number of results to retrieve\"\n",
        "    ),\n",
        "    args_schema=WebExtractionRequest,\n",
        "    return_direct=False,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "\n",
        "class EnsembleRetrievalTool(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"User query.\")\n",
        "    k: int = Field(5, title=\"Number of Results\", description=\"Number of results.\")\n",
        "\n",
        "\n",
        "def ensemble_retriever(input: str, k: int = 5) -> List[str]:\n",
        "    general_retrieval = general_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={'k': k, 'lambda_mult': 0.25}\n",
        "    )\n",
        "    in_memory_retrieval = in_memory_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={'k': k, 'lambda_mult': 0.25}\n",
        "    )\n",
        "    ensemble = EnsembleRetriever(\n",
        "        retrievers=[general_retrieval, in_memory_retrieval],\n",
        "        weights=[0.5, 0.5]\n",
        "    )\n",
        "    docs = ensemble.invoke(input)\n",
        "    return [d.page_content for d in docs]\n",
        "\n",
        "\n",
        "ensemble_retriever_tool = StructuredTool.from_function(\n",
        "    func=ensemble_retriever,\n",
        "    name=\"Ensemble Retriever Tool\",\n",
        "    description = (\n",
        "    \"\"\"\n",
        "    Use this tool to retrieve information from reference database and\n",
        "    extraction of documents that Human has uploaded.\n",
        "\n",
        "    Input must be a JSON string with the schema:\n",
        "        - input (str): The user query.\n",
        "        - k (int): Number of results to retrieve.\n",
        "    \"\"\"\n",
        "    ),\n",
        "    args_schema=EnsembleRetrievalTool,\n",
        "    response_format=\"content\",\n",
        "    return_direct=False\n",
        ")\n",
        "\n",
        "###############################################################################\n",
        "# LLM Model Setup\n",
        "###############################################################################\n",
        "\n",
        "TEMPERATURE = 0.5\n",
        "# model = ChatOpenAI(\n",
        "#     model=\"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
        "#     temperature=TEMPERATURE,\n",
        "#     timeout=None,\n",
        "#     max_retries=2,\n",
        "#     api_key=\"not_required\",\n",
        "#     base_url=\"http://localhost:8000/v1\",\n",
        "# )\n",
        "\n",
        "model = ChatGroq(\n",
        "    model_name=\"deepseek-r1-distill-llama-70b\",\n",
        "    temperature=TEMPERATURE,\n",
        "    api_key=GROQ_API_KEY,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "###############################################################################\n",
        "# LangGraph Setup\n",
        "###############################################################################\n",
        "\n",
        "# Define messages state\n",
        "class MessagesState(TypedDict):\n",
        "    messages: Sequence[BaseMessage]\n",
        "\n",
        "\n",
        "def save_memory(summary_text: str, *, config, store: BaseStore) -> str:\n",
        "    user_id = config.get(\"configurable\", {}).get(\"user_id\")\n",
        "    thread_id = config.get(\"configurable\", {}).get(\"thread_id\")\n",
        "    namespace = (user_id, \"memories\")\n",
        "    memory_id = thread_id\n",
        "    store.put(namespace, memory_id, {\"memory\": summary_text})\n",
        "    return f\"Saved to memory key: {memory_id}\"\n",
        "\n",
        "\n",
        "def update_memory(state: MessagesState, config, store: BaseStore):\n",
        "    messages = state[\"messages\"]\n",
        "    messages_dict = [{\"role\": msg.type, \"content\": msg.content} for msg in messages]\n",
        "    user_id = config.get(\"configurable\", {}).get(\"user_id\")\n",
        "    thread_id = config.get(\"configurable\", {}).get(\"thread_id\")\n",
        "    namespace = (user_id, \"memories\")\n",
        "    memory_id = f\"{thread_id}\"\n",
        "    store.put(namespace, memory_id, {\"memory\": messages_dict})\n",
        "    return f\"Saved to memory key: {memory_id}\"\n",
        "\n",
        "\n",
        "class RecallMemory(BaseModel):\n",
        "    query_text: str = Field(..., title=\"Search Text\", description=\"The text to search.\")\n",
        "    k: int = Field(5, title=\"Number of Results\", description=\"Number of results.\")\n",
        "\n",
        "\n",
        "def recall_memory(query_text: str, k: int = 5) -> str:\n",
        "    user_id = config.get(\"configurable\", {}).get(\"user_id\")\n",
        "    memories = [\n",
        "        m.value[\"memory\"] for m in in_memory_store.search((user_id, \"memories\"), query=query_text, limit=k)\n",
        "        if \"memory\" in m.value\n",
        "    ]\n",
        "    return f\"User memories: {memories}\"\n",
        "\n",
        "\n",
        "recall_memory_tool = StructuredTool.from_function(\n",
        "    func=recall_memory,\n",
        "    name=\"Recall Memory Tool\",\n",
        "    description=\"Retrieve user memories relevant to the query.\",\n",
        "    args_schema=RecallMemory,\n",
        "    response_format=\"content\",\n",
        "    return_direct=False,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "\n",
        "class SummariseConversation(BaseModel):\n",
        "    summary_text: str = Field(..., title=\"text\", description=\"A summary of entire conversation.\")\n",
        "\n",
        "\n",
        "def summarise_node(summary_text: str):\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    current_thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "    new_thread_id = str(int(current_thread_id) + 1)\n",
        "    config_for_saving = {\n",
        "        \"configurable\": {\n",
        "            \"user_id\": user_id,\n",
        "            \"thread_id\": new_thread_id\n",
        "        }\n",
        "    }\n",
        "    _ = save_memory(summary_text, config=config_for_saving, store=in_memory_store)\n",
        "\n",
        "\n",
        "summarise_tool = StructuredTool.from_function(\n",
        "    func=summarise_node,\n",
        "    name=\"Summary Tool\",\n",
        "    description=\"\"\"\n",
        "      Summarize the current conversation in no more than\n",
        "      1000 words. Also retain any unanswered quiz questions along with\n",
        "      your internal answers so the next conversation thread can continue.\n",
        "      Do not reveal solutions to the user yet. Use this tool to save\n",
        "      the current conversation to memory and then end the conversation.\n",
        "      \"\"\",\n",
        "    args_schema=SummariseConversation,\n",
        "    response_format=\"content\",\n",
        "    return_direct=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "tools = [\n",
        "    mcq_retriever_tool,\n",
        "    web_extraction_tool,\n",
        "    ensemble_retriever_tool,\n",
        "    general_retriever_tool,\n",
        "    in_memory_retriever_tool,\n",
        "    recall_memory_tool,\n",
        "    summarise_tool,\n",
        "]\n",
        "\n",
        "llm_with_tools = model.bind_tools(tools)\n",
        "\n",
        "\n",
        "def call_model(state: MessagesState, config):\n",
        "    \"\"\"\n",
        "    The main agent node that calls the LLM with the user + system messages.\n",
        "    \"\"\"\n",
        "    messages = []\n",
        "    for m in state[\"messages\"]:\n",
        "        if isinstance(m, dict):\n",
        "            messages.append(HumanMessage(content=m.get(\"content\", \"\"), role=m.get(\"role\", \"user\")))\n",
        "        else:\n",
        "            messages.append(m)\n",
        "\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(MessagesState)\n",
        "graph_builder.add_node(\"agent\", call_model)\n",
        "tool_node = ToolNode(tools=tools)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "graph_builder.set_entry_point(\"agent\")\n",
        "graph_builder.add_conditional_edges(\"agent\", tools_condition)\n",
        "graph_builder.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "graph = graph_builder.compile(checkpointer=checkpointer, store=in_memory_store)\n",
        "\n",
        "###############################################################################\n",
        "# Public Functions for the Gradio App\n",
        "###############################################################################\n",
        "\n",
        "def upload_documents(doc_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Load documents from the given folder path and upload into in-memory vector store.\n",
        "    \"\"\"\n",
        "    documents = load_files_from_folder(doc_path)\n",
        "    if not documents:\n",
        "        return f\"No documents found in {doc_path}.\"\n",
        "    chunked_texts = split_text_into_chunks(documents)\n",
        "    in_memory_vs.add_documents(chunked_texts)\n",
        "    return f\"Uploaded {len(documents)} documents from {doc_path} to in-memory vector store.\"\n",
        "\n",
        "\n",
        "\n",
        "def download_conversation_history(user_id: str, store: BaseStore = in_memory_store) -> str:\n",
        "    \"\"\"\n",
        "    Download the entire conversation history from memory store and save it to a JSON file.\n",
        "    \"\"\"\n",
        "    memories = store.search((user_id, \"memories\"))\n",
        "    conversation_history = [m.value.get(\"memory\") for m in memories if \"memory\" in m.value]\n",
        "    filename = f\"{user_id}_conversation_history.json\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(conversation_history, f, indent=2)\n",
        "    return f\"Conversation history saved to {filename}\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWELX-uoRJYJ"
      },
      "source": [
        "### Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaFl4Ke2RJYJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "###############################################################################\n",
        "# Gradio App\n",
        "###############################################################################\n",
        "\n",
        "# Function for user to input their query and system prompt to the agent\n",
        "def submit_query(user_query, temperature):\n",
        "    \"\"\"\n",
        "    Triggered when the user clicks the submit icon.\n",
        "    - user_query -> str\n",
        "    - temperature -> float\n",
        "    \"\"\"\n",
        "    # 'user_1' from the config in utils.\n",
        "    USER_ID = config[\"configurable\"][\"user_id\"]\n",
        "    # Get last thread_id\n",
        "    last_thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "    thread_id = str(int(last_thread_id) + 1)\n",
        "\n",
        "    # Update the config with the new thread_id\n",
        "    config = {\"configurable\": {\"thread_id\": thread_id, \"user_id\": USER_ID}}\n",
        "\n",
        "    # 1) Call query_agent as before to get the streaming generator.\n",
        "    events = graph.stream(\n",
        "        {\n",
        "            \"messages\": [\n",
        "                #{\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_query}\n",
        "            ]\n",
        "        },\n",
        "        config,  # user_id, thread_id, etc.\n",
        "        stream_mode=\"values\",\n",
        "    )\n",
        "\n",
        "    # 2) We'll capture each message's pretty_print() into a list for the console.\n",
        "    from io import StringIO\n",
        "    import sys\n",
        "\n",
        "    message_stream = []\n",
        "    final_response = \"\"\n",
        "    for event in events:\n",
        "        # Each event is a dict with \"messages\" as a list of BaseMessage objects.\n",
        "        for msg in event[\"messages\"]:\n",
        "            # If for some reason the msg doesn't support pretty_print, we fallback to .content\n",
        "            captured_output = StringIO()\n",
        "            original_stdout = sys.stdout\n",
        "            try:\n",
        "                sys.stdout = captured_output\n",
        "                # If it's an AI/Tool message with pretty_print(), call it:\n",
        "                if hasattr(msg, \"pretty_print\"):\n",
        "                    msg.pretty_print()\n",
        "                else:\n",
        "                    # Otherwise, just print its content\n",
        "                    print(msg.content)\n",
        "            finally:\n",
        "                sys.stdout = original_stdout\n",
        "\n",
        "            # Store the captured text into our message_stream\n",
        "            pretty_text = captured_output.getvalue()\n",
        "            message_stream.append(pretty_text.strip())\n",
        "\n",
        "        # If this event had at least one message, the last is presumably the LLM's response\n",
        "        if event[\"messages\"]:\n",
        "            final_response = event[\"messages\"][-1].content\n",
        "\n",
        "    update_memory(event, config, store=in_memory_store) # Update Memory\n",
        "\n",
        "    # 3) Return final response for the chatbot's main window\n",
        "    #    and the entire stream for the console output.\n",
        "    return final_response, \"\\n\".join(message_stream)\n",
        "\n",
        "\n",
        "def process_upload(files_list):\n",
        "    \"\"\"\n",
        "    Triggered when the user clicks the folder icon to upload documents.\n",
        "    Receives a list of Gradio file objects.\n",
        "    \"\"\"\n",
        "    if not files_list:\n",
        "        return \"No files to upload.\"\n",
        "\n",
        "    temp_folder = \"./uploaded_files\"\n",
        "    os.makedirs(temp_folder, exist_ok=True)\n",
        "\n",
        "    for f in files_list:\n",
        "        file_path = os.path.join(temp_folder, f.name)\n",
        "        with open(file_path, \"wb\") as outfile:\n",
        "            outfile.write(f.read())\n",
        "\n",
        "    result = upload_documents(temp_folder)\n",
        "    return result\n",
        "\n",
        "def toggle_advanced_settings(show_advanced):\n",
        "    \"\"\"\n",
        "    Toggles the visibility of the advanced settings panel.\n",
        "    \"\"\"\n",
        "    return gr.update(visible=show_advanced)\n",
        "\n",
        "def generate_json_history():\n",
        "    \"\"\"\n",
        "    Generates a conversation-history JSON file for the user.\n",
        "    \"\"\"\n",
        "    result = download_conversation_history(USER_ID)\n",
        "    return result\n",
        "\n",
        "# ============================================================================\n",
        "\n",
        "with gr.Blocks() as AI_Tutor:\n",
        "    gr.Markdown(\"# AI Tutor Chatbot (Gradio App)\")\n",
        "\n",
        "    # Main chat window:\n",
        "    chatbot = gr.Chatbot(label=\"Chat Window\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1, min_width=50):\n",
        "            file_upload = gr.Files(\n",
        "                file_types=[\"pdf\", \"ppt\", \"pptx\", \"doc\", \"docx\", \"txt\"],\n",
        "                file_count=\"multiple\",\n",
        "                label=\"Upload\"\n",
        "            )\n",
        "            upload_button = gr.Button(\n",
        "                \"📁\",\n",
        "                elem_id=\"upload_icon\"\n",
        "            )\n",
        "        with gr.Column(scale=4):\n",
        "            user_input = gr.Textbox(\n",
        "            lines=5,\n",
        "            max_lines=5,\n",
        "            label=\"Type your query here:\",\n",
        "            placeholder=\"Enter your question...\",\n",
        "            show_label=False,\n",
        "            elem_id=\"user_query_box\"\n",
        "          )\n",
        "\n",
        "            submit_button = gr.Button(\n",
        "                \"➡️\",\n",
        "                elem_id=\"submit_icon\"\n",
        "            )\n",
        "\n",
        "\n",
        "    # Toggle advanced settings:\n",
        "    advanced_toggle = gr.Checkbox(\n",
        "        label=\"Show Advanced Settings\",\n",
        "        value=False\n",
        "    )\n",
        "\n",
        "\n",
        "    with gr.Column(visible=False) as advanced_panel:\n",
        "\n",
        "        console_output = gr.Textbox(\n",
        "        label=\"Console Window (Message Stream)\",\n",
        "        interactive=False,\n",
        "        lines=10,\n",
        "        placeholder=\"Stream of messages...\"\n",
        "        )\n",
        "\n",
        "        temp_slider = gr.Slider(\n",
        "            minimum=0.0,\n",
        "            maximum=1.0,\n",
        "            value=0.5,\n",
        "            step=0.1,\n",
        "            label=\"Temperature\"\n",
        "        )\n",
        "\n",
        "        json_button = gr.Button(\n",
        "            \"Download Conversation History\",\n",
        "            variant=\"secondary\"\n",
        "        )\n",
        "        json_result = gr.Textbox(\n",
        "            label=\"JSON Export Info\",\n",
        "            interactive=False,\n",
        "            lines=10,\n",
        "        )\n",
        "\n",
        "    # Define interactions\n",
        "    advanced_toggle.change(\n",
        "        fn=toggle_advanced_settings,\n",
        "        inputs=[advanced_toggle],\n",
        "        outputs=[advanced_panel]\n",
        "    )\n",
        "\n",
        "    upload_button.click(\n",
        "        fn=process_upload,\n",
        "        inputs=[file_upload],\n",
        "        outputs=[console_output]\n",
        "    )\n",
        "\n",
        "    submit_button.click(\n",
        "        fn=submit_query,\n",
        "        inputs=[user_input, temp_slider],\n",
        "        outputs=[chatbot, console_output]\n",
        "    )\n",
        "\n",
        "    json_button.click(\n",
        "        fn=generate_json_history,\n",
        "        outputs=[json_result]\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ### Instructions:\n",
        "    1. Type your query in the textbox and click the submit icon on the right.\n",
        "    2. To upload documents for the chatbot to reference, select or drag your files and then click the folder icon.\n",
        "    3. For advanced settings (temperature and custom system prompt), enable the checkbox below.\n",
        "    4. You can download the conversation history anytime.\n",
        "    \"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    AI_Tutor.launch()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "KmeoL-_lcs8Y",
        "s_2h8tWUc9yA",
        "QNgX4ZVYrS8Z",
        "LuhaRfR6dLno"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "yourenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6afe1e6ac2e643f59eddd484f10368e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1549f73024f41a3aff059cdc23facdd",
              "IPY_MODEL_47f9e15ca49c44ca88535f75f10a4b50",
              "IPY_MODEL_d0142f770cd848ee9c9e3f4d17495ed5"
            ],
            "layout": "IPY_MODEL_0c0dd17f179540dfb7a9a7c9b852eaf3"
          }
        },
        "d1549f73024f41a3aff059cdc23facdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de4e44deaa2840a6a5951f2211d68b21",
            "placeholder": "​",
            "style": "IPY_MODEL_2a85723232e841d08e2fe1e31dbac1a7",
            "value": "modules.json: 100%"
          }
        },
        "47f9e15ca49c44ca88535f75f10a4b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8739b7a267a48ab8c0a51b2630cc457",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee82235ac82c47ffa88fa6a1fade8e52",
            "value": 349
          }
        },
        "d0142f770cd848ee9c9e3f4d17495ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a16055e6e604c49b8f9e4f8722597ff",
            "placeholder": "​",
            "style": "IPY_MODEL_e7b490a3fdca466fa8c5f4b1a82eaec0",
            "value": " 349/349 [00:00&lt;00:00, 35.7kB/s]"
          }
        },
        "0c0dd17f179540dfb7a9a7c9b852eaf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de4e44deaa2840a6a5951f2211d68b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a85723232e841d08e2fe1e31dbac1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8739b7a267a48ab8c0a51b2630cc457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee82235ac82c47ffa88fa6a1fade8e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a16055e6e604c49b8f9e4f8722597ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7b490a3fdca466fa8c5f4b1a82eaec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f04899fa87b948b3b0158c7856800736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_829deb1aa5fc4e62b1ba01530b4c9243",
              "IPY_MODEL_88852e7e97f744109748324b1fc2b8e0",
              "IPY_MODEL_a192016aebd943b8b1b44973248b50d5"
            ],
            "layout": "IPY_MODEL_ddfc394e88ee4f87a5df986ccbc6b344"
          }
        },
        "829deb1aa5fc4e62b1ba01530b4c9243": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f83da10809fa48c79d40da1555ecf696",
            "placeholder": "​",
            "style": "IPY_MODEL_b0f234845f514e3ab7dcaf5dea36134b",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "88852e7e97f744109748324b1fc2b8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2694f77db7dd402a8382f5ebd2ed3010",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_071a9e5fe8284a4b857e6f489da1037d",
            "value": 116
          }
        },
        "a192016aebd943b8b1b44973248b50d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5b6b41ea8b54409ac5886c0ce698683",
            "placeholder": "​",
            "style": "IPY_MODEL_4ad1c346a498430ea46f49cbe06b0e47",
            "value": " 116/116 [00:00&lt;00:00, 10.8kB/s]"
          }
        },
        "ddfc394e88ee4f87a5df986ccbc6b344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f83da10809fa48c79d40da1555ecf696": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0f234845f514e3ab7dcaf5dea36134b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2694f77db7dd402a8382f5ebd2ed3010": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "071a9e5fe8284a4b857e6f489da1037d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5b6b41ea8b54409ac5886c0ce698683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ad1c346a498430ea46f49cbe06b0e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1bc37bd46c44a23877daf1f0e5981a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63d7a619b96c4af59f8706bc499afc1a",
              "IPY_MODEL_bf5a761df0ed4e40aa0610a7b9148485",
              "IPY_MODEL_ac789c364c44400d823d77daa0265ec6"
            ],
            "layout": "IPY_MODEL_3be7499afecc42498af58e9fa5b040c3"
          }
        },
        "63d7a619b96c4af59f8706bc499afc1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53e87132a5ea4ee3948dde0ff000c8c0",
            "placeholder": "​",
            "style": "IPY_MODEL_35c367606a5c400f93105a4cfa28c63f",
            "value": "README.md: 100%"
          }
        },
        "bf5a761df0ed4e40aa0610a7b9148485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddab6fb65ae948a0b8e2a88db7532342",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ce70e7b7a164163a5c1b53495ed8408",
            "value": 10659
          }
        },
        "ac789c364c44400d823d77daa0265ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8d1ed04fb964b3bb29633c7860a8ddd",
            "placeholder": "​",
            "style": "IPY_MODEL_41a1cc22eb504954adaa6bc365ababdf",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 878kB/s]"
          }
        },
        "3be7499afecc42498af58e9fa5b040c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53e87132a5ea4ee3948dde0ff000c8c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35c367606a5c400f93105a4cfa28c63f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddab6fb65ae948a0b8e2a88db7532342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce70e7b7a164163a5c1b53495ed8408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8d1ed04fb964b3bb29633c7860a8ddd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41a1cc22eb504954adaa6bc365ababdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c2c37f9c9c147c5bc17b9b08c408ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_611265e20d7f48faba589a69bb8c77d2",
              "IPY_MODEL_028fbc9a98c44f8a97a04ec4db28b2ff",
              "IPY_MODEL_38942f9de2524362adaaf70d3f2b391e"
            ],
            "layout": "IPY_MODEL_9449caaa34a44ae59f8e3b03bd5599bf"
          }
        },
        "611265e20d7f48faba589a69bb8c77d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2f69ab506fd4935abffa618c408e823",
            "placeholder": "​",
            "style": "IPY_MODEL_8b75801f080a4260a0e9158feb124d3d",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "028fbc9a98c44f8a97a04ec4db28b2ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d7189377f17442b96671c9a06a275ea",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5854c2dd1714cf6bb9c877c95ea0ce6",
            "value": 53
          }
        },
        "38942f9de2524362adaaf70d3f2b391e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_215d670cf53f40b8b6b1812fdd091307",
            "placeholder": "​",
            "style": "IPY_MODEL_f5480b0158404681a84ca60480e6d390",
            "value": " 53.0/53.0 [00:00&lt;00:00, 5.09kB/s]"
          }
        },
        "9449caaa34a44ae59f8e3b03bd5599bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2f69ab506fd4935abffa618c408e823": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b75801f080a4260a0e9158feb124d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d7189377f17442b96671c9a06a275ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5854c2dd1714cf6bb9c877c95ea0ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "215d670cf53f40b8b6b1812fdd091307": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5480b0158404681a84ca60480e6d390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93bf6000677f4ffea642ab7cddb6763e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8aa9bc3b7916477f94c5ef7834960416",
              "IPY_MODEL_5c4b0210e46040b88c7cfbbdec0c3a19",
              "IPY_MODEL_2d8562546ae74aa9bafc4b915051ef0d"
            ],
            "layout": "IPY_MODEL_9cd2b020af4648f8a740812bd51a57c4"
          }
        },
        "8aa9bc3b7916477f94c5ef7834960416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_347c084ab38e407c8437de8f5907bceb",
            "placeholder": "​",
            "style": "IPY_MODEL_a2a4ba7e868a4d489017c8c22a51cf75",
            "value": "config.json: 100%"
          }
        },
        "5c4b0210e46040b88c7cfbbdec0c3a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8089128cb7f44ae3ba6bccd97ad3e068",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48ec3ef7665e472395cebc00db2102f5",
            "value": 612
          }
        },
        "2d8562546ae74aa9bafc4b915051ef0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d2ec4f5e6ad4c75894baa88b4dd0b3d",
            "placeholder": "​",
            "style": "IPY_MODEL_cc38a5a56e3f4d65a57eb06657422268",
            "value": " 612/612 [00:00&lt;00:00, 48.2kB/s]"
          }
        },
        "9cd2b020af4648f8a740812bd51a57c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "347c084ab38e407c8437de8f5907bceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2a4ba7e868a4d489017c8c22a51cf75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8089128cb7f44ae3ba6bccd97ad3e068": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48ec3ef7665e472395cebc00db2102f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d2ec4f5e6ad4c75894baa88b4dd0b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc38a5a56e3f4d65a57eb06657422268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75a7847ee65a42369a4703ef45563941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a162b8b521e14d42a473aff19719115f",
              "IPY_MODEL_ad44880e770b4f3ba1144446159679de",
              "IPY_MODEL_c51a4ae703f1462ebab2a4f85ed12690"
            ],
            "layout": "IPY_MODEL_6529c8033b754d8484bbc59f821554ad"
          }
        },
        "a162b8b521e14d42a473aff19719115f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef8922d6666c48889b956d9f351dbd7b",
            "placeholder": "​",
            "style": "IPY_MODEL_076bcd68ab4d46cc8c1f8cb36131b3ba",
            "value": "model.safetensors: 100%"
          }
        },
        "ad44880e770b4f3ba1144446159679de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f17b731396994e99976848416c61b34c",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1abcaa4f6bc2477d9732952c9eadc0c0",
            "value": 90868376
          }
        },
        "c51a4ae703f1462ebab2a4f85ed12690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c069d611d594decb74a8875c6541da2",
            "placeholder": "​",
            "style": "IPY_MODEL_78f856c1184b4f4485673b83519cc811",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 224MB/s]"
          }
        },
        "6529c8033b754d8484bbc59f821554ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef8922d6666c48889b956d9f351dbd7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "076bcd68ab4d46cc8c1f8cb36131b3ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f17b731396994e99976848416c61b34c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1abcaa4f6bc2477d9732952c9eadc0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c069d611d594decb74a8875c6541da2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f856c1184b4f4485673b83519cc811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3ad73577f6345e2b182a98617796163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9f6b956ca8a46d39ffb16e3c1b887df",
              "IPY_MODEL_4e10d825c2744d41aca6deb318157d6a",
              "IPY_MODEL_48a22237d53244248af5418ca567767a"
            ],
            "layout": "IPY_MODEL_60ecd9753ec14f1687dd58268dda7980"
          }
        },
        "e9f6b956ca8a46d39ffb16e3c1b887df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3736e92b01084352914504b27e5847f8",
            "placeholder": "​",
            "style": "IPY_MODEL_3a19c4a112154e90b889f4e585cb6a0d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4e10d825c2744d41aca6deb318157d6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_321b903024e74f329719013e10926601",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b3d9bc841e74444aef8f3b13a469269",
            "value": 350
          }
        },
        "48a22237d53244248af5418ca567767a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7855bf0314524a9e974d3e495cef1dd0",
            "placeholder": "​",
            "style": "IPY_MODEL_94ab280109184ddca428a59a63ef6300",
            "value": " 350/350 [00:00&lt;00:00, 25.2kB/s]"
          }
        },
        "60ecd9753ec14f1687dd58268dda7980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3736e92b01084352914504b27e5847f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a19c4a112154e90b889f4e585cb6a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "321b903024e74f329719013e10926601": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b3d9bc841e74444aef8f3b13a469269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7855bf0314524a9e974d3e495cef1dd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94ab280109184ddca428a59a63ef6300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb0c6272e20d47d4b4558923738fe335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a65ddad54fcf44f0a3dde215b8e4bc5f",
              "IPY_MODEL_c4ef0a7ce7a04b09b28298cf1541ae4f",
              "IPY_MODEL_fff05f34c21a488f8c53904fe6571a6a"
            ],
            "layout": "IPY_MODEL_0bc88cb8510749c49be69eacd4ba709b"
          }
        },
        "a65ddad54fcf44f0a3dde215b8e4bc5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1313875850a4f40915c7a7c8e15c492",
            "placeholder": "​",
            "style": "IPY_MODEL_f6e83b0fd1104ca89544f54bae663a4e",
            "value": "vocab.txt: 100%"
          }
        },
        "c4ef0a7ce7a04b09b28298cf1541ae4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8a5e24932554f2a9fe26eb8cbaa3f51",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64b6d248f26040ccb4a27dd76a7e9755",
            "value": 231508
          }
        },
        "fff05f34c21a488f8c53904fe6571a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4a8f095092c44d593051c44f141436e",
            "placeholder": "​",
            "style": "IPY_MODEL_484cec3204e54b049b2006dbb9b3f4bd",
            "value": " 232k/232k [00:00&lt;00:00, 2.41MB/s]"
          }
        },
        "0bc88cb8510749c49be69eacd4ba709b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1313875850a4f40915c7a7c8e15c492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6e83b0fd1104ca89544f54bae663a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8a5e24932554f2a9fe26eb8cbaa3f51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64b6d248f26040ccb4a27dd76a7e9755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4a8f095092c44d593051c44f141436e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "484cec3204e54b049b2006dbb9b3f4bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f2b58239a4e484ab32b1129a860ca2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_844a6c3b6f8d4e5b9589b01d5bec4b6f",
              "IPY_MODEL_304c61f86d204d428fe54244076d5dcb",
              "IPY_MODEL_90da32e41b78436dadff45e332968111"
            ],
            "layout": "IPY_MODEL_204c1321920d4abeb9525a9369f209ad"
          }
        },
        "844a6c3b6f8d4e5b9589b01d5bec4b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea8b68ada4dc448da92077892e77ff4a",
            "placeholder": "​",
            "style": "IPY_MODEL_a3f55b2fdac5483cbe3ef13deeebbe6b",
            "value": "tokenizer.json: 100%"
          }
        },
        "304c61f86d204d428fe54244076d5dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0c40a99f31b43339e9a008d6c09b3d8",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f2051fe56d8444e8bb3fbdfc4fbf44a",
            "value": 466247
          }
        },
        "90da32e41b78436dadff45e332968111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e720cd14e1844a4da24d9d0b06383f2d",
            "placeholder": "​",
            "style": "IPY_MODEL_dc265d845ab84bfcab7df0b20f592827",
            "value": " 466k/466k [00:00&lt;00:00, 2.55MB/s]"
          }
        },
        "204c1321920d4abeb9525a9369f209ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea8b68ada4dc448da92077892e77ff4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f55b2fdac5483cbe3ef13deeebbe6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0c40a99f31b43339e9a008d6c09b3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f2051fe56d8444e8bb3fbdfc4fbf44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e720cd14e1844a4da24d9d0b06383f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc265d845ab84bfcab7df0b20f592827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f4a2a8c9ffa4695beb261ca5cbb1516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6a9ed06aac441009ba7b9e1ecd58a50",
              "IPY_MODEL_0569f34c935243c88985f213fe9957f0",
              "IPY_MODEL_c6627d0e9b2840d4bf5248fefe0e346a"
            ],
            "layout": "IPY_MODEL_311a4278152c4abfab3baa5eacab30f1"
          }
        },
        "d6a9ed06aac441009ba7b9e1ecd58a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c931eb29ff674932905793056fac3b7e",
            "placeholder": "​",
            "style": "IPY_MODEL_059510aa283a4a8490c2994037b3756c",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "0569f34c935243c88985f213fe9957f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d10fb30ef462485fb45a0c8bae52cae9",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_501d22f40f3e481ea80946d5ba8863eb",
            "value": 112
          }
        },
        "c6627d0e9b2840d4bf5248fefe0e346a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe3dca3e670f4f9992485f189d517838",
            "placeholder": "​",
            "style": "IPY_MODEL_35bd01b0f0564b598c2f3c9dca75d012",
            "value": " 112/112 [00:00&lt;00:00, 7.20kB/s]"
          }
        },
        "311a4278152c4abfab3baa5eacab30f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c931eb29ff674932905793056fac3b7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "059510aa283a4a8490c2994037b3756c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d10fb30ef462485fb45a0c8bae52cae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "501d22f40f3e481ea80946d5ba8863eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe3dca3e670f4f9992485f189d517838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35bd01b0f0564b598c2f3c9dca75d012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7439d8cc949144f191f5b5c488080ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08401b8dc90a4ff7879a78694f128843",
              "IPY_MODEL_3536f62921934f2aa4477c92e275d89e",
              "IPY_MODEL_42ced05be3ae4c769c35f4edd25597d1"
            ],
            "layout": "IPY_MODEL_633579902f644b9eb3039e0426a6c6ef"
          }
        },
        "08401b8dc90a4ff7879a78694f128843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67ad733a039b4a478e0997e81554dc53",
            "placeholder": "​",
            "style": "IPY_MODEL_79d4279601ec48e9853453a5c0028783",
            "value": "1_Pooling%2Fconfig.json: 100%"
          }
        },
        "3536f62921934f2aa4477c92e275d89e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b03095f53e8d4c80a82092c2aa16122a",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a4c84bb97734a06beb1bd6ed63cf8e1",
            "value": 190
          }
        },
        "42ced05be3ae4c769c35f4edd25597d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_979fe0dfc77a4149b997d0f1d78f57de",
            "placeholder": "​",
            "style": "IPY_MODEL_a29933c104a244779dc49979efbe6a4b",
            "value": " 190/190 [00:00&lt;00:00, 13.4kB/s]"
          }
        },
        "633579902f644b9eb3039e0426a6c6ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ad733a039b4a478e0997e81554dc53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79d4279601ec48e9853453a5c0028783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b03095f53e8d4c80a82092c2aa16122a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a4c84bb97734a06beb1bd6ed63cf8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "979fe0dfc77a4149b997d0f1d78f57de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a29933c104a244779dc49979efbe6a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}