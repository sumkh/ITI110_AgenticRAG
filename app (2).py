# -*- coding: utf-8 -*-
"""APP

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/155OHRPEk6kmlgVw5UBlUDV4SmluokuAZ

I still need some time in understand your code. Here is the Proof of concept for the Tutor AI UI.

Issues - able to load the document.
i am not clear on the Business work flow or To be process for Tutor AI.
"""

!pip install --upgrade gradio groq langchain langchain-core langchain-community \
    langchain-text-splitters langchain-docling langchain-chroma \
    langgraph chromadb langsmith llama-cpp-python \
    langchain_huggingface sentence_transformers langchain-groq
!pip install --upgrade langchain langchain-groq
!pip install pymupdf

import gradio as gr
import groq
from langchain_groq import ChatGroq
from langchain.schema import HumanMessage
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.docstore.document import Document
import os
import chardet
import fitz  # PyMuPDF for PDFs
import docx  # python-docx for Word files

# Set API Key (Ensure it's stored securely in an environment variable)
groq.api_key = os.getenv("GROQ_API_KEY", "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")

# Initialize Chat Model
chat_model = ChatGroq(model_name="llama3-8b-8192", api_key=groq.api_key)

# Initialize Embeddings
embedding_model = HuggingFaceEmbeddings()

# Initialize ChromaDB
vectorstore = Chroma(embedding_function=embedding_model)

# Function to handle chatbot interactions
def chat_with_groq(user_input):
    try:
        response = chat_model([HumanMessage(content=user_input)])
        return response.content
    except Exception as e:
        return f"Error: {str(e)}"

# Function to detect encoding safely
def detect_encoding(file_path):
    try:
        with open(file_path, "rb") as f:
            raw_data = f.read(4096)  # Read first 4KB for detection
            detected = chardet.detect(raw_data)
            encoding = detected["encoding"]

        return encoding if encoding else "utf-8"  # Default to UTF-8 if detection fails
    except Exception:
        return "utf-8"

# Function to extract text from PDF
def extract_text_from_pdf(pdf_path):
    try:
        doc = fitz.open(pdf_path)
        text = "\n".join([page.get_text("text") for page in doc])
        return text if text.strip() else "No extractable text found."
    except Exception as e:
        return f"Error extracting text from PDF: {str(e)}"

# Function to extract text from Word files (.docx)
def extract_text_from_docx(docx_path):
    try:
        doc = docx.Document(docx_path)
        text = "\n".join([para.text for para in doc.paragraphs])
        return text if text.strip() else "No extractable text found."
    except Exception as e:
        return f"Error extracting text from Word document: {str(e)}"

# Function to process documents safely
def process_document(file):
    try:
        file_extension = os.path.splitext(file.name)[-1].lower()

        if file_extension in [".png", ".jpg", ".jpeg"]:
            return f"Error: Images cannot be processed for text extraction."

        # Extract text based on file type
        if file_extension == ".pdf":
            content = extract_text_from_pdf(file.name)
        elif file_extension == ".docx":
            content = extract_text_from_docx(file.name)
        else:
            encoding = detect_encoding(file.name)
            with open(file.name, "r", encoding=encoding, errors="replace") as f:
                content = f.read()

        # Process text into chunks
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        documents = [Document(page_content=chunk) for chunk in text_splitter.split_text(content)]
        vectorstore.add_documents(documents)

        return f"Document processed successfully (File Type: {file_extension})"

    except Exception as e:
        return f"Error processing document: {str(e)}"

# Image URL
image_url = "https://img.freepik.com/premium-photo/little-girl-is-seen-sitting-front-laptop-computer-engaged-with-nearby-robot-robot-assistant-helping-child-with-homework-ai-generated_585735-12266.jpg"

# Gradio UI
with gr.Blocks() as demo:
    # Centered "AI Tutor" Title
    gr.HTML("<h2 style='text-align: center;'>AI Tutor</h2>")

    # Centered Image
    gr.HTML(f"""
        <div style="text-align: center; margin-bottom: 20px;">
            <img src="{image_url}" style="max-width: 60%; height: auto; border-radius: 10px; box-shadow: 0 4px 8px rgba(0,0,0,0.2);" />
        </div>
    """)

    with gr.Row():
        with gr.Column():
            user_input = gr.Textbox(label="Ask a question")
            chat_output = gr.Textbox(label="Response")
            submit_btn = gr.Button("Ask")
        with gr.Column():
            file_upload = gr.File(label="Upload a document")
            process_status = gr.Textbox(label="Processing Status", interactive=False)
            process_btn = gr.Button("Process Document")

    submit_btn.click(chat_with_groq, inputs=user_input, outputs=chat_output)
    process_btn.click(process_document, inputs=file_upload, outputs=process_status)

if __name__ == "__main__":
    demo.launch()