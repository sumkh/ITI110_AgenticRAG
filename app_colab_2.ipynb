{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumkh/ITI110_AgenticRAG/blob/main/app_colab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVfMT6l1cobl"
      },
      "source": [
        "## AI Tutor Chatbot (Version 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmeoL-_lcs8Y"
      },
      "source": [
        "### Setting Up - Install Requirements (Restart Session after installation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MkI4XOWxSXvl"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install langchain-groq huggingface_hub transformers langchain langchain_huggingface langgraph accelerate bitsandbytes langchain-core langchain-text-splitters langchain-community chromadb langchain-chroma langsmith docling langchain-docling sentence_transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_2h8tWUc9yA"
      },
      "source": [
        "### Load Packages and Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lzrhAq9cbbU",
        "outputId": "3c68b1af-00bc-4e79-cd46-a761e774e5ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-17 10:42:52--  https://github.com/sumkh/NYP_Dataset/raw/refs/heads/main/Documents.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/sumkh/NYP_Dataset/refs/heads/main/Documents.zip [following]\n",
            "--2025-02-17 10:42:53--  https://raw.githubusercontent.com/sumkh/NYP_Dataset/refs/heads/main/Documents.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18510909 (18M) [application/zip]\n",
            "Saving to: ‘Documents.zip’\n",
            "\n",
            "Documents.zip       100%[===================>]  17.65M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-02-17 10:42:54 (124 MB/s) - ‘Documents.zip’ saved [18510909/18510909]\n",
            "\n",
            "Archive:  /content/Documents.zip\n",
            "   creating: Documents/\n",
            "   creating: Documents/general/\n",
            "  inflating: Documents/general/Topic 1 Introduction to AI and AI on Azure.pdf  \n",
            "  inflating: Documents/general/deeplearningreview.docx  \n",
            "  inflating: Documents/general/slide_1.pptx  \n",
            "   creating: Documents/mcq/\n",
            "  inflating: Documents/mcq/mcq.csv   \n",
            "  inflating: Documents/mcq/mcq2.csv  \n",
            "   creating: general_db/\n",
            "   creating: general_db/0ab351f4-2d03-423f-bbf2-093d3b8eba80/\n",
            "  inflating: general_db/0ab351f4-2d03-423f-bbf2-093d3b8eba80/data_level0.bin  \n",
            "  inflating: general_db/0ab351f4-2d03-423f-bbf2-093d3b8eba80/header.bin  \n",
            "  inflating: general_db/0ab351f4-2d03-423f-bbf2-093d3b8eba80/length.bin  \n",
            " extracting: general_db/0ab351f4-2d03-423f-bbf2-093d3b8eba80/link_lists.bin  \n",
            "  inflating: general_db/chroma.sqlite3  \n",
            "   creating: mcq_db/\n",
            "  inflating: mcq_db/chroma.sqlite3   \n",
            "   creating: mcq_db/d897d22c-91fc-4db5-8a6b-aacbd9c5f57d/\n",
            "  inflating: mcq_db/d897d22c-91fc-4db5-8a6b-aacbd9c5f57d/data_level0.bin  \n",
            "  inflating: mcq_db/d897d22c-91fc-4db5-8a6b-aacbd9c5f57d/header.bin  \n",
            "  inflating: mcq_db/d897d22c-91fc-4db5-8a6b-aacbd9c5f57d/length.bin  \n",
            " extracting: mcq_db/d897d22c-91fc-4db5-8a6b-aacbd9c5f57d/link_lists.bin  \n",
            "  inflating: requirements.txt        \n"
          ]
        }
      ],
      "source": [
        "# Download required files from Github repo\n",
        "!wget https://github.com/sumkh/NYP_Dataset/raw/refs/heads/main/Documents.zip\n",
        "!unzip -o /content/Documents.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Znk0gm1ce67",
        "outputId": "897baaf2-0dec-4f93-d910-5f80cb9fea77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "import json\n",
        "import hashlib\n",
        "import uuid\n",
        "import logging\n",
        "from typing import List, Optional, Union, Literal, Dict\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "# LangChain & related imports\n",
        "from langchain_core.tools import tool, StructuredTool\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever\n",
        "\n",
        "# Extraction for Documents\n",
        "from langchain_docling.loader import ExportType\n",
        "from langchain_docling import DoclingLoader\n",
        "from docling.chunking import HybridChunker\n",
        "\n",
        "# Extraction for HTML\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Configurations and Get the API key from the environment variable\n",
        "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2SDpdN9Yck4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389,
          "referenced_widgets": [
            "3c76ee851ef148b6bca750395a41f6f3",
            "3ee475f359ae4d8dab44dd307be595b6",
            "ac058d254794461d9bfed53238fe92e6",
            "b6cdf019a5484fd8886bd7eb9756bb73",
            "59cbd69afebd42a689d03a568170aa32",
            "143010e7e067406e97862a42969bc73c",
            "913a943660ce4418a8fd541e26c747df",
            "c3bb5ebbc70e480392fc03644f539363",
            "ade9aaf927664bfcad63bdb976f155cc",
            "033aeffc3db1439fa398f7f6f9baf371",
            "42aefc6cdca14ed19dfdb41836662e45",
            "c77ff518916440ab80ce40c358a7538f",
            "a916106d653c43d49e40ccc1e33f9e45",
            "26b3d32cd85740c6a1456f04071be330",
            "e390228c54c2426b9c42f6a8e4b86f64",
            "a0de562b264e41558ccfc65ffbb7eb57",
            "0a6d0a0af217429fa43305bc05d22586",
            "7ad21e12241b4b08893124bbad6b7738",
            "59bf10101ffa428c8f74978ceac12719",
            "86932b952a1b43d19df34f0e9d05692a",
            "e2746b45f651481781250e9d80c54c92",
            "6670c2f754214d0c9a5a894e06bcd0eb",
            "02d3e825dc664818bde225837ba4e5e1",
            "9025cd9df18b4f37841747b03f448994",
            "9ae93a1f47194ce1b702329d9f57e8c1",
            "5cd74a537e314e58963164c99acc2783",
            "72373f0cc3574660975808c4430ad5ca",
            "d368994b53bd4b96ac44a6f39611e604",
            "588c45ad36c44aab9a0476d56cc8b557",
            "dd6157f159bc452397416dc581389590",
            "fd60731c99654ee19e5dc36b95213b0d",
            "6dcbdc0f620e47ac9167a2d76af14099",
            "2b2cd31397ee4b96b1501ea20799f022",
            "17a28df8152845ea9a22a94321aa0616",
            "d34cda9b45f148778d76a727e11d87f0",
            "d894333be47a420dbcc2c9f8953788df",
            "32d37357f80b4ea09d30083b343b254a",
            "f7ebd610cf9a41e691d7822c11e08cfa",
            "56602f4ac090457a951a989b37201110",
            "b2739542ad9a4151982cf3cebf6b3097",
            "d4bd6a3a044a495ab1ae5ebf6ba6a705",
            "da90c99b63ba4904a09ebe584ce6144c",
            "626e26e81e084dcbab9e6f6dd17ea5cc",
            "a3cd7badc48247f4a4a6aa08161c2085",
            "9f068dba409a48688f7d0627cd0fc0a6",
            "0c04642f273e4baf9e52006fcd724996",
            "fd16e84738974da4a0f19e63b14a02b8",
            "321e982959fd4093922b64b57b22785b",
            "a3b0a642b037421f8ebbaf638c2c073b",
            "48f8c54add7b4a3699380d6d856b55eb",
            "3eddd41b3a9f4363be20fdeb57682a93",
            "afb969d5c69c4fa58dbb74e7fb9cedc8",
            "6294dfabc5d3425892ad1e81c4589d6e",
            "ffaeb72fe7154aa78c08d6753992a7ec",
            "1afe438755ab4fdc843447d7909b22d7",
            "c7dec22e4d074d8c8ae304f0e2abf9a5",
            "335fd6a06650474fb5e4257dcbb86804",
            "70df440995c54b14b6381afd59fdb383",
            "1b7cb45af8a64badbe2fd37dbfe9fa0c",
            "56d8452aa06c417bba4b9ff44dd4bebb",
            "2ceb9aaba3a2455abf5b399f2e853280",
            "a79ac03b0321425990267c1bd9e9aa9f",
            "ec6f287292354af4a9143da9d291e83e",
            "458be0c028cc4a7db1001a0cd595ebfe",
            "1adfcfac656c488da93d934ebe18efa5",
            "c24ca9cb47544e848a9e106e210dc3cc",
            "52aa278c7b62496a8c9d4a37b973e7fb",
            "a5f6629d2ecf4801b9d41013b8e65742",
            "6d1ca68569c546ff9723fff625d43301",
            "94499c81ce3246418a3301b7fba1d37e",
            "1766758a6f8542599b61d4edd7451b94",
            "c2c010c8fe264883ad5177acc194a053",
            "d075d104068e40309bcb425c85fe04fd",
            "63e41ef5833041b89c87689a034b779f",
            "906193615eb34188b338178b3444c485",
            "b2c47be6e9fb4dbc8b3311adaa659518",
            "a622b71401274f2d83782df8056c2a39",
            "5b5d251bc326469fb032bd077b2f4400",
            "1477782451a9424091d01a31c177a599",
            "e765494393b748c6975bb76f2bff5024",
            "cffd82067082429f9cccf636be5ac86d",
            "50cd402fadee4225bdcbba33e7561bbb",
            "95753bf271ed418b9c0bbe74e44d2780",
            "d9c18a0e10d545cea49789a4005de1dc",
            "eeab1eb8a48d4c389fef2bb762398772",
            "65a8ddfa00664ae69e977e5c4cb6c415",
            "182900e6443a437e8a1ceecbe9a6cba3",
            "d07ed0bfbffc49e08c32976815b1ed65",
            "88e75183cfaf4a89ab37d434408ed04e",
            "7f5c3d38366045ea8be9958c168537fb",
            "fc4184f532ff45e189ef920b224c082d",
            "3cfec7a8205747118318cc814b9eeaba",
            "cc444aae2aaa43be84b875c91c631559",
            "1792d67a0b4a47f4b52cbd95de38f02d",
            "6ba89b6ef0694015a70f7212cf2cea0b",
            "5cded92529774b6698e4f1c6636d04ae",
            "959293859e3a474a92b413002f183e85",
            "4addd4534c3549758f3dccc8dc4af1e6",
            "61c226fc0f7440f496f41a47f657b030",
            "a295e03cc0304c56b2cade48ed882b0c",
            "5c8e3c1ca130481da10feb44f551cbc6",
            "7aa8ef3cfaae4ccfb6f7896f47f22634",
            "33a0d8ac9f7c46df9505d055b4847d15",
            "5259feaa6bd942cc844ca6bcfc80f1d4",
            "b44c2a2659f34d529d76ca72c80a8e72",
            "c1c9684a6d7c45c6a519d7d27bd6dd7f",
            "ae3e90a14b1848bca90bf43f2b89c301",
            "ce4ed14b96a14896a10052e961026c54",
            "0d1df2f3ec9d4fbfac6cfc995e273818",
            "52ad327400fa404fb3c2f0fc704bcde8",
            "6b44514b80cc4a42994c19211c3b03d1",
            "e8a261f47be74fec89e24cca8431b590",
            "4c10e961a73b48c18c1e2a16741ddb1b",
            "4bc945f2ea984dbb8620dd50dfb037dc",
            "5793980ffe6c4c06a56d18418cba3a07",
            "bf21a4c82ad84bca96cafbe94f9aa6d9",
            "6b9856ad421648568509414d337edaf0",
            "8631b1bbedfc416ea59aff2542caddf2",
            "b3f6a0b9769e4bdf81dab8afe7c73719",
            "a87fde87f1e64800875f9f0212903da1",
            "2d06999fb26f4096a168752680b5407a"
          ]
        },
        "outputId": "28d7c06e-b843-4641-d5f7-419656794ad3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c76ee851ef148b6bca750395a41f6f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c77ff518916440ab80ce40c358a7538f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02d3e825dc664818bde225837ba4e5e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17a28df8152845ea9a22a94321aa0616"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f068dba409a48688f7d0627cd0fc0a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7dec22e4d074d8c8ae304f0e2abf9a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52aa278c7b62496a8c9d4a37b973e7fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b5d251bc326469fb032bd077b2f4400"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88e75183cfaf4a89ab37d434408ed04e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a295e03cc0304c56b2cade48ed882b0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b44514b80cc4a42994c19211c3b03d1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# =============================================================================\n",
        "#                         Document Extraction Functions\n",
        "# =============================================================================\n",
        "\n",
        "def extract_documents(doc_path: str) -> List[str]:\n",
        "    \"\"\"\n",
        "    Recursively collects all file paths from folder 'doc_path'.\n",
        "    Used by ExtractDocument.load_files() to find documents to parse.\n",
        "    \"\"\"\n",
        "    extracted_docs = []\n",
        "\n",
        "    for root, _, files in os.walk(doc_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            extracted_docs.append(file_path)\n",
        "    return extracted_docs\n",
        "\n",
        "\n",
        "def _generate_uuid(page_content: str) -> str:\n",
        "    \"\"\"Generate a UUID for a chunk of text using MD5 hashing.\"\"\"\n",
        "    md5_hash = hashlib.md5(page_content.encode()).hexdigest()\n",
        "    return str(uuid.UUID(md5_hash[0:32]))\n",
        "\n",
        "\n",
        "def load_file(file_path: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Load a file from the given path and return a list of Document objects.\n",
        "    \"\"\"\n",
        "    _documents = []\n",
        "\n",
        "    # Load the file and extract the text chunks\n",
        "    try:\n",
        "        loader = DoclingLoader(\n",
        "            file_path = file_path,\n",
        "            export_type = ExportType.DOC_CHUNKS,\n",
        "            chunker = HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
        "        )\n",
        "        docs = loader.load()\n",
        "        logger.info(f\"Total parsed doc-chunks: {len(docs)} from Source: {file_path}\")\n",
        "\n",
        "        for d in docs:\n",
        "            # Tag each document's chunk with the source file and a unique ID\n",
        "            doc = Document(\n",
        "                page_content=d.page_content,\n",
        "                metadata={\n",
        "                    \"source\": file_path,\n",
        "                    \"doc_id\": _generate_uuid(d.page_content),\n",
        "                    \"source_type\": \"file\",\n",
        "                }\n",
        "            )\n",
        "            _documents.append(doc)\n",
        "        logger.info(f\"Total generated LangChain document chunks: {len(_documents)}\\n.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading file: {file_path}. Exception: {e}\\n.\")\n",
        "\n",
        "    return _documents\n",
        "\n",
        "\n",
        "# Define function to load documents from a folder\n",
        "def load_files_from_folder(doc_path: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Load documents from the given folder path and return a list of Document objects.\n",
        "    \"\"\"\n",
        "    _documents = []\n",
        "    # Extract all files path from the given folder\n",
        "    extracted_docs = extract_documents(doc_path)\n",
        "\n",
        "    # Iterate through each document and extract the text chunks\n",
        "    for file_path in extracted_docs:\n",
        "        _documents.extend(load_file(file_path))\n",
        "\n",
        "    return _documents\n",
        "\n",
        "# =============================================================================\n",
        "# Load structured data in csv file to LangChain Document format\n",
        "def load_mcq_csvfiles(file_path: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Load structured data in mcq csv file from the given file path and return a list of Document object.\n",
        "    Expected format: each row of csv is comma separated into \"mcq_number\", \"mcq_type\", \"text_content\"\n",
        "    \"\"\"\n",
        "    _documents = []\n",
        "\n",
        "    # iterate through each csv file and load each row into _dict_per_question format\n",
        "    # Ensure we process only CSV files\n",
        "    if not file_path.endswith(\".csv\"):\n",
        "        return _documents  # Skip non-CSV files\n",
        "    try:\n",
        "        # Open and read the CSV file\n",
        "        with open(file_path, mode='r', encoding='utf-8') as file:\n",
        "            reader = csv.DictReader(file)\n",
        "            for row in reader:\n",
        "                # Ensure required columns exist in the row\n",
        "                if not all(k in row for k in [\"mcq_number\", \"mcq_type\", \"text_content\"]): # Ensure required columns exist and exclude header\n",
        "                    logger.error(f\"Skipping row due to missing fields: {row}\")\n",
        "                    continue\n",
        "                # Tag each row of csv is comma separated into \"mcq_number\", \"mcq_type\", \"text_content\"\n",
        "                doc = Document(\n",
        "                    page_content = row[\"text_content\"], # text_content segment is separated by \"|\"\n",
        "                    metadata={\n",
        "                        \"source\": f\"{file_path}_{row['mcq_number']}\",  # file_path + mcq_number\n",
        "                        \"doc_id\": _generate_uuid(f\"{file_path}_{row['mcq_number']}\"),  # Unique ID\n",
        "                        \"source_type\": row[\"mcq_type\"],  # MCQ type\n",
        "                    }\n",
        "                )\n",
        "                _documents.append(doc)\n",
        "            logger.info(f\"Successfully loaded {len(_documents)} LangChain document chunks from {file_path}.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading file: {file_path}. Exception: {e}\\n.\")\n",
        "\n",
        "    return _documents\n",
        "\n",
        "# Define function to load documents from a folder for structured data in csv file\n",
        "def load_files_from_folder_mcq(doc_path: str) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Load mcq csv file from the given folder path and return a list of Document objects.\n",
        "    \"\"\"\n",
        "    _documents = []\n",
        "    # Extract all files path from the given folder\n",
        "    extracted_docs = [\n",
        "        os.path.join(doc_path, file) for file in os.listdir(doc_path)\n",
        "        if file.endswith(\".csv\")  # Process only CSV files\n",
        "    ]\n",
        "\n",
        "    # Iterate through each document and extract the text chunks\n",
        "    for file_path in extracted_docs:\n",
        "        _documents.extend(load_mcq_csvfiles(file_path))\n",
        "\n",
        "    return _documents\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "#                         Website Extraction Functions\n",
        "# =============================================================================\n",
        "def _generate_uuid(page_content: str) -> str:\n",
        "    \"\"\"Generate a UUID for a chunk of text using MD5 hashing.\"\"\"\n",
        "    md5_hash = hashlib.md5(page_content.encode()).hexdigest()\n",
        "    return str(uuid.UUID(md5_hash[0:32]))\n",
        "\n",
        "def ensure_scheme(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    if not parsed_url.scheme:\n",
        "        return 'http://' + url  # Default to http, or use 'https://' if preferred\n",
        "    return url\n",
        "\n",
        "def extract_html(url: List[str]) -> List[Document]:\n",
        "    if isinstance(url, str):\n",
        "        url = [url]\n",
        "    \"\"\"\n",
        "    Extracts text from the HTML content of web pages listed in 'web_path'.\n",
        "    Returns a list of LangChain 'Document' objects.\n",
        "    \"\"\"\n",
        "    # Ensure all URLs have a scheme\n",
        "    web_paths = [ensure_scheme(u) for u in url]\n",
        "\n",
        "    loader = WebBaseLoader(web_paths)\n",
        "    loader.requests_per_second = 1\n",
        "    docs = loader.load()\n",
        "\n",
        "    # Iterate through each document, clean the content, removing excessive line return and store it in a LangChain Document\n",
        "    _documents = []\n",
        "    for doc in docs:\n",
        "        # Clean the concent\n",
        "        doc.page_content = doc.page_content.strip()\n",
        "        doc.page_content = doc.page_content.replace(\"\\n\", \" \")\n",
        "        doc.page_content = doc.page_content.replace(\"\\r\", \" \")\n",
        "        doc.page_content = doc.page_content.replace(\"\\t\", \" \")\n",
        "        doc.page_content = doc.page_content.replace(\"  \", \" \")\n",
        "        doc.page_content = doc.page_content.replace(\"   \", \" \")\n",
        "\n",
        "        # Store it in a LangChain Document\n",
        "        web_doc = Document(\n",
        "            page_content=doc.page_content,\n",
        "            metadata={\n",
        "                \"source\": doc.metadata.get(\"source\"),\n",
        "                \"doc_id\": _generate_uuid(doc.page_content),\n",
        "                \"source_type\": \"web\"\n",
        "            }\n",
        "        )\n",
        "        _documents.append(web_doc)\n",
        "    return _documents\n",
        "\n",
        "# =============================================================================\n",
        "#                         Vector Store Initialisation\n",
        "# =============================================================================\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=EMBED_MODEL_ID)\n",
        "\n",
        "# Initialise vector stores\n",
        "general_vs = Chroma(\n",
        "    collection_name=\"general_vstore\",\n",
        "    embedding_function=embedding_model,\n",
        "    persist_directory=\"./general_db\"\n",
        ")\n",
        "\n",
        "mcq_vs = Chroma(\n",
        "    collection_name=\"mcq_vstore\",\n",
        "    embedding_function=embedding_model,\n",
        "    persist_directory=\"./mcq_db\"\n",
        ")\n",
        "\n",
        "in_memory_vs = Chroma(\n",
        "    collection_name=\"in_memory_vstore\",\n",
        "    embedding_function=embedding_model\n",
        ")\n",
        "\n",
        "# Split the documents into smaller chunks for better embedding coverage\n",
        "def split_text_into_chunks(docs: List[Document]) -> List[Document]:\n",
        "    \"\"\"\n",
        "    Splits a list of Documents into smaller text chunks using\n",
        "    RecursiveCharacterTextSplitter while preserving metadata.\n",
        "    Returns a list of Document objects.\n",
        "    \"\"\"\n",
        "    if not docs:\n",
        "        return []\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1000, # Split into chunks of 1000 characters\n",
        "        chunk_overlap=200, # Overlap by 200 characters\n",
        "        add_start_index=True\n",
        "    )\n",
        "    chunked_docs = splitter.split_documents(docs)\n",
        "    return chunked_docs # List of Document objects\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "#                         Retrieval Tools\n",
        "# =============================================================================\n",
        "\n",
        "# Define a simple similarity search retrieval tool on msq_vs\n",
        "class MCQRetrievalTool(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"The input text to search for.\")\n",
        "    k: int = Field(2, title=\"Number of Results\", description=\"The number of results to retrieve.\")\n",
        "\n",
        "def mcq_retriever(input: str, k: int = 2) -> List[str]:\n",
        "    # Retrieve the top k most similar mcq question documents from the vector store\n",
        "    docs_func = mcq_vs.as_retriever(\n",
        "        search_type=\"similarity\",\n",
        "        search_kwargs={\n",
        "        'k': k,\n",
        "        'filter':{\"source_type\": \"mcq_question\"}\n",
        "    },\n",
        "    )\n",
        "    docs_qns = docs_func.invoke(input, k=k)\n",
        "\n",
        "    # Extract the document IDs from the retrieved documents\n",
        "    doc_ids = [d.metadata.get(\"doc_id\") for d in docs_qns if \"doc_id\" in d.metadata]\n",
        "\n",
        "    # Retrieve full documents based on the doc_ids\n",
        "    docs = mcq_vs.get(where = {'doc_id': {\"$in\":doc_ids}})\n",
        "\n",
        "    qns_list = {}\n",
        "    for i, d in enumerate(docs['metadatas']):\n",
        "        qns_list[d['source'] + \" \" + d['source_type']] = docs['documents'][i]\n",
        "\n",
        "    return qns_list\n",
        "\n",
        "# Create a StructuredTool from the function\n",
        "mcq_retriever_tool = StructuredTool.from_function(\n",
        "    func = mcq_retriever,\n",
        "    name = \"MCQ Retrieval Tool\",\n",
        "    description = (\n",
        "    \"\"\"\n",
        "    Use this tool to retrieve MCQ questions set when Human asks to generate a quiz related to a topic.\n",
        "    DO NOT GIVE THE ANSWERS to Human before Human has answered all the questions.\n",
        "\n",
        "    If Human give answers for questions you do not know, SAY you do not have the questions for the answer\n",
        "    and ASK if the Human want you to generate a new quiz and then SAVE THE QUIZ with Summary Tool before ending the conversation.\n",
        "\n",
        "\n",
        "    Input must be a JSON string with the schema:\n",
        "        - input (str): The search topic to retrieve MCQ questions set related to the topic.\n",
        "        - k (int): Number of question set to retrieve.\n",
        "        Example usage: input='What is AI?', k=5\n",
        "\n",
        "    Returns:\n",
        "    - A dict of MCQ questions:\n",
        "    Key: 'metadata of question' e.g. './Documents/mcq/mcq.csv_Qn31 mcq_question' with suffix ['question', 'answer', 'answer_reason', 'options', 'wrong_options_reason']\n",
        "    Value: Text Content\n",
        "\n",
        "    \"\"\"\n",
        "    ),\n",
        "    args_schema = MCQRetrievalTool,\n",
        "    response_format=\"content\",\n",
        "    return_direct = False, # Return the response as a list of strings\n",
        "    verbose = False  # To log tool's progress\n",
        "    )\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Retrieve more documents with higher diversity using MMR (Maximal Marginal Relevance) from the general vector store\n",
        "# Useful if the dataset has many similar documents\n",
        "class GenRetrievalTool(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"The input text to search for.\")\n",
        "    k: int = Field(2, title=\"Number of Results\", description=\"The number of results to retrieve.\")\n",
        "\n",
        "def gen_retriever(input: str, k: int = 2) -> List[str]:\n",
        "    # Use retriever of vector store to retrieve documents\n",
        "    docs_func = general_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs = {'k': k, 'lambda_mult': 0.25}\n",
        "    )\n",
        "    docs = docs_func.invoke(input, k=k)\n",
        "    return [d.page_content for d in docs]\n",
        "\n",
        "# Create a StructuredTool from the function\n",
        "general_retriever_tool = StructuredTool.from_function(\n",
        "    func = gen_retriever,\n",
        "    name = \"Assistant References Retrieval Tool\",\n",
        "    description = (\n",
        "    \"\"\"\n",
        "    Use this tool to retrieve reference information from Assistant reference database for Human queries related to a topic or\n",
        "    and when Human asked to generate guides to learn or study about a topic.\n",
        "\n",
        "    Input must be a JSON string with the schema:\n",
        "        - input (str): The user query.\n",
        "        - k (int): Number of results to retrieve.\n",
        "        Example usage: input='What is AI?', k=5\n",
        "    Returns:\n",
        "    - A list of retrieved document's content string.\n",
        "    \"\"\"\n",
        "    ),\n",
        "    args_schema = GenRetrievalTool,\n",
        "    response_format=\"content\",\n",
        "    return_direct = False, # Return the content of the documents\n",
        "    verbose = False  # To log tool's progress\n",
        "    )\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Retrieve more documents with higher diversity using MMR (Maximal Marginal Relevance) from the in-memory vector store\n",
        "# Query in-memory vector store only\n",
        "class InMemoryRetrievalTool(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"The input text to search for.\")\n",
        "    k: int = Field(2, title=\"Number of Results\", description=\"The number of results to retrieve.\")\n",
        "\n",
        "def in_memory_retriever(input: str, k: int = 2) -> List[str]:\n",
        "    # Use retriever of vector store to retrieve documents\n",
        "    docs_func = in_memory_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs = {'k': k, 'lambda_mult': 0.25}\n",
        "    )\n",
        "    docs = docs_func.invoke(input, k=k)\n",
        "    return [d.page_content for d in docs]\n",
        "\n",
        "# Create a StructuredTool from the function\n",
        "in_memory_retriever_tool = StructuredTool.from_function(\n",
        "    func = in_memory_retriever,\n",
        "    name = \"In-Memory Retrieval Tool\",\n",
        "    description = (\n",
        "    \"\"\"\n",
        "    Use this tool when Human ask Assistant to retrieve information from documents that Human has uploaded.\n",
        "\n",
        "    Input must be a JSON string with the schema:\n",
        "        - input (str): The user query.\n",
        "        - k (int): Number of results to retrieve.\n",
        "    \"\"\"\n",
        "    ),\n",
        "    args_schema = InMemoryRetrievalTool,\n",
        "    response_format=\"content\",\n",
        "    return_direct = False, # Whether to return the tool’s output directly\n",
        "    verbose = False  # To log tool's progress\n",
        "    )\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Web Extraction Tool\n",
        "class WebExtractionRequest(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"The input text to search for.\")\n",
        "    url: str = Field(\n",
        "        ...,\n",
        "        title=\"url\",\n",
        "        description=\"urls to extract content from\"\n",
        "    )\n",
        "    k: int = Field(5, title=\"Number of Results\", description=\"The number of results to retrieve.\")\n",
        "\n",
        "# Extract content from a web URL, load into in_memory_vstore\n",
        "def extract_web_path_tool(input: str, url: str, k: int = 5) -> List[str]:\n",
        "    if isinstance(url, str):\n",
        "        url = [url]\n",
        "    \"\"\"\n",
        "    Extract content from the web URLs based on user's input.\n",
        "    Args:\n",
        "    - input: The input text to search for.\n",
        "    - url: URLs to extract content from.\n",
        "    - k: Number of results to retrieve.\n",
        "    Returns:\n",
        "     - A list of retrieved document's content string.\n",
        "    \"\"\"\n",
        "    # Extract content from the web\n",
        "    html_docs = extract_html(url)\n",
        "    if not html_docs:\n",
        "        return f\"No content extracted from {url}.\"\n",
        "\n",
        "    # Split the documents into smaller chunks for better embedding coverage\n",
        "    chunked_texts = split_text_into_chunks(html_docs)\n",
        "    in_memory_vs.add_documents(chunked_texts) # Add the chunked texts to the in-memory vector store\n",
        "\n",
        "    # Extract content from the in-memory vector store\n",
        "    # Use retriever of vector store to retrieve documents\n",
        "    docs_func = in_memory_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={\n",
        "        'k': k,\n",
        "        'lambda_mult': 0.25,\n",
        "        'filter':{\"source\": {\"$in\": url}}\n",
        "    },\n",
        "    )\n",
        "    docs = docs_func.invoke(input, k=k)\n",
        "    return [d.page_content for d in docs]\n",
        "\n",
        "# Create a StructuredTool from the function\n",
        "web_extraction_tool = StructuredTool.from_function(\n",
        "    func = extract_web_path_tool,\n",
        "    name = \"Web Extraction Tool\",\n",
        "    description = (\n",
        "        \"Assistant should use this tool to extract content from web URLs based on user's input, \"\n",
        "        \"Web extraction is initially load into database and then return k: Number of results to retrieve\"\n",
        "    ),\n",
        "    args_schema = WebExtractionRequest,\n",
        "    return_direct = False, # Whether to return the tool’s output directly\n",
        "    verbose = False  # To log tool's progress\n",
        "    )\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# Ensemble Retrieval from General and In-Memory Vector Stores\n",
        "class EnsembleRetrievalTool(BaseModel):\n",
        "    input: str = Field(..., title=\"input\", description=\"The input text to search for.\")\n",
        "    k: int = Field(5, title=\"Number of Results\", description=\"The number of results to retrieve.\")\n",
        "\n",
        "def ensemble_retriever(input: str, k: int = 5) -> List[str]:\n",
        "    # Use retriever of vector store to retrieve documents\n",
        "    general_retrieval = general_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs = {'k': k, 'lambda_mult': 0.25}\n",
        "    )\n",
        "    in_memory_retrieval = in_memory_vs.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs = {'k': k, 'lambda_mult': 0.25}\n",
        "    )\n",
        "\n",
        "    ensemble_retriever = EnsembleRetriever(\n",
        "        retrievers=[general_retrieval, in_memory_retrieval],\n",
        "        weights=[0.5, 0.5]\n",
        "    )\n",
        "    docs = ensemble_retriever.invoke(input)\n",
        "    return [d.page_content for d in docs]\n",
        "\n",
        "# Create a StructuredTool from the function\n",
        "ensemble_retriever_tool = StructuredTool.from_function(\n",
        "    func = ensemble_retriever,\n",
        "    name = \"Ensemble Retriever Tool\",\n",
        "    description = (\n",
        "    \"\"\"\n",
        "    Use this tool to retrieve information from reference database and\n",
        "    extraction of documents that Human has uploaded.\n",
        "\n",
        "    Input must be a JSON string with the schema:\n",
        "        - input (str): The user query.\n",
        "        - k (int): Number of results to retrieve.\n",
        "    \"\"\"\n",
        "    ),\n",
        "    args_schema = EnsembleRetrievalTool,\n",
        "    response_format=\"content\",\n",
        "    return_direct = False\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# Define a Customised Wrapper from vLLM Wrapper\n",
        "###############################################################################\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import warnings\n",
        "from operator import itemgetter\n",
        "from typing import (\n",
        "    Any,\n",
        "    AsyncIterator,\n",
        "    Callable,\n",
        "    Dict,\n",
        "    Iterator,\n",
        "    List,\n",
        "    Literal,\n",
        "    Mapping,\n",
        "    Optional,\n",
        "    Sequence,\n",
        "    Tuple,\n",
        "    Type,\n",
        "    TypedDict,\n",
        "    Union,\n",
        "    cast,\n",
        ")\n",
        "\n",
        "from langchain_core._api import deprecated\n",
        "from langchain_core.callbacks import (\n",
        "    AsyncCallbackManagerForLLMRun,\n",
        "    CallbackManagerForLLMRun,\n",
        ")\n",
        "from langchain_core.language_models import LanguageModelInput\n",
        "from langchain_core.language_models.chat_models import (\n",
        "    BaseChatModel,\n",
        "    LangSmithParams,\n",
        "    agenerate_from_stream,\n",
        "    generate_from_stream,\n",
        ")\n",
        "from langchain_core.messages import (\n",
        "    AIMessage,\n",
        "    AIMessageChunk,\n",
        "    BaseMessage,\n",
        "    BaseMessageChunk,\n",
        "    ChatMessage,\n",
        "    ChatMessageChunk,\n",
        "    FunctionMessage,\n",
        "    FunctionMessageChunk,\n",
        "    HumanMessage,\n",
        "    HumanMessageChunk,\n",
        "    InvalidToolCall,\n",
        "    SystemMessage,\n",
        "    SystemMessageChunk,\n",
        "    ToolCall,\n",
        "    ToolMessage,\n",
        "    ToolMessageChunk,\n",
        ")\n",
        "from langchain_core.output_parsers import (\n",
        "    JsonOutputParser,\n",
        "    PydanticOutputParser,\n",
        ")\n",
        "from langchain_core.output_parsers.base import OutputParserLike\n",
        "from langchain_core.output_parsers.openai_tools import (\n",
        "    JsonOutputKeyToolsParser,\n",
        "    PydanticToolsParser,\n",
        "    make_invalid_tool_call,\n",
        "    parse_tool_call,\n",
        ")\n",
        "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult\n",
        "from langchain_core.runnables import Runnable, RunnableMap, RunnablePassthrough\n",
        "from langchain_core.tools import BaseTool\n",
        "from langchain_core.utils import (\n",
        "    from_env,\n",
        "    get_pydantic_field_names,\n",
        "    secret_from_env,\n",
        ")\n",
        "from langchain_core.utils.function_calling import (\n",
        "    convert_to_openai_function,\n",
        "    convert_to_openai_tool,\n",
        ")\n",
        "from langchain_core.utils.pydantic import is_basemodel_subclass\n",
        "from pydantic import (\n",
        "    BaseModel,\n",
        "    ConfigDict,\n",
        "    Field,\n",
        "    SecretStr,\n",
        "    model_validator,\n",
        ")\n",
        "from typing_extensions import Self\n",
        "\n",
        "def _is_pydantic_class(obj: Any) -> bool:\n",
        "    return isinstance(obj, type) and is_basemodel_subclass(obj)\n",
        "\n",
        "\n",
        "class _FunctionCall(TypedDict):\n",
        "    name: str\n",
        "\n",
        "def _convert_dict_to_message(_dict: Mapping[str, Any]) -> BaseMessage:\n",
        "    \"\"\"Convert a dictionary to a LangChain BaseMessage.\"\"\"\n",
        "    role = _dict.get(\"role\")\n",
        "    name = _dict.get(\"name\")\n",
        "    id_ = _dict.get(\"id\")\n",
        "\n",
        "    if role == \"user\":\n",
        "        return HumanMessage(content=_dict.get(\"content\", \"\"), id=id_, name=name)\n",
        "    elif role == \"assistant\":\n",
        "        # For Azure or OpenAI-like usage, 'assistant' can have content or tool calls\n",
        "        content = _dict.get(\"content\") or \"\"\n",
        "        additional_kwargs: Dict[str, Any] = {}\n",
        "        tool_calls = []\n",
        "        invalid_tool_calls = []\n",
        "        if raw_tool_calls := _dict.get(\"tool_calls\"):\n",
        "            additional_kwargs[\"tool_calls\"] = raw_tool_calls\n",
        "            for raw_tool_call in raw_tool_calls:\n",
        "                try:\n",
        "                    tool_calls.append(parse_tool_call(raw_tool_call, return_id=True))\n",
        "                except Exception as e:\n",
        "                    invalid_tool_calls.append(\n",
        "                        make_invalid_tool_call(raw_tool_call, str(e))\n",
        "                    )\n",
        "        return AIMessage(\n",
        "            content=content,\n",
        "            additional_kwargs=additional_kwargs,\n",
        "            name=name,\n",
        "            id=id_,\n",
        "            tool_calls=tool_calls,\n",
        "            invalid_tool_calls=invalid_tool_calls,\n",
        "        )\n",
        "    elif role in (\"system\", \"developer\"):\n",
        "        # \"developer\" is a custom role used by some expansions\n",
        "        # We store it in additional_kwargs if needed\n",
        "        if role == \"developer\":\n",
        "            additional_kwargs = {\"__openai_role__\": role}\n",
        "        else:\n",
        "            additional_kwargs = {}\n",
        "        return SystemMessage(\n",
        "            content=_dict.get(\"content\", \"\"),\n",
        "            name=name,\n",
        "            id=id_,\n",
        "            additional_kwargs=additional_kwargs,\n",
        "        )\n",
        "    elif role == \"function\":\n",
        "        return FunctionMessage(\n",
        "            content=_dict.get(\"content\", \"\"), name=cast(str, _dict.get(\"name\")), id=id_\n",
        "        )\n",
        "    elif role == \"tool\":\n",
        "        # custom \"tool\" role\n",
        "        additional_kwargs = {}\n",
        "        if \"name\" in _dict:\n",
        "            additional_kwargs[\"name\"] = _dict[\"name\"]\n",
        "        return ToolMessage(\n",
        "            content=_dict.get(\"content\", \"\"),\n",
        "            tool_call_id=cast(str, _dict.get(\"tool_call_id\")),\n",
        "            additional_kwargs=additional_kwargs,\n",
        "            name=name,\n",
        "            id=id_,\n",
        "        )\n",
        "    else:\n",
        "        # fallback for other roles\n",
        "        return ChatMessage(content=_dict.get(\"content\", \"\"), role=role, id=id_)\n",
        "\n",
        "\n",
        "def _format_message_content(content: Any) -> Any:\n",
        "    \"\"\"Format message content, removing blocks with type == 'tool_use' if present.\"\"\"\n",
        "    if content and isinstance(content, list):\n",
        "        formatted_content = []\n",
        "        for block in content:\n",
        "            if (\n",
        "                isinstance(block, dict)\n",
        "                and block.get(\"type\") == \"tool_use\"\n",
        "            ):\n",
        "                continue\n",
        "            formatted_content.append(block)\n",
        "        return formatted_content\n",
        "    return content\n",
        "\n",
        "\n",
        "def _convert_message_to_dict(message: BaseMessage) -> Dict[str, Any]:\n",
        "    \"\"\"Convert a LangChain BaseMessage to a dictionary (role/content).\"\"\"\n",
        "    message_dict: Dict[str, Any] = {\n",
        "        \"content\": _format_message_content(message.content)\n",
        "    }\n",
        "\n",
        "    # Some messages store 'name' in message.name or additional_kwargs['name']\n",
        "    if (name := message.name or message.additional_kwargs.get(\"name\")) is not None:\n",
        "        message_dict[\"name\"] = name\n",
        "\n",
        "    if isinstance(message, ChatMessage):\n",
        "        message_dict[\"role\"] = message.role\n",
        "    elif isinstance(message, HumanMessage):\n",
        "        message_dict[\"role\"] = \"user\"\n",
        "    elif isinstance(message, AIMessage):\n",
        "        message_dict[\"role\"] = \"assistant\"\n",
        "        if \"tool_calls\" in message.additional_kwargs:\n",
        "            message_dict[\"tool_calls\"] = message.additional_kwargs[\"tool_calls\"]\n",
        "            # filter to only certain properties\n",
        "            tool_call_supported_props = {\"id\", \"type\", \"function\"}\n",
        "            message_dict[\"tool_calls\"] = [\n",
        "                {k: v for k, v in tool_call.items() if k in tool_call_supported_props}\n",
        "                for tool_call in message_dict[\"tool_calls\"]\n",
        "            ]\n",
        "        # If tool calls present, empty string => None\n",
        "        if \"tool_calls\" in message_dict:\n",
        "            message_dict[\"content\"] = message_dict[\"content\"] or None\n",
        "    elif isinstance(message, SystemMessage):\n",
        "        # We store developer as __openai_role__ in additional_kwargs\n",
        "        # But for a standard system message we keep role=\"system\"\n",
        "        if \"__openai_role__\" in message.additional_kwargs:\n",
        "            message_dict[\"role\"] = \"developer\"\n",
        "        else:\n",
        "            message_dict[\"role\"] = \"system\"\n",
        "    elif isinstance(message, ToolMessage):\n",
        "        message_dict[\"role\"] = \"tool\"\n",
        "        message_dict[\"tool_call_id\"] = message.tool_call_id\n",
        "        supported_props = {\"content\", \"role\", \"tool_call_id\", \"name\"}\n",
        "        message_dict = {k: v for k, v in message_dict.items() if k in supported_props}\n",
        "    else:\n",
        "        raise TypeError(f\"Got unknown type of message: {type(message)}\")\n",
        "\n",
        "    return message_dict\n",
        "\n",
        "def _convert_chunk_to_message_chunk(\n",
        "    chunk: Mapping[str, Any], default_class: Type[BaseMessageChunk]\n",
        ") -> BaseMessageChunk:\n",
        "    choice = chunk[\"choices\"][0]\n",
        "    _dict = choice[\"delta\"]\n",
        "    role = cast(str, _dict.get(\"role\"))\n",
        "    content = cast(str, _dict.get(\"content\") or \"\")\n",
        "    additional_kwargs: Dict = {}\n",
        "    if _dict.get(\"function_call\"):\n",
        "        function_call = dict(_dict[\"function_call\"])\n",
        "        if \"name\" in function_call and function_call[\"name\"] is None:\n",
        "            function_call[\"name\"] = \"\"\n",
        "        additional_kwargs[\"function_call\"] = function_call\n",
        "    if _dict.get(\"tool_calls\"):\n",
        "        additional_kwargs[\"tool_calls\"] = _dict[\"tool_calls\"]\n",
        "\n",
        "    if role == \"user\" or default_class == HumanMessageChunk:\n",
        "        return HumanMessageChunk(content=content)\n",
        "    elif role == \"assistant\" or default_class == AIMessageChunk:\n",
        "        if usage := (chunk.get(\"x_groq\") or {}).get(\"usage\"):\n",
        "            input_tokens = usage.get(\"prompt_tokens\", 0)\n",
        "            output_tokens = usage.get(\"completion_tokens\", 0)\n",
        "            usage_metadata = {\n",
        "                \"input_tokens\": input_tokens,\n",
        "                \"output_tokens\": output_tokens,\n",
        "                \"total_tokens\": usage.get(\"total_tokens\", input_tokens + output_tokens),\n",
        "            }\n",
        "        else:\n",
        "            usage_metadata = None\n",
        "        return AIMessageChunk(\n",
        "            content=content,\n",
        "            additional_kwargs=additional_kwargs,\n",
        "            usage_metadata=usage_metadata,  # type: ignore[arg-type]\n",
        "        )\n",
        "    elif role == \"system\" or default_class == SystemMessageChunk:\n",
        "        return SystemMessageChunk(content=content)\n",
        "    elif role == \"function\" or default_class == FunctionMessageChunk:\n",
        "        return FunctionMessageChunk(content=content, name=_dict[\"name\"])\n",
        "    elif role == \"tool\" or default_class == ToolMessageChunk:\n",
        "        return ToolMessageChunk(content=content, tool_call_id=_dict[\"tool_call_id\"])\n",
        "    elif role or default_class == ChatMessageChunk:\n",
        "        return ChatMessageChunk(content=content, role=role)\n",
        "    else:\n",
        "        return default_class(content=content)  # type: ignore\n",
        "\n",
        "\n",
        "class BaseChat_vLLMWrapper(BaseChatModel):\n",
        "    \"\"\"\n",
        "    A wrapper for a vLLM model for chat.\n",
        "    Replace `self._client._generate(...)` calls with the actual method from your LLM client.\n",
        "    \"\"\"\n",
        "\n",
        "    # We'll assume you pass in `client` at init; we store it as `_client`.\n",
        "    # If you also have default params, you could store them similarly.\n",
        "    _client: Any\n",
        "    streaming: bool = False\n",
        "    \"\"\"Whether to stream the results or not.\"\"\"\n",
        "\n",
        "    def __init__(self, client: Any, **kwargs: Any):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            client: The vLLM-like client instance that can be called to generate.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self._client = client\n",
        "\n",
        "\n",
        "    def _convert_messages_to_prompt(self, messages: List[BaseMessage]) -> str:\n",
        "        \"\"\"\n",
        "        Example method: convert a list of BaseMessage into a single string prompt.\n",
        "        Adjust how you prefix roles, etc., depending on your LLM’s needs.\n",
        "        \"\"\"\n",
        "        lines = []\n",
        "\n",
        "        # If messages is a dictionary, convert it to a list containing the dictionary\n",
        "        if isinstance(messages, dict):\n",
        "            messages = [messages]\n",
        "\n",
        "        for m in messages:\n",
        "            # role = m.role if m.role else m.__class__.__name__\n",
        "            role = m.get(\"type\", None) if isinstance(m, dict) else (m.type if hasattr(m, 'type') else m.__class__.__name__)  # Get role from dict or object\n",
        "            content = m.get(\"content\", \"\") if isinstance(m, dict) else m.content  # Get content from dict or object\n",
        "            lines.append(f\"{role}: {content}\")\n",
        "\n",
        "        # for m in messages:\n",
        "        #     #role = m.role if m.role else m.__class__.__name__\n",
        "        #     role = m.type if hasattr(m, 'type') else m.__class__.__name__\n",
        "        #     lines.append(f\"{role}: {m.content}\")\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "    def _generate(\n",
        "        self,\n",
        "        messages: List[BaseMessage],\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "        **kwargs: Any,\n",
        "\n",
        "    ) -> ChatResult:\n",
        "        if self.streaming:\n",
        "                stream_iter = self._stream(\n",
        "                    messages, stop=stop, run_manager=run_manager, **kwargs\n",
        "                )\n",
        "                return generate_from_stream(stream_iter)\n",
        "\n",
        "        message_dicts, params = self._create_message_dicts(messages, stop)\n",
        "        params = {\n",
        "            **params,\n",
        "            **kwargs,\n",
        "        }\n",
        "        # Convert messages to a single prompt:\n",
        "        prompt_str = self._convert_messages_to_prompt(message_dicts)\n",
        "        response = self._client._generate(\n",
        "            prompts=prompt_str, stop=stop, run_manager=run_manager, **kwargs\n",
        "        )\n",
        "        print(\"DEBUG LLM response:\", response)\n",
        "\n",
        "        return self._create_chat_result(response)\n",
        "\n",
        "    def _stream(\n",
        "        self,\n",
        "        messages: List[BaseMessage],\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> Iterator[ChatGenerationChunk]:\n",
        "        message_dicts, params = self._create_message_dicts(messages, stop)\n",
        "        # Convert messages to a single prompt:\n",
        "        prompt_str = self._convert_messages_to_prompt(message_dicts)\n",
        "\n",
        "        params = {**params, **kwargs, \"stream\": True}\n",
        "\n",
        "        default_chunk_class: Type[BaseMessageChunk] = AIMessageChunk\n",
        "        for chunk in self._client._generate(\n",
        "            prompts=prompt_str, stop=stop, run_manager=run_manager, **kwargs\n",
        "        ):\n",
        "            if not isinstance(chunk, dict):\n",
        "                chunk = chunk.model_dump()\n",
        "            if len(chunk[\"choices\"]) == 0:\n",
        "                continue\n",
        "            choice = chunk[\"choices\"][0]\n",
        "            message_chunk = _convert_chunk_to_message_chunk(chunk, default_chunk_class)\n",
        "            generation_info = {}\n",
        "            if finish_reason := choice.get(\"finish_reason\"):\n",
        "                generation_info[\"finish_reason\"] = finish_reason\n",
        "            logprobs = choice.get(\"logprobs\")\n",
        "            if logprobs:\n",
        "                generation_info[\"logprobs\"] = logprobs\n",
        "            default_chunk_class = message_chunk.__class__\n",
        "            generation_chunk = ChatGenerationChunk(\n",
        "                message=message_chunk, generation_info=generation_info or None\n",
        "            )\n",
        "\n",
        "            if run_manager:\n",
        "                run_manager.on_llm_new_token(\n",
        "                    generation_chunk.text, chunk=generation_chunk, logprobs=logprobs\n",
        "                )\n",
        "            yield generation_chunk\n",
        "\n",
        "\n",
        "    def _create_chat_result(self, response: Any) -> ChatResult:\n",
        "        \"\"\"\n",
        "        Convert your LLM's response into a ChatResult that LangChain expects.\n",
        "        The debug log shows 'generations' is a list of lists of Generation objects:\n",
        "          {\n",
        "            \"generations\": [[{\"text\": \"...\"}, ...]],\n",
        "            \"llm_output\": ...,\n",
        "            ...\n",
        "          }\n",
        "        \"\"\"\n",
        "        # If it's not a dict, try model_dump() or dict()\n",
        "        if not isinstance(response, dict):\n",
        "            # If using Pydantic v2, 'model_dump' is preferred\n",
        "            if hasattr(response, \"model_dump\"):\n",
        "                response = response.model_dump()\n",
        "            else:\n",
        "                response = response.dict()\n",
        "\n",
        "        # Grab the top-level 'generations' key\n",
        "        all_generations = response.get(\"generations\", [])\n",
        "        if not all_generations:\n",
        "            raise ValueError(\"No 'generations' found in LLM response or it's empty.\")\n",
        "\n",
        "        # all_generations[0] is the list of generations for the *first* prompt\n",
        "        first_prompt_generations = all_generations[0]\n",
        "        if not first_prompt_generations:\n",
        "            raise ValueError(\"No generation output for the first prompt.\")\n",
        "\n",
        "        # Take the first generation (or handle multiple if you prefer)\n",
        "        gen_obj = first_prompt_generations[0]  # e.g. {\"text\": \"...\"}\n",
        "        text = gen_obj.get(\"text\", \"\")\n",
        "\n",
        "        # Create an AIMessage from that text\n",
        "        ai_message = AIMessage(content=text)\n",
        "        generation_info = {}  # e.g. store other data if present\n",
        "        chat_gen = ChatGeneration(message=ai_message, generation_info=generation_info)\n",
        "\n",
        "        # If your LLM returns usage stats or something, parse them here.\n",
        "        # For now, we'll just store an empty dict or reuse \"llm_output\" from response\n",
        "        llm_output = {}\n",
        "        if \"llm_output\" in response and response[\"llm_output\"] is not None:\n",
        "            llm_output = response[\"llm_output\"]\n",
        "\n",
        "        # Return as a ChatResult with a single generation\n",
        "        return ChatResult(generations=[chat_gen], llm_output=llm_output)\n",
        "\n",
        "    def _create_message_dicts(\n",
        "        self, messages: List[BaseMessage], stop: Optional[List[str]]\n",
        "    ) -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:\n",
        "        \"\"\"Return a list of dicts (converted from BaseMessage) plus any default params.\"\"\"\n",
        "        # If you have default params, you might do:\n",
        "        # params = dict(self._default_params)\n",
        "        params: Dict[str, Any] = {}\n",
        "        if stop is not None:\n",
        "            params[\"stop\"] = stop\n",
        "        message_dicts = [_convert_message_to_dict(m) for m in messages]\n",
        "        return message_dicts, params\n",
        "\n",
        "\n",
        "    def bind_functions(\n",
        "        self,\n",
        "        functions: Sequence[Union[Dict[str, Any], Type[BaseModel], Callable, BaseTool]],\n",
        "        function_call: Optional[\n",
        "            Union[_FunctionCall, str, Literal[\"auto\", \"none\"]]\n",
        "        ] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> Runnable[LanguageModelInput, BaseMessage]:\n",
        "        \"\"\"Bind functions (and other objects) to this chat model.\n",
        "\n",
        "        Model is compatible with OpenAI function-calling API.\n",
        "\n",
        "        NOTE: Using bind_tools is recommended instead, as the `functions` and\n",
        "            `function_call` request parameters are officially deprecated.\n",
        "\n",
        "        Args:\n",
        "            functions: A list of function definitions to bind to this chat model.\n",
        "                Can be  a dictionary, pydantic model, or callable. Pydantic\n",
        "                models and callables will be automatically converted to\n",
        "                their schema dictionary representation.\n",
        "            function_call: Which function to require the model to call.\n",
        "                Must be the name of the single provided function or\n",
        "                \"auto\" to automatically determine which function to call\n",
        "                (if any).\n",
        "            **kwargs: Any additional parameters to pass to\n",
        "                :meth:`~langchain_groq.chat_models.ChatGroq.bind`.\n",
        "        \"\"\"\n",
        "\n",
        "        formatted_functions = [convert_to_openai_function(fn) for fn in functions]\n",
        "        if function_call is not None:\n",
        "            function_call = (\n",
        "                {\"name\": function_call}\n",
        "                if isinstance(function_call, str)\n",
        "                and function_call not in (\"auto\", \"none\")\n",
        "                else function_call\n",
        "            )\n",
        "            if isinstance(function_call, dict) and len(formatted_functions) != 1:\n",
        "                raise ValueError(\n",
        "                    \"When specifying `function_call`, you must provide exactly one \"\n",
        "                    \"function.\"\n",
        "                )\n",
        "            if (\n",
        "                isinstance(function_call, dict)\n",
        "                and formatted_functions[0][\"name\"] != function_call[\"name\"]\n",
        "            ):\n",
        "                raise ValueError(\n",
        "                    f\"Function call {function_call} was specified, but the only \"\n",
        "                    f\"provided function was {formatted_functions[0]['name']}.\"\n",
        "                )\n",
        "            kwargs = {**kwargs, \"function_call\": function_call}\n",
        "        return super().bind(\n",
        "            functions=formatted_functions,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "    def bind_tools(\n",
        "        self,\n",
        "        tools: Sequence[Union[Dict[str, Any], Type[BaseModel], Callable, BaseTool]],\n",
        "        *,\n",
        "        tool_choice: Optional[\n",
        "            Union[dict, str, Literal[\"auto\", \"any\", \"none\"], bool]\n",
        "        ] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> Runnable[LanguageModelInput, BaseMessage]:\n",
        "        \"\"\"Bind tool-like objects to this chat model.\n",
        "\n",
        "        Args:\n",
        "            tools: A list of tool definitions to bind to this chat model.\n",
        "                Supports any tool definition handled by\n",
        "                :meth:`langchain_core.utils.function_calling.convert_to_openai_tool`.\n",
        "            tool_choice: Which tool to require the model to call.\n",
        "                Must be the name of the single provided function,\n",
        "                \"auto\" to automatically determine which function to call\n",
        "                with the option to not call any function, \"any\" to enforce that some\n",
        "                function is called, or a dict of the form:\n",
        "                {\"type\": \"function\", \"function\": {\"name\": <<tool_name>>}}.\n",
        "            **kwargs: Any additional parameters to pass to the\n",
        "                :class:`~langchain.runnable.Runnable` constructor.\n",
        "        \"\"\"\n",
        "\n",
        "        formatted_tools = [convert_to_openai_tool(tool) for tool in tools]\n",
        "        if tool_choice is not None and tool_choice:\n",
        "            if tool_choice == \"any\":\n",
        "                tool_choice = \"required\"\n",
        "            if isinstance(tool_choice, str) and (\n",
        "                tool_choice not in (\"auto\", \"none\", \"required\")\n",
        "            ):\n",
        "                tool_choice = {\"type\": \"function\", \"function\": {\"name\": tool_choice}}\n",
        "            if isinstance(tool_choice, bool):\n",
        "                if len(tools) > 1:\n",
        "                    raise ValueError(\n",
        "                        \"tool_choice can only be True when there is one tool. Received \"\n",
        "                        f\"{len(tools)} tools.\"\n",
        "                    )\n",
        "                tool_name = formatted_tools[0][\"function\"][\"name\"]\n",
        "                tool_choice = {\n",
        "                    \"type\": \"function\",\n",
        "                    \"function\": {\"name\": tool_name},\n",
        "                }\n",
        "\n",
        "            kwargs[\"tool_choice\"] = tool_choice\n",
        "        return super().bind(tools=formatted_tools, **kwargs)\n",
        "\n",
        "    def with_structured_output(\n",
        "        self,\n",
        "        schema: Optional[Union[Dict, Type[BaseModel]]] = None,\n",
        "        *,\n",
        "        method: Literal[\"function_calling\", \"json_mode\"] = \"function_calling\",\n",
        "        include_raw: bool = False,\n",
        "        **kwargs: Any,\n",
        "    ) -> Runnable[LanguageModelInput, Union[Dict, BaseModel]]:\n",
        "        if kwargs:\n",
        "            raise ValueError(f\"Received unsupported arguments {kwargs}\")\n",
        "        is_pydantic_schema = _is_pydantic_class(schema)\n",
        "        if method == \"function_calling\":\n",
        "            if schema is None:\n",
        "                raise ValueError(\n",
        "                    \"schema must be specified when method is 'function_calling'. \"\n",
        "                    \"Received None.\"\n",
        "                )\n",
        "            formatted_tool = convert_to_openai_tool(schema)\n",
        "            tool_name = formatted_tool[\"function\"][\"name\"]\n",
        "            llm = self.bind_tools(\n",
        "                [schema],\n",
        "                tool_choice=tool_name,\n",
        "                structured_output_format={\n",
        "                    \"kwargs\": {\"method\": \"function_calling\"},\n",
        "                    \"schema\": formatted_tool,\n",
        "                },\n",
        "            )\n",
        "            if is_pydantic_schema:\n",
        "                output_parser: OutputParserLike = PydanticToolsParser(\n",
        "                    tools=[schema],  # type: ignore[list-item]\n",
        "                    first_tool_only=True,  # type: ignore[list-item]\n",
        "                )\n",
        "            else:\n",
        "                output_parser = JsonOutputKeyToolsParser(\n",
        "                    key_name=tool_name, first_tool_only=True\n",
        "                )\n",
        "        elif method == \"json_mode\":\n",
        "            llm = self.bind(\n",
        "                response_format={\"type\": \"json_object\"},\n",
        "                structured_output_format={\n",
        "                    \"kwargs\": {\"method\": \"json_mode\"},\n",
        "                    \"schema\": schema,\n",
        "                },\n",
        "            )\n",
        "            output_parser = (\n",
        "                PydanticOutputParser(pydantic_object=schema)  # type: ignore[type-var, arg-type]\n",
        "                if is_pydantic_schema\n",
        "                else JsonOutputParser()\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                f\"Unrecognized method argument. Expected one of 'function_calling' or \"\n",
        "                f\"'json_mode'. Received: '{method}'\"\n",
        "            )\n",
        "\n",
        "        if include_raw:\n",
        "            parser_assign = RunnablePassthrough.assign(\n",
        "                parsed=itemgetter(\"raw\") | output_parser, parsing_error=lambda _: None\n",
        "            )\n",
        "            parser_none = RunnablePassthrough.assign(parsed=lambda _: None)\n",
        "            parser_with_fallback = parser_assign.with_fallbacks(\n",
        "                [parser_none], exception_key=\"parsing_error\"\n",
        "            )\n",
        "            return RunnableMap(raw=llm) | parser_with_fallback\n",
        "        else:\n",
        "            return llm | output_parser\n",
        "\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        \"\"\"Return the type of chat model.\"\"\"\n",
        "        return \"vllm\""
      ],
      "metadata": {
        "id": "4I3MjgGGcDWp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangGraph"
      ],
      "metadata": {
        "id": "k7soxxBDs_qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GROQ_API_KEY = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "# Initialize Groq LLM\n",
        "model = ChatGroq(\n",
        "    model_name=\"deepseek-r1-distill-llama-70b\",\n",
        "    temperature=0.6,\n",
        "    api_key=GROQ_API_KEY,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(model.invoke(\"Who are you?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyup3FLGDE34",
        "outputId": "45e4ecbe-7f5d-4601-ba00-5899c7099d0b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"<think>\\n\\n</think>\\n\\nGreetings! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 7, 'total_tokens': 51, 'completion_time': 0.16, 'prompt_time': 0.003513417, 'queue_time': 0.23902688600000002, 'total_time': 0.163513417}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_9397364173', 'finish_reason': 'stop', 'logprobs': None} id='run-e08f9d14-b865-417e-ace0-6b5984079e5f-0' usage_metadata={'input_tokens': 7, 'output_tokens': 44, 'total_tokens': 51}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train of Thought Prompt Template\n",
        "system_message = \"\"\"\n",
        "[SYSTEM PROMPT]\n",
        "\n",
        "You are an AI Tutor whose purpose is to assist and educate the Human. You should:\n",
        "\n",
        "1. **Reason in a structured, step-by-step manner** (chain-of-thought). This involves:\n",
        "   - Carefully thinking through the question.\n",
        "   - Breaking down any complex tasks into smaller parts.\n",
        "   - Combining background knowledge and context.\n",
        "   - Identifying which (if any) tools might help answer or clarify the question.\n",
        "\n",
        "2. If a **tool** is required, you must:\n",
        "   - Clearly identify why you need the tool.\n",
        "   - Indicate the exact tool call (for example: “Use the [Tool Name] tool with the input: ...”).\n",
        "   - Only use tools you actually need. If you can determine the answer without a tool, you may proceed without calling it.\n",
        "\n",
        "3. **Keep your step-by-step reasoning private** (hidden from the user). Only share a concise, student-friendly explanation or final answer in your public response.\n",
        "   - If the user explicitly wants to see your reasoning, you can provide it in a summarized or simplified way, but do not reveal your entire chain-of-thought verbatim.\n",
        "   - This helps maintain clarity and avoids confusion.\n",
        "\n",
        "4. **Offer thorough, correct, and helpful answers**:\n",
        "   - If the user’s question is unclear, ask clarifying questions.\n",
        "   - If the answer may be improved by additional details or examples, provide them.\n",
        "   - If you need a deeper check on any piece of data, consider calling a tool (e.g. a knowledge base, web search, calculator, code executor, etc.) if it’s available.\n",
        "\n",
        "5. **Structure** of your final message:\n",
        "   - Provide a **clear and concise** answer or explanation.\n",
        "   - If you performed internal reasoning and/or tool calls, do not reveal those verbatim.\n",
        "     Instead, present only the final synthesized answer or, if relevant, a short summary of your thought process.\n",
        "   - If a user specifically requests how you arrived at the answer, provide a high-level summary of your reasoning steps without divulging every internal detail.\n",
        "\n",
        "6. **Constraints**:\n",
        "   - If you are uncertain, express your uncertainty rather than providing false information.\n",
        "   - Keep your language constructive, encouraging, and educational.\n",
        "   - Follow any other platform or policy guidelines.\n",
        "\n",
        "7. **Final Response**\n",
        "   - Develop your reasoning (Chain-of-Thought) as concise as possible without affecting the quality of your responses.\n",
        "   - After you have draw your conclusion, give your final response starting with the tag <FINAL_RESPONSE> and end the conversation.\n",
        "   - If you have no conclusion or do not have answer to the Human, say so for <FINAL_RESPONSE> and end the conversation.\n",
        "\n",
        "[END SYSTEM PROMPT]\n",
        "\"\"\"\n",
        "\n",
        "# prompt_template =[\n",
        "#     {\"role\": \"system\", \"content\": system_message},\n",
        "#     {\"role\": \"user\", \"content\": \"{question}\"},\n",
        "#     {\"role\": \"assistant\", \"content\": \"{answer}\"},\n",
        "#     ]\n",
        "\n"
      ],
      "metadata": {
        "id": "vMc6D9AwkDzM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "SXMyAFM6bSiz",
        "outputId": "8be853e5-2fee-4b0b-a6af-3d46302fa3da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-cd98a24b762a>:36: LangChainBetaWarning: The function `init_embeddings` is in beta. It is actively being worked on, so the API may change.\n",
            "  \"embed\": init_embeddings(\"huggingface:sentence-transformers/all-MiniLM-L6-v2\"),\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import json\n",
        "from typing import (\n",
        "    Annotated,\n",
        "    Sequence,\n",
        "    TypedDict,\n",
        "    List,\n",
        ")\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# LangChain / LangGraph imports\n",
        "from langchain_core.messages import (\n",
        "    SystemMessage,\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    BaseMessage,\n",
        "    ToolMessage,\n",
        ")\n",
        "from langchain_core.tools import StructuredTool\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "\n",
        "from langgraph.prebuilt import InjectedStore\n",
        "from langgraph.store.base import BaseStore\n",
        "from langgraph.store.memory import InMemoryStore\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain.embeddings import init_embeddings\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "###############################################################################\n",
        "# 1. Initialize memory + config\n",
        "###############################################################################\n",
        "in_memory_store = InMemoryStore(\n",
        "    index={\n",
        "        \"embed\": init_embeddings(\"huggingface:sentence-transformers/all-MiniLM-L6-v2\"),\n",
        "        \"dims\": 384,  # Embedding dimensions\n",
        "    }\n",
        ")\n",
        "\n",
        "# A memory saver to checkpoint conversation states\n",
        "checkpointer = MemorySaver()\n",
        "\n",
        "# Initialize config with user & thread info\n",
        "config = {}\n",
        "config[\"configurable\"] = {\n",
        "    \"user_id\": \"user_1\",\n",
        "    \"thread_id\": 0,\n",
        "}\n",
        "\n",
        "###############################################################################\n",
        "# 2. Define MessagesState\n",
        "###############################################################################\n",
        "class MessagesState(TypedDict):\n",
        "    \"\"\"The state of the agent.\n",
        "\n",
        "    The key 'messages' uses add_messages as a reducer,\n",
        "    so each time this state is updated, new messages are appended.\n",
        "    # See https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers\n",
        "    \"\"\"\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 3. Memory Tools\n",
        "###############################################################################\n",
        "def save_memory(summary_text: str, *, config: RunnableConfig, store: BaseStore) -> str:\n",
        "    \"\"\"Save the given memory for the current user and return the key.\"\"\"\n",
        "    user_id = config.get(\"configurable\", {}).get(\"user_id\")\n",
        "    thread_id = config.get(\"configurable\", {}).get(\"thread_id\")\n",
        "    namespace = (user_id, \"memories\")\n",
        "    memory_id = thread_id\n",
        "    store.put(namespace, memory_id, {\"summary\": summary_text})\n",
        "    return memory_id\n",
        "\n",
        "def update_memory(state: MessagesState, config: RunnableConfig, *, store: BaseStore):\n",
        "    # Extract the messages list from the event, handling potential missing key\n",
        "    messages = state[\"messages\"]\n",
        "    # Convert LangChain messages to dictionaries before storing\n",
        "    messages_as_dicts = [_convert_message_to_dict(msg) for msg in messages]\n",
        "\n",
        "    # Get the user id from the config\n",
        "    user_id = config.get(\"configurable\", {}).get(\"user_id\")\n",
        "    thread_id = config.get(\"configurable\", {}).get(\"thread_id\")\n",
        "    # Namespace the memory\n",
        "    namespace = (user_id, \"memories\")\n",
        "    # Create a new memory ID\n",
        "    memory_id = f\"{thread_id}_{str(uuid.uuid4())}\"\n",
        "    store.put(namespace, memory_id, {\"memory\": messages_as_dicts})\n",
        "    return memory_id\n",
        "\n",
        "\n",
        "# Define a Pydantic schema for the save_memory tool (if needed elsewhere)\n",
        "# https://langchain-ai.github.io/langgraphjs/reference/classes/checkpoint.InMemoryStore.html\n",
        "class RecallMemory(BaseModel):\n",
        "    query_text: str = Field(..., title=\"Search Text\", description=\"The text to search from memories for similar records.\")\n",
        "    k: int = Field(5, title=\"Number of Results\", description=\"Number of results to retrieve.\")\n",
        "\n",
        "def recall_memory(query_text: str, k: int = 5) -> str:\n",
        "    \"\"\"Retrieve user memories from in_memory_store.\"\"\"\n",
        "    user_id = config.get(\"configurable\", {}).get(\"user_id\")\n",
        "    namespace = (user_id, \"memories\")\n",
        "\n",
        "    memories = [m.value[\"data\"] for m in in_memory_store.search(namespace=namespace, query=query_text, limit=k)]\n",
        "    joined = f\"User memories: {', '.join(memories)}\"\n",
        "    return joined\n",
        "\n",
        "# Create a StructuredTool from the function\n",
        "recall_memory_tool = StructuredTool.from_function(\n",
        "    func=recall_memory,\n",
        "    name=\"Recall Memory Tool\",\n",
        "    description=\"\"\"\n",
        "      Retrieve memories relevant to the user's query.\n",
        "      \"\"\",\n",
        "    args_schema=RecallMemory,\n",
        "    response_format=\"content\",\n",
        "    return_direct=False,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "###############################################################################\n",
        "# 4. Summarize Node (using StructuredTool)\n",
        "###############################################################################\n",
        "# Define a Pydantic schema for the Summary tool\n",
        "class SummariseConversation(BaseModel):\n",
        "    summary_text: str = Field(..., title=\"text\", description=\"Summary of Conversation\")\n",
        "\n",
        "def summarise_node(summary_text: str):\n",
        "    \"\"\"\n",
        "    Final node that summarizes the entire conversation for the current thread,\n",
        "    saves it in memory, increments the thread_id, and ends the conversation.\n",
        "    Returns a confirmation string.\n",
        "    \"\"\"\n",
        "    user_id = config[\"configurable\"][\"user_id\"]\n",
        "    current_thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "    new_thread_id = str(int(current_thread_id) + 1)\n",
        "\n",
        "    # Prepare configuration for saving memory with updated thread id\n",
        "    config_for_saving = {\n",
        "        \"configurable\": {\n",
        "            \"user_id\": user_id,\n",
        "            \"thread_id\": new_thread_id\n",
        "        }\n",
        "    }\n",
        "    key = save_memory(summary_text, config=config_for_saving, store=in_memory_store)\n",
        "    return f\"Summary saved under key: {key}\"\n",
        "\n",
        "# Create a StructuredTool from the function (this wraps summarise_node)\n",
        "summarise_tool = StructuredTool.from_function(\n",
        "    func=summarise_node,\n",
        "    name=\"Summary Tool\",\n",
        "    description=\"\"\"\n",
        "      Summarize the current conversation in no more than\n",
        "      1000 words. Also retain any unanswered quiz questions along with\n",
        "      your internal answers so the next conversation thread can continue.\n",
        "      Do not reveal solutions to the user yet. Use this tool to save\n",
        "      the current conversation to memory and then end the conversation.\n",
        "      \"\"\",\n",
        "    args_schema=SummariseConversation,\n",
        "    response_format=\"content\",\n",
        "    return_direct=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "###############################################################################\n",
        "# 5. Build the Graph\n",
        "###############################################################################\n",
        "graph_builder = StateGraph(MessagesState)\n",
        "\n",
        "# Use the built-in ToolNode from langgraph that calls any declared tools.\n",
        "tools = [\n",
        "    mcq_retriever_tool,\n",
        "    web_extraction_tool,\n",
        "    ensemble_retriever_tool,\n",
        "    general_retriever_tool,\n",
        "    in_memory_retriever_tool,\n",
        "    recall_memory_tool,\n",
        "    summarise_tool,  # Use the StructuredTool version, not the raw function\n",
        "]\n",
        "\n",
        "tool_node = ToolNode(tools=tools)\n",
        "end_node = ToolNode(tools=[summarise_tool])  # Use summarise_tool for end node\n",
        "\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "# Wrap the Custom ChatvLLM over the base_vllm model\n",
        "#model = BaseChat_vLLMWrapper(base_vllm)\n",
        "\n",
        "\n",
        "# Wrap your model with tools\n",
        "llm_with_tools = model.bind_tools(tools)\n",
        "\n",
        "###############################################################################\n",
        "# 6. The agent's main node: call_model\n",
        "###############################################################################\n",
        "def call_model(state: MessagesState, config: RunnableConfig):\n",
        "    \"\"\"\n",
        "    The main agent node that calls the LLM with the user + system messages.\n",
        "    Since our vLLM chat wrapper expects a list of BaseMessage objects,\n",
        "    we convert any dict messages to HumanMessage objects.\n",
        "    If the LLM requests a tool call, we'll route to the 'tools' node next\n",
        "    (depending on the condition).\n",
        "    \"\"\"\n",
        "    # Convert message dicts to HumanMessage instances if needed.\n",
        "    messages = []\n",
        "    for m in state[\"messages\"]:\n",
        "        if isinstance(m, dict):\n",
        "            # Use role from dict (defaulting to 'user' if missing)\n",
        "            messages.append(HumanMessage(content=m.get(\"content\", \"\"), role=m.get(\"role\", \"user\")))\n",
        "        else:\n",
        "            messages.append(m)\n",
        "\n",
        "    # Invoke the LLM (with tools) using the converted messages.\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "###############################################################################\n",
        "# 7. Add Nodes & Edges, Then Compile\n",
        "###############################################################################\n",
        "graph_builder.add_node(\"agent\", call_model)\n",
        "graph_builder.add_node(\"tools\", tool_node)\n",
        "graph_builder.add_node(\"summary\", end_node)\n",
        "\n",
        "# Entry point\n",
        "graph_builder.set_entry_point(\"agent\")\n",
        "\n",
        "# def custom_tools_condition(llm_output: dict) -> str:\n",
        "#     \"\"\"Return which node to go to next based on the LLM output.\"\"\"\n",
        "\n",
        "#     # The LLM's JSON might have a field like {\"name\": \"Recall Memory Tool\", \"arguments\": {...}}.\n",
        "#     tool_name = llm_output.get(\"name\", None)\n",
        "\n",
        "#     # If the LLM calls \"Summary Tool\", jump directly to the 'summary' node\n",
        "#     if tool_name == \"Summary Tool\":\n",
        "#         return \"summary\"\n",
        "\n",
        "#     # If the LLM calls any other recognized tool, go to 'tools'\n",
        "#     valid_tool_names = [t.name for t in tools]  # all tools in the main tool_node\n",
        "#     if tool_name in valid_tool_names:\n",
        "#         return \"tools\"\n",
        "\n",
        "#     # If there's no recognized tool name, assume we're done => go to summary\n",
        "#     return \"__end__\"\n",
        "\n",
        "# graph_builder.add_conditional_edges(\n",
        "#     \"agent\",\n",
        "#     custom_tools_condition,\n",
        "#     {\n",
        "#         \"tools\": \"tools\",\n",
        "#         \"summary\": \"summary\",\n",
        "#         \"__end__\": \"summary\",\n",
        "#     }\n",
        "# )\n",
        "\n",
        "# If LLM requests a tool, go to \"tools\", otherwise go to \"summary\"\n",
        "graph_builder.add_conditional_edges(\"agent\", tools_condition, {\"tools\": \"tools\", \"__end__\": \"summary\"})\n",
        "#graph_builder.add_conditional_edges(\"agent\", lambda llm_output: \"tools\" if llm_output.get(\"name\", None) in [t.name for t in tools] else \"summary\", {\"tools\": \"tools\", \"__end__\": \"summary\"}\n",
        "\n",
        "# If we used a tool, return to the agent for final answer or more tools\n",
        "graph_builder.add_edge(\"tools\", \"agent\")\n",
        "graph_builder.add_edge(\"agent\", \"summary\")\n",
        "graph_builder.set_finish_point(\"summary\")\n",
        "\n",
        "# Compile the graph with checkpointing and persistent store\n",
        "graph = graph_builder.compile(checkpointer=checkpointer, store=in_memory_store)\n",
        "\n",
        "#from langgraph.prebuilt import create_react_agent\n",
        "#graph = create_react_agent(llm_with_tools, tools=tool_node, checkpointer=checkpointer, store=in_memory_store)\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image(graph.get_graph().draw_mermaid_png()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Questions"
      ],
      "metadata": {
        "id": "VVugyLKTfrS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2hbnTzV8d8po",
        "outputId": "37ae73f0-c8b6-49ea-dce4-ceab0feb7d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation Thread ID: 2 -> 3\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Provide 5 MCQ questions on Artificial Intelligence to help me with practice.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  MCQ Retrieval Tool (call_n6we)\n",
            " Call ID: call_n6we\n",
            "  Args:\n",
            "    input: Artificial Intelligence\n",
            "    k: 5\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: MCQ Retrieval Tool\n",
            "\n",
            "{\"./Documents/mcq/mcq.csv_Qn2 mcq_question\": \"Your organization is developing a decision support solution to monitor data for anomalies and deliver real-time insights to stakeholders. The solution requires continuous monitoring and automated alerts for deviations from expected patterns. Which Azure AI service should you select to implement the data monitoring aspect effectively?\", \"./Documents/mcq/mcq.csv_Qn2 mcq_answer\": \"Answer - [A] Azure AI Metrics Advisor\", \"./Documents/mcq/mcq.csv_Qn2 mcq_answer_reason\": \"Option A - Azure AI Metrics Advisor: Specifically designed for real-time anomaly detection and continuous data monitoring, making it the best fit for the given scenario.|EXAM FOCUS - Always remember to use Azure AI Metrics Advisor for real-time data monitoring and anomaly detection. Make sure the solution is set up to continuously monitor data streams to detect deviations early.|CAUTION ALERT - Stay alert to not mistakenly select services like Video Indexer or Text Analytics for tasks that require continuous data monitoring, as they do not provide the real-time capabilities needed.\", \"./Documents/mcq/mcq.csv_Qn2 mcq_options\": \"Option A) Azure AI Metrics Advisor |Option B) Azure AI Content Moderator |Option C) Azure AI Video Indexer |Option D) Azure AI Text Analytics |Option E) Azure AI Language Understanding (LUIS)\", \"./Documents/mcq/mcq.csv_Qn2 mcq_wrong_option_reason\": \"Option B - Azure AI Content Moderator: Designed for content moderation tasks such as detecting offensive content, not suitable for data monitoring.|Option C - Azure AI Video Indexer: Used for extracting insights from videos, not tailored for continuous data monitoring.|Option D - Azure AI Text Analytics: Primarily for text analysis tasks like sentiment analysis, not suited for data monitoring.|Option E - Azure AI Language Understanding (LUIS): Focused on building conversational AI applications, not intended for data monitoring.\", \"./Documents/mcq/mcq.csv_Qn16 mcq_question\": \"You are developing an AI solution for a document management system that requires extracting text from images of various documents. Which method is commonly used for text extraction from images, especially when dealing with complex backgrounds and layouts?\", \"./Documents/mcq/mcq.csv_Qn16 mcq_answer\": \"Answer - [A] Optical Character Recognition (OCR).\", \"./Documents/mcq/mcq.csv_Qn16 mcq_answer_reason\": \"EXAM FOCUS - Always remember that OCR is the go-to method for extracting text from images with complex backgrounds and layouts. You can rely on OCR for highly accurate text extraction in document management systems.|CAUTION ALERT - Avoid assuming that Azure Form Recognizer is the best solution for text extraction in this scenario. Stay alert to the difference between extracting structured data from forms and raw text from images.\", \"./Documents/mcq/mcq.csv_Qn16 mcq_options\": \"Option A) Optical Character Recognition (OCR) |Option B) Azure AI Form Recognizer |Option C) Rule-based parsing |Option D) Semantic analysis |Option E) Azure AI Computer Vision API.\", \"./Documents/mcq/mcq.csv_Qn16 mcq_wrong_option_reason\": \"Option B - Azure AI Form Recognizer is designed for structured form data extraction, not general OCR.|Option C - Rule-based parsing requires predefined rules and lacks flexibility for complex image backgrounds.|Option D - Semantic analysis is used for text understanding, not extraction.|Option E - Azure AI Computer Vision API provides OCR but is not as robust as dedicated OCR solutions for complex document layouts.\", \"./Documents/mcq/mcq.csv_Qn50 mcq_question\": \"You are designing an AI-driven recommendation system for an e-commerce platform that utilizes generative AI to suggest personalized product bundles to customers. Which architectural consideration should you prioritize to ensure seamless integration of generative AI into the solution while meeting scalability requirements? Select all answers that apply.\", \"./Documents/mcq/mcq.csv_Qn50 mcq_answer\": \"Answer - [A, C]\", \"./Documents/mcq/mcq.csv_Qn50 mcq_answer_reason\": \"Option A - Implementing a microservices architecture allows independent scaling of generative AI components.|Option C - Leveraging Azure Kubernetes Service (AKS) ensures efficient orchestration of containerized AI models.|EXAM FOCUS - You need to implement a microservices architecture and leverage Azure Kubernetes Service (AKS) for scalability in your generative AI solution. Always remember that AKS helps manage dynamic resource allocation for containerized models.|CAUTION ALERT - Stay clear of using serverless architectures for this task—they are better suited for event-driven processes, not AI model orchestration. Avoid thinking Azure Batch or Data Factory will address real-time scalability—they are more suitable for batch processing and data pipelines.\", \"./Documents/mcq/mcq.csv_Qn50 mcq_options\": \"Option A) Implementing a microservices architecture to modularize generative AI components and enable independent scaling of services. |Option B) Deploying a serverless architecture using Azure Functions to automatically scale resources based on demand. |Option C) Leveraging Azure Kubernetes Service (AKS) to orchestrate containerized generative AI models and manage resource allocation dynamically. |Option D) Utilizing Azure Batch to schedule and execute large-scale generative AI training jobs across distributed computing resources. |Option E) Implementing Azure Data Factory to orchestrate data pipelines and facilitate seamless data ingestion for generative AI models.\", \"./Documents/mcq/mcq.csv_Qn50 mcq_wrong_option_reason\": \"Option B - Serverless architectures work well for event-driven applications but may not provide optimal control over AI model orchestration.|Option D - Azure Batch is suited for scheduled workloads, not real-time AI inference.|Option E - Azure Data Factory is useful for data processing but does not manage AI model scalability.\", \"./Documents/mcq/mcq2.csv_Qn21 mcq_question\": \"You are building a solution that uses Azure AI Search. You need to create a skillset definition. What are minimum sections you should include in the definition?\", \"./Documents/mcq/mcq2.csv_Qn21 mcq_answer\": \"Answer - [A]\", \"./Documents/mcq/mcq2.csv_Qn21 mcq_answer_reason\": \" \", \"./Documents/mcq/mcq2.csv_Qn21 mcq_options\": \"Option A) name\", \"./Documents/mcq/mcq2.csv_Qn21 mcq_wrong_option_reason\": \" \", \"./Documents/mcq/mcq2.csv_Qn47 mcq_question\": \"Which type of AI skill extracts text from images in Azure AI Search?\", \"./Documents/mcq/mcq2.csv_Qn47 mcq_answer\": \"Answer - [A]\", \"./Documents/mcq/mcq2.csv_Qn47 mcq_answer_reason\": \" \", \"./Documents/mcq/mcq2.csv_Qn47 mcq_options\": \"Option A) OCR Skill|Option B) Entity Recognition Skill|Option C) Translation Skill|Option D) Key Phrase Extraction Skill\", \"./Documents/mcq/mcq2.csv_Qn47 mcq_wrong_option_reason\": \" \"}\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here are five multiple-choice questions (MCQs) related to Artificial Intelligence to help you practice:\n",
            "\n",
            "---\n",
            "\n",
            "### Question 1:  \n",
            "**Your organization is developing a decision support solution to monitor data for anomalies and deliver real-time insights to stakeholders. The solution requires continuous monitoring and automated alerts for deviations from expected patterns. Which Azure AI service should you select to implement the data monitoring aspect effectively?**\n",
            "\n",
            "A) Azure AI Metrics Advisor  \n",
            "B) Azure AI Content Moderator  \n",
            "C) Azure AI Video Indexer  \n",
            "D) Azure AI Text Analytics  \n",
            "E) Azure AI Language Understanding (LUIS)  \n",
            "\n",
            "**Answer:** A) Azure AI Metrics Advisor  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 2:  \n",
            "**You are developing an AI solution for a document management system that requires extracting text from images of various documents. Which method is commonly used for text extraction from images, especially when dealing with complex backgrounds and layouts?**\n",
            "\n",
            "A) Optical Character Recognition (OCR)  \n",
            "B) Azure AI Form Recognizer  \n",
            "C) Rule-based parsing  \n",
            "D) Semantic analysis  \n",
            "E) Azure AI Computer Vision API  \n",
            "\n",
            "**Answer:** A) Optical Character Recognition (OCR)  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 3:  \n",
            "**You are designing an AI-driven recommendation system for an e-commerce platform that utilizes generative AI to suggest personalized product bundles to customers. Which architectural consideration should you prioritize to ensure seamless integration of generative AI into the solution while meeting scalability requirements? Select all that apply.**\n",
            "\n",
            "A) Implementing a microservices architecture to modularize generative AI components and enable independent scaling of services.  \n",
            "B) Deploying a serverless architecture using Azure Functions to automatically scale resources based on demand.  \n",
            "C) Leveraging Azure Kubernetes Service (AKS) to orchestrate containerized generative AI models and manage resource allocation dynamically.  \n",
            "D) Utilizing Azure Batch to schedule and execute large-scale generative AI training jobs across distributed computing resources.  \n",
            "E) Implementing Azure Data Factory to orchestrate data pipelines and facilitate seamless data ingestion for generative AI models.  \n",
            "\n",
            "**Answer:** A and C  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 4:  \n",
            "**You are building a solution that uses Azure AI Search. You need to create a skillset definition. What is the minimum section you should include in the definition?**\n",
            "\n",
            "A) Name  \n",
            "B) Description  \n",
            "C) Context  \n",
            "D) Skills  \n",
            "E) None of the above  \n",
            "\n",
            "**Answer:** A) Name  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 5:  \n",
            "**Which type of AI skill extracts text from images in Azure AI Search?**\n",
            "\n",
            "A) OCR Skill  \n",
            "B) Entity Recognition Skill  \n",
            "C) Translation Skill  \n",
            "D) Key Phrase Extraction Skill  \n",
            "\n",
            "**Answer:** A) OCR Skill  \n",
            "\n",
            "---\n",
            "\n",
            "Let me know if you'd like me to explain any of the answers or provide more questions!\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here are five multiple-choice questions (MCQs) related to Artificial Intelligence to help you practice:\n",
            "\n",
            "---\n",
            "\n",
            "### Question 1:  \n",
            "**Your organization is developing a decision support solution to monitor data for anomalies and deliver real-time insights to stakeholders. The solution requires continuous monitoring and automated alerts for deviations from expected patterns. Which Azure AI service should you select to implement the data monitoring aspect effectively?**\n",
            "\n",
            "A) Azure AI Metrics Advisor  \n",
            "B) Azure AI Content Moderator  \n",
            "C) Azure AI Video Indexer  \n",
            "D) Azure AI Text Analytics  \n",
            "E) Azure AI Language Understanding (LUIS)  \n",
            "\n",
            "**Answer:** A) Azure AI Metrics Advisor  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 2:  \n",
            "**You are developing an AI solution for a document management system that requires extracting text from images of various documents. Which method is commonly used for text extraction from images, especially when dealing with complex backgrounds and layouts?**\n",
            "\n",
            "A) Optical Character Recognition (OCR)  \n",
            "B) Azure AI Form Recognizer  \n",
            "C) Rule-based parsing  \n",
            "D) Semantic analysis  \n",
            "E) Azure AI Computer Vision API  \n",
            "\n",
            "**Answer:** A) Optical Character Recognition (OCR)  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 3:  \n",
            "**You are designing an AI-driven recommendation system for an e-commerce platform that utilizes generative AI to suggest personalized product bundles to customers. Which architectural consideration should you prioritize to ensure seamless integration of generative AI into the solution while meeting scalability requirements? Select all that apply.**\n",
            "\n",
            "A) Implementing a microservices architecture to modularize generative AI components and enable independent scaling of services.  \n",
            "B) Deploying a serverless architecture using Azure Functions to automatically scale resources based on demand.  \n",
            "C) Leveraging Azure Kubernetes Service (AKS) to orchestrate containerized generative AI models and manage resource allocation dynamically.  \n",
            "D) Utilizing Azure Batch to schedule and execute large-scale generative AI training jobs across distributed computing resources.  \n",
            "E) Implementing Azure Data Factory to orchestrate data pipelines and facilitate seamless data ingestion for generative AI models.  \n",
            "\n",
            "**Answer:** A and C  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 4:  \n",
            "**You are building a solution that uses Azure AI Search. You need to create a skillset definition. What is the minimum section you should include in the definition?**\n",
            "\n",
            "A) Name  \n",
            "B) Description  \n",
            "C) Context  \n",
            "D) Skills  \n",
            "E) None of the above  \n",
            "\n",
            "**Answer:** A) Name  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 5:  \n",
            "**Which type of AI skill extracts text from images in Azure AI Search?**\n",
            "\n",
            "A) OCR Skill  \n",
            "B) Entity Recognition Skill  \n",
            "C) Translation Skill  \n",
            "D) Key Phrase Extraction Skill  \n",
            "\n",
            "**Answer:** A) OCR Skill  \n",
            "\n",
            "---\n",
            "\n",
            "Let me know if you'd like me to explain any of the answers or provide more questions!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3_cf5fd8ed-229c-48f7-82b4-92fb472ffe71'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# URL\n",
        "url1 = \"https://www.ibm.com/think/topics/artificial-intelligence\"\n",
        "url2 = \"https://www.ibm.com/think/topics/machine-learning\"\n",
        "\n",
        "question_1 = (f\"Find out about Deep Learning from databases. Then search from website: {url1} and {url2} with web extraction tool\")\n",
        "question_2 = \"Provide 5 MCQ questions on Artificial Intelligence to help me with practice.\"\n",
        "question_3 = \"Here are my answers: 1. A, 2. B, 3. C, 4. D, 5. E. Please check mu answer, provide reasons for my wrong answers and provide the correct answers with explanations.\"\n",
        "question_4 = \"Provide another 5 MCQ questions on Artificial Intelligence to help me with practice.\"\n",
        "question_5 = \"Here are my answers: 1. A, 2. B, 3. C, 4. D, 5. E. Please check mu answer, provide reasons for my wrong answers and provide the correct answers with explanations.\"\n",
        "question_6 = \"Provide a study quide to help me learn for my wrong answers for the MCQ questions.\"\n",
        "question_7 = \"Based on your reference databases only, provide a study quide on Deep Learning.\"\n",
        "question_8 = \"Based on your memory, provide a summary of our conversation.\"\n",
        "question_9 = \"Summarise the conversation so far.\"\n",
        "\n",
        "# Grab the current user_id and thread_id from config\n",
        "user_id = \"user_1\"\n",
        "\n",
        "# Get last thread_id\n",
        "last_thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "thread_id = str(int(last_thread_id) + 1)\n",
        "\n",
        "# Print Config\n",
        "print(f\"Conversation Thread ID: {last_thread_id} -> {thread_id}\")\n",
        "\n",
        "# Update the config with the new thread_id\n",
        "config = {\"configurable\": {\"thread_id\": thread_id, \"user_id\": user_id}}\n",
        "\n",
        "\n",
        "# Create a system prompt (your overall instructions to the AI)\n",
        "system_msg = SystemMessage(content=\"\"\"\n",
        "You are a helpful AI Tutor assistant.\n",
        "After response to Human, call for Summary Tool to END.\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "#The config is the **second positional argument** to stream() or invoke()!\n",
        "events = graph.stream(\n",
        "    {\"messages\": [\n",
        "        #{\"role\": \"system\", \"content\": system_msg.content},\n",
        "        {\"role\": \"user\", \"content\": question_2}]},\n",
        "    config, # Pass the thread-level persistence to the graph\n",
        "    stream_mode=\"values\",\n",
        ")\n",
        "for event in events:\n",
        "    ai_response = event[\"messages\"][-1]\n",
        "    ai_response.pretty_print()\n",
        "\n",
        "update_memory(event, config, store=in_memory_store) # Update Memory\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ai_response.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSTkSlmpfdSI",
        "outputId": "3690c8dc-6f6f-4154-c614-ebed252e85d4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Here are five multiple-choice questions (MCQs) related to Artificial Intelligence to help you practice:\n",
            "\n",
            "---\n",
            "\n",
            "### Question 1:  \n",
            "**Your organization is developing a decision support solution to monitor data for anomalies and deliver real-time insights to stakeholders. The solution requires continuous monitoring and automated alerts for deviations from expected patterns. Which Azure AI service should you select to implement the data monitoring aspect effectively?**\n",
            "\n",
            "A) Azure AI Metrics Advisor  \n",
            "B) Azure AI Content Moderator  \n",
            "C) Azure AI Video Indexer  \n",
            "D) Azure AI Text Analytics  \n",
            "E) Azure AI Language Understanding (LUIS)  \n",
            "\n",
            "**Answer:** A) Azure AI Metrics Advisor  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 2:  \n",
            "**You are developing an AI solution for a document management system that requires extracting text from images of various documents. Which method is commonly used for text extraction from images, especially when dealing with complex backgrounds and layouts?**\n",
            "\n",
            "A) Optical Character Recognition (OCR)  \n",
            "B) Azure AI Form Recognizer  \n",
            "C) Rule-based parsing  \n",
            "D) Semantic analysis  \n",
            "E) Azure AI Computer Vision API  \n",
            "\n",
            "**Answer:** A) Optical Character Recognition (OCR)  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 3:  \n",
            "**You are designing an AI-driven recommendation system for an e-commerce platform that utilizes generative AI to suggest personalized product bundles to customers. Which architectural consideration should you prioritize to ensure seamless integration of generative AI into the solution while meeting scalability requirements? Select all that apply.**\n",
            "\n",
            "A) Implementing a microservices architecture to modularize generative AI components and enable independent scaling of services.  \n",
            "B) Deploying a serverless architecture using Azure Functions to automatically scale resources based on demand.  \n",
            "C) Leveraging Azure Kubernetes Service (AKS) to orchestrate containerized generative AI models and manage resource allocation dynamically.  \n",
            "D) Utilizing Azure Batch to schedule and execute large-scale generative AI training jobs across distributed computing resources.  \n",
            "E) Implementing Azure Data Factory to orchestrate data pipelines and facilitate seamless data ingestion for generative AI models.  \n",
            "\n",
            "**Answer:** A and C  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 4:  \n",
            "**You are building a solution that uses Azure AI Search. You need to create a skillset definition. What is the minimum section you should include in the definition?**\n",
            "\n",
            "A) Name  \n",
            "B) Description  \n",
            "C) Context  \n",
            "D) Skills  \n",
            "E) None of the above  \n",
            "\n",
            "**Answer:** A) Name  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 5:  \n",
            "**Which type of AI skill extracts text from images in Azure AI Search?**\n",
            "\n",
            "A) OCR Skill  \n",
            "B) Entity Recognition Skill  \n",
            "C) Translation Skill  \n",
            "D) Key Phrase Extraction Skill  \n",
            "\n",
            "**Answer:** A) OCR Skill  \n",
            "\n",
            "---\n",
            "\n",
            "Let me know if you'd like me to explain any of the answers or provide more questions!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ai_response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-AGGGUcig_q",
        "outputId": "a6351ca9-e207-4c44-fe1e-850f1118b259"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are five multiple-choice questions (MCQs) related to Artificial Intelligence to help you practice:\n",
            "\n",
            "---\n",
            "\n",
            "### Question 1:  \n",
            "**Your organization is developing a decision support solution to monitor data for anomalies and deliver real-time insights to stakeholders. The solution requires continuous monitoring and automated alerts for deviations from expected patterns. Which Azure AI service should you select to implement the data monitoring aspect effectively?**\n",
            "\n",
            "A) Azure AI Metrics Advisor  \n",
            "B) Azure AI Content Moderator  \n",
            "C) Azure AI Video Indexer  \n",
            "D) Azure AI Text Analytics  \n",
            "E) Azure AI Language Understanding (LUIS)  \n",
            "\n",
            "**Answer:** A) Azure AI Metrics Advisor  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 2:  \n",
            "**You are developing an AI solution for a document management system that requires extracting text from images of various documents. Which method is commonly used for text extraction from images, especially when dealing with complex backgrounds and layouts?**\n",
            "\n",
            "A) Optical Character Recognition (OCR)  \n",
            "B) Azure AI Form Recognizer  \n",
            "C) Rule-based parsing  \n",
            "D) Semantic analysis  \n",
            "E) Azure AI Computer Vision API  \n",
            "\n",
            "**Answer:** A) Optical Character Recognition (OCR)  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 3:  \n",
            "**You are designing an AI-driven recommendation system for an e-commerce platform that utilizes generative AI to suggest personalized product bundles to customers. Which architectural consideration should you prioritize to ensure seamless integration of generative AI into the solution while meeting scalability requirements? Select all that apply.**\n",
            "\n",
            "A) Implementing a microservices architecture to modularize generative AI components and enable independent scaling of services.  \n",
            "B) Deploying a serverless architecture using Azure Functions to automatically scale resources based on demand.  \n",
            "C) Leveraging Azure Kubernetes Service (AKS) to orchestrate containerized generative AI models and manage resource allocation dynamically.  \n",
            "D) Utilizing Azure Batch to schedule and execute large-scale generative AI training jobs across distributed computing resources.  \n",
            "E) Implementing Azure Data Factory to orchestrate data pipelines and facilitate seamless data ingestion for generative AI models.  \n",
            "\n",
            "**Answer:** A and C  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 4:  \n",
            "**You are building a solution that uses Azure AI Search. You need to create a skillset definition. What is the minimum section you should include in the definition?**\n",
            "\n",
            "A) Name  \n",
            "B) Description  \n",
            "C) Context  \n",
            "D) Skills  \n",
            "E) None of the above  \n",
            "\n",
            "**Answer:** A) Name  \n",
            "\n",
            "---\n",
            "\n",
            "### Question 5:  \n",
            "**Which type of AI skill extracts text from images in Azure AI Search?**\n",
            "\n",
            "A) OCR Skill  \n",
            "B) Entity Recognition Skill  \n",
            "C) Translation Skill  \n",
            "D) Key Phrase Extraction Skill  \n",
            "\n",
            "**Answer:** A) OCR Skill  \n",
            "\n",
            "---\n",
            "\n",
            "Let me know if you'd like me to explain any of the answers or provide more questions!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assessing ChatBot Memory\n",
        "user_id = \"user_1\"\n",
        "namespace_for_memory = (user_id, \"memories\")\n",
        "memories = in_memory_store.search(namespace_for_memory)\n",
        "\n",
        "memories[-1].dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q0pn6gfhmJh",
        "outputId": "66ded211-19e0-4503-fb57-abdcf78ba41d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'namespace': ['user_1', 'memories'],\n",
              " 'key': '3_cf5fd8ed-229c-48f7-82b4-92fb472ffe71',\n",
              " 'value': {'memory': [{'content': 'Provide 5 MCQ questions on Artificial Intelligence to help me with practice.',\n",
              "    'role': 'user'},\n",
              "   {'content': None,\n",
              "    'role': 'assistant',\n",
              "    'tool_calls': [{'id': 'call_n6we',\n",
              "      'function': {'arguments': '{\"input\": \"Artificial Intelligence\", \"k\": 5}',\n",
              "       'name': 'MCQ Retrieval Tool'},\n",
              "      'type': 'function'}]},\n",
              "   {'content': 'Error: MCQ Retrieval Tool is not a valid tool, try one of [Summary Tool].',\n",
              "    'name': 'MCQ Retrieval Tool',\n",
              "    'role': 'tool',\n",
              "    'tool_call_id': 'call_n6we'},\n",
              "   {'content': '{\"./Documents/mcq/mcq.csv_Qn2 mcq_question\": \"Your organization is developing a decision support solution to monitor data for anomalies and deliver real-time insights to stakeholders. The solution requires continuous monitoring and automated alerts for deviations from expected patterns. Which Azure AI service should you select to implement the data monitoring aspect effectively?\", \"./Documents/mcq/mcq.csv_Qn2 mcq_answer\": \"Answer - [A] Azure AI Metrics Advisor\", \"./Documents/mcq/mcq.csv_Qn2 mcq_answer_reason\": \"Option A - Azure AI Metrics Advisor: Specifically designed for real-time anomaly detection and continuous data monitoring, making it the best fit for the given scenario.|EXAM FOCUS - Always remember to use Azure AI Metrics Advisor for real-time data monitoring and anomaly detection. Make sure the solution is set up to continuously monitor data streams to detect deviations early.|CAUTION ALERT - Stay alert to not mistakenly select services like Video Indexer or Text Analytics for tasks that require continuous data monitoring, as they do not provide the real-time capabilities needed.\", \"./Documents/mcq/mcq.csv_Qn2 mcq_options\": \"Option A) Azure AI Metrics Advisor |Option B) Azure AI Content Moderator |Option C) Azure AI Video Indexer |Option D) Azure AI Text Analytics |Option E) Azure AI Language Understanding (LUIS)\", \"./Documents/mcq/mcq.csv_Qn2 mcq_wrong_option_reason\": \"Option B - Azure AI Content Moderator: Designed for content moderation tasks such as detecting offensive content, not suitable for data monitoring.|Option C - Azure AI Video Indexer: Used for extracting insights from videos, not tailored for continuous data monitoring.|Option D - Azure AI Text Analytics: Primarily for text analysis tasks like sentiment analysis, not suited for data monitoring.|Option E - Azure AI Language Understanding (LUIS): Focused on building conversational AI applications, not intended for data monitoring.\", \"./Documents/mcq/mcq.csv_Qn16 mcq_question\": \"You are developing an AI solution for a document management system that requires extracting text from images of various documents. Which method is commonly used for text extraction from images, especially when dealing with complex backgrounds and layouts?\", \"./Documents/mcq/mcq.csv_Qn16 mcq_answer\": \"Answer - [A] Optical Character Recognition (OCR).\", \"./Documents/mcq/mcq.csv_Qn16 mcq_answer_reason\": \"EXAM FOCUS - Always remember that OCR is the go-to method for extracting text from images with complex backgrounds and layouts. You can rely on OCR for highly accurate text extraction in document management systems.|CAUTION ALERT - Avoid assuming that Azure Form Recognizer is the best solution for text extraction in this scenario. Stay alert to the difference between extracting structured data from forms and raw text from images.\", \"./Documents/mcq/mcq.csv_Qn16 mcq_options\": \"Option A) Optical Character Recognition (OCR) |Option B) Azure AI Form Recognizer |Option C) Rule-based parsing |Option D) Semantic analysis |Option E) Azure AI Computer Vision API.\", \"./Documents/mcq/mcq.csv_Qn16 mcq_wrong_option_reason\": \"Option B - Azure AI Form Recognizer is designed for structured form data extraction, not general OCR.|Option C - Rule-based parsing requires predefined rules and lacks flexibility for complex image backgrounds.|Option D - Semantic analysis is used for text understanding, not extraction.|Option E - Azure AI Computer Vision API provides OCR but is not as robust as dedicated OCR solutions for complex document layouts.\", \"./Documents/mcq/mcq.csv_Qn50 mcq_question\": \"You are designing an AI-driven recommendation system for an e-commerce platform that utilizes generative AI to suggest personalized product bundles to customers. Which architectural consideration should you prioritize to ensure seamless integration of generative AI into the solution while meeting scalability requirements? Select all answers that apply.\", \"./Documents/mcq/mcq.csv_Qn50 mcq_answer\": \"Answer - [A, C]\", \"./Documents/mcq/mcq.csv_Qn50 mcq_answer_reason\": \"Option A - Implementing a microservices architecture allows independent scaling of generative AI components.|Option C - Leveraging Azure Kubernetes Service (AKS) ensures efficient orchestration of containerized AI models.|EXAM FOCUS - You need to implement a microservices architecture and leverage Azure Kubernetes Service (AKS) for scalability in your generative AI solution. Always remember that AKS helps manage dynamic resource allocation for containerized models.|CAUTION ALERT - Stay clear of using serverless architectures for this task—they are better suited for event-driven processes, not AI model orchestration. Avoid thinking Azure Batch or Data Factory will address real-time scalability—they are more suitable for batch processing and data pipelines.\", \"./Documents/mcq/mcq.csv_Qn50 mcq_options\": \"Option A) Implementing a microservices architecture to modularize generative AI components and enable independent scaling of services. |Option B) Deploying a serverless architecture using Azure Functions to automatically scale resources based on demand. |Option C) Leveraging Azure Kubernetes Service (AKS) to orchestrate containerized generative AI models and manage resource allocation dynamically. |Option D) Utilizing Azure Batch to schedule and execute large-scale generative AI training jobs across distributed computing resources. |Option E) Implementing Azure Data Factory to orchestrate data pipelines and facilitate seamless data ingestion for generative AI models.\", \"./Documents/mcq/mcq.csv_Qn50 mcq_wrong_option_reason\": \"Option B - Serverless architectures work well for event-driven applications but may not provide optimal control over AI model orchestration.|Option D - Azure Batch is suited for scheduled workloads, not real-time AI inference.|Option E - Azure Data Factory is useful for data processing but does not manage AI model scalability.\", \"./Documents/mcq/mcq2.csv_Qn21 mcq_question\": \"You are building a solution that uses Azure AI Search. You need to create a skillset definition. What are minimum sections you should include in the definition?\", \"./Documents/mcq/mcq2.csv_Qn21 mcq_answer\": \"Answer - [A]\", \"./Documents/mcq/mcq2.csv_Qn21 mcq_answer_reason\": \" \", \"./Documents/mcq/mcq2.csv_Qn21 mcq_options\": \"Option A) name\", \"./Documents/mcq/mcq2.csv_Qn21 mcq_wrong_option_reason\": \" \", \"./Documents/mcq/mcq2.csv_Qn47 mcq_question\": \"Which type of AI skill extracts text from images in Azure AI Search?\", \"./Documents/mcq/mcq2.csv_Qn47 mcq_answer\": \"Answer - [A]\", \"./Documents/mcq/mcq2.csv_Qn47 mcq_answer_reason\": \" \", \"./Documents/mcq/mcq2.csv_Qn47 mcq_options\": \"Option A) OCR Skill|Option B) Entity Recognition Skill|Option C) Translation Skill|Option D) Key Phrase Extraction Skill\", \"./Documents/mcq/mcq2.csv_Qn47 mcq_wrong_option_reason\": \" \"}',\n",
              "    'name': 'MCQ Retrieval Tool',\n",
              "    'role': 'tool',\n",
              "    'tool_call_id': 'call_n6we'},\n",
              "   {'content': \"Here are five multiple-choice questions (MCQs) related to Artificial Intelligence to help you practice:\\n\\n---\\n\\n### Question 1:  \\n**Your organization is developing a decision support solution to monitor data for anomalies and deliver real-time insights to stakeholders. The solution requires continuous monitoring and automated alerts for deviations from expected patterns. Which Azure AI service should you select to implement the data monitoring aspect effectively?**\\n\\nA) Azure AI Metrics Advisor  \\nB) Azure AI Content Moderator  \\nC) Azure AI Video Indexer  \\nD) Azure AI Text Analytics  \\nE) Azure AI Language Understanding (LUIS)  \\n\\n**Answer:** A) Azure AI Metrics Advisor  \\n\\n---\\n\\n### Question 2:  \\n**You are developing an AI solution for a document management system that requires extracting text from images of various documents. Which method is commonly used for text extraction from images, especially when dealing with complex backgrounds and layouts?**\\n\\nA) Optical Character Recognition (OCR)  \\nB) Azure AI Form Recognizer  \\nC) Rule-based parsing  \\nD) Semantic analysis  \\nE) Azure AI Computer Vision API  \\n\\n**Answer:** A) Optical Character Recognition (OCR)  \\n\\n---\\n\\n### Question 3:  \\n**You are designing an AI-driven recommendation system for an e-commerce platform that utilizes generative AI to suggest personalized product bundles to customers. Which architectural consideration should you prioritize to ensure seamless integration of generative AI into the solution while meeting scalability requirements? Select all that apply.**\\n\\nA) Implementing a microservices architecture to modularize generative AI components and enable independent scaling of services.  \\nB) Deploying a serverless architecture using Azure Functions to automatically scale resources based on demand.  \\nC) Leveraging Azure Kubernetes Service (AKS) to orchestrate containerized generative AI models and manage resource allocation dynamically.  \\nD) Utilizing Azure Batch to schedule and execute large-scale generative AI training jobs across distributed computing resources.  \\nE) Implementing Azure Data Factory to orchestrate data pipelines and facilitate seamless data ingestion for generative AI models.  \\n\\n**Answer:** A and C  \\n\\n---\\n\\n### Question 4:  \\n**You are building a solution that uses Azure AI Search. You need to create a skillset definition. What is the minimum section you should include in the definition?**\\n\\nA) Name  \\nB) Description  \\nC) Context  \\nD) Skills  \\nE) None of the above  \\n\\n**Answer:** A) Name  \\n\\n---\\n\\n### Question 5:  \\n**Which type of AI skill extracts text from images in Azure AI Search?**\\n\\nA) OCR Skill  \\nB) Entity Recognition Skill  \\nC) Translation Skill  \\nD) Key Phrase Extraction Skill  \\n\\n**Answer:** A) OCR Skill  \\n\\n---\\n\\nLet me know if you'd like me to explain any of the answers or provide more questions!\",\n",
              "    'role': 'assistant'}]},\n",
              " 'created_at': '2025-02-17T10:52:07.370720+00:00',\n",
              " 'updated_at': '2025-02-17T10:52:07.370723+00:00',\n",
              " 'score': None}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22kg8hnphqgy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "KmeoL-_lcs8Y",
        "s_2h8tWUc9yA",
        "k7soxxBDs_qr"
      ],
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyO/xD6ZwqoSye40iDA3+DRZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c76ee851ef148b6bca750395a41f6f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ee475f359ae4d8dab44dd307be595b6",
              "IPY_MODEL_ac058d254794461d9bfed53238fe92e6",
              "IPY_MODEL_b6cdf019a5484fd8886bd7eb9756bb73"
            ],
            "layout": "IPY_MODEL_59cbd69afebd42a689d03a568170aa32"
          }
        },
        "3ee475f359ae4d8dab44dd307be595b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_143010e7e067406e97862a42969bc73c",
            "placeholder": "​",
            "style": "IPY_MODEL_913a943660ce4418a8fd541e26c747df",
            "value": "modules.json: 100%"
          }
        },
        "ac058d254794461d9bfed53238fe92e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3bb5ebbc70e480392fc03644f539363",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ade9aaf927664bfcad63bdb976f155cc",
            "value": 349
          }
        },
        "b6cdf019a5484fd8886bd7eb9756bb73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_033aeffc3db1439fa398f7f6f9baf371",
            "placeholder": "​",
            "style": "IPY_MODEL_42aefc6cdca14ed19dfdb41836662e45",
            "value": " 349/349 [00:00&lt;00:00, 28.2kB/s]"
          }
        },
        "59cbd69afebd42a689d03a568170aa32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "143010e7e067406e97862a42969bc73c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "913a943660ce4418a8fd541e26c747df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3bb5ebbc70e480392fc03644f539363": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ade9aaf927664bfcad63bdb976f155cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "033aeffc3db1439fa398f7f6f9baf371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42aefc6cdca14ed19dfdb41836662e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c77ff518916440ab80ce40c358a7538f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a916106d653c43d49e40ccc1e33f9e45",
              "IPY_MODEL_26b3d32cd85740c6a1456f04071be330",
              "IPY_MODEL_e390228c54c2426b9c42f6a8e4b86f64"
            ],
            "layout": "IPY_MODEL_a0de562b264e41558ccfc65ffbb7eb57"
          }
        },
        "a916106d653c43d49e40ccc1e33f9e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a6d0a0af217429fa43305bc05d22586",
            "placeholder": "​",
            "style": "IPY_MODEL_7ad21e12241b4b08893124bbad6b7738",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "26b3d32cd85740c6a1456f04071be330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59bf10101ffa428c8f74978ceac12719",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86932b952a1b43d19df34f0e9d05692a",
            "value": 116
          }
        },
        "e390228c54c2426b9c42f6a8e4b86f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2746b45f651481781250e9d80c54c92",
            "placeholder": "​",
            "style": "IPY_MODEL_6670c2f754214d0c9a5a894e06bcd0eb",
            "value": " 116/116 [00:00&lt;00:00, 9.40kB/s]"
          }
        },
        "a0de562b264e41558ccfc65ffbb7eb57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a6d0a0af217429fa43305bc05d22586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad21e12241b4b08893124bbad6b7738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59bf10101ffa428c8f74978ceac12719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86932b952a1b43d19df34f0e9d05692a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2746b45f651481781250e9d80c54c92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6670c2f754214d0c9a5a894e06bcd0eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02d3e825dc664818bde225837ba4e5e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9025cd9df18b4f37841747b03f448994",
              "IPY_MODEL_9ae93a1f47194ce1b702329d9f57e8c1",
              "IPY_MODEL_5cd74a537e314e58963164c99acc2783"
            ],
            "layout": "IPY_MODEL_72373f0cc3574660975808c4430ad5ca"
          }
        },
        "9025cd9df18b4f37841747b03f448994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d368994b53bd4b96ac44a6f39611e604",
            "placeholder": "​",
            "style": "IPY_MODEL_588c45ad36c44aab9a0476d56cc8b557",
            "value": "README.md: 100%"
          }
        },
        "9ae93a1f47194ce1b702329d9f57e8c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd6157f159bc452397416dc581389590",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd60731c99654ee19e5dc36b95213b0d",
            "value": 10659
          }
        },
        "5cd74a537e314e58963164c99acc2783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dcbdc0f620e47ac9167a2d76af14099",
            "placeholder": "​",
            "style": "IPY_MODEL_2b2cd31397ee4b96b1501ea20799f022",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 886kB/s]"
          }
        },
        "72373f0cc3574660975808c4430ad5ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d368994b53bd4b96ac44a6f39611e604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "588c45ad36c44aab9a0476d56cc8b557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd6157f159bc452397416dc581389590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd60731c99654ee19e5dc36b95213b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dcbdc0f620e47ac9167a2d76af14099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b2cd31397ee4b96b1501ea20799f022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17a28df8152845ea9a22a94321aa0616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d34cda9b45f148778d76a727e11d87f0",
              "IPY_MODEL_d894333be47a420dbcc2c9f8953788df",
              "IPY_MODEL_32d37357f80b4ea09d30083b343b254a"
            ],
            "layout": "IPY_MODEL_f7ebd610cf9a41e691d7822c11e08cfa"
          }
        },
        "d34cda9b45f148778d76a727e11d87f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56602f4ac090457a951a989b37201110",
            "placeholder": "​",
            "style": "IPY_MODEL_b2739542ad9a4151982cf3cebf6b3097",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "d894333be47a420dbcc2c9f8953788df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4bd6a3a044a495ab1ae5ebf6ba6a705",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da90c99b63ba4904a09ebe584ce6144c",
            "value": 53
          }
        },
        "32d37357f80b4ea09d30083b343b254a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_626e26e81e084dcbab9e6f6dd17ea5cc",
            "placeholder": "​",
            "style": "IPY_MODEL_a3cd7badc48247f4a4a6aa08161c2085",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.76kB/s]"
          }
        },
        "f7ebd610cf9a41e691d7822c11e08cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56602f4ac090457a951a989b37201110": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2739542ad9a4151982cf3cebf6b3097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4bd6a3a044a495ab1ae5ebf6ba6a705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da90c99b63ba4904a09ebe584ce6144c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "626e26e81e084dcbab9e6f6dd17ea5cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3cd7badc48247f4a4a6aa08161c2085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f068dba409a48688f7d0627cd0fc0a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c04642f273e4baf9e52006fcd724996",
              "IPY_MODEL_fd16e84738974da4a0f19e63b14a02b8",
              "IPY_MODEL_321e982959fd4093922b64b57b22785b"
            ],
            "layout": "IPY_MODEL_a3b0a642b037421f8ebbaf638c2c073b"
          }
        },
        "0c04642f273e4baf9e52006fcd724996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48f8c54add7b4a3699380d6d856b55eb",
            "placeholder": "​",
            "style": "IPY_MODEL_3eddd41b3a9f4363be20fdeb57682a93",
            "value": "config.json: 100%"
          }
        },
        "fd16e84738974da4a0f19e63b14a02b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afb969d5c69c4fa58dbb74e7fb9cedc8",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6294dfabc5d3425892ad1e81c4589d6e",
            "value": 612
          }
        },
        "321e982959fd4093922b64b57b22785b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffaeb72fe7154aa78c08d6753992a7ec",
            "placeholder": "​",
            "style": "IPY_MODEL_1afe438755ab4fdc843447d7909b22d7",
            "value": " 612/612 [00:00&lt;00:00, 45.7kB/s]"
          }
        },
        "a3b0a642b037421f8ebbaf638c2c073b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48f8c54add7b4a3699380d6d856b55eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eddd41b3a9f4363be20fdeb57682a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afb969d5c69c4fa58dbb74e7fb9cedc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6294dfabc5d3425892ad1e81c4589d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffaeb72fe7154aa78c08d6753992a7ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1afe438755ab4fdc843447d7909b22d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7dec22e4d074d8c8ae304f0e2abf9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_335fd6a06650474fb5e4257dcbb86804",
              "IPY_MODEL_70df440995c54b14b6381afd59fdb383",
              "IPY_MODEL_1b7cb45af8a64badbe2fd37dbfe9fa0c"
            ],
            "layout": "IPY_MODEL_56d8452aa06c417bba4b9ff44dd4bebb"
          }
        },
        "335fd6a06650474fb5e4257dcbb86804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ceb9aaba3a2455abf5b399f2e853280",
            "placeholder": "​",
            "style": "IPY_MODEL_a79ac03b0321425990267c1bd9e9aa9f",
            "value": "model.safetensors: 100%"
          }
        },
        "70df440995c54b14b6381afd59fdb383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec6f287292354af4a9143da9d291e83e",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_458be0c028cc4a7db1001a0cd595ebfe",
            "value": 90868376
          }
        },
        "1b7cb45af8a64badbe2fd37dbfe9fa0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1adfcfac656c488da93d934ebe18efa5",
            "placeholder": "​",
            "style": "IPY_MODEL_c24ca9cb47544e848a9e106e210dc3cc",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 125MB/s]"
          }
        },
        "56d8452aa06c417bba4b9ff44dd4bebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ceb9aaba3a2455abf5b399f2e853280": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a79ac03b0321425990267c1bd9e9aa9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec6f287292354af4a9143da9d291e83e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "458be0c028cc4a7db1001a0cd595ebfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1adfcfac656c488da93d934ebe18efa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c24ca9cb47544e848a9e106e210dc3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52aa278c7b62496a8c9d4a37b973e7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5f6629d2ecf4801b9d41013b8e65742",
              "IPY_MODEL_6d1ca68569c546ff9723fff625d43301",
              "IPY_MODEL_94499c81ce3246418a3301b7fba1d37e"
            ],
            "layout": "IPY_MODEL_1766758a6f8542599b61d4edd7451b94"
          }
        },
        "a5f6629d2ecf4801b9d41013b8e65742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2c010c8fe264883ad5177acc194a053",
            "placeholder": "​",
            "style": "IPY_MODEL_d075d104068e40309bcb425c85fe04fd",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6d1ca68569c546ff9723fff625d43301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63e41ef5833041b89c87689a034b779f",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_906193615eb34188b338178b3444c485",
            "value": 350
          }
        },
        "94499c81ce3246418a3301b7fba1d37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2c47be6e9fb4dbc8b3311adaa659518",
            "placeholder": "​",
            "style": "IPY_MODEL_a622b71401274f2d83782df8056c2a39",
            "value": " 350/350 [00:00&lt;00:00, 22.8kB/s]"
          }
        },
        "1766758a6f8542599b61d4edd7451b94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2c010c8fe264883ad5177acc194a053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d075d104068e40309bcb425c85fe04fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63e41ef5833041b89c87689a034b779f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "906193615eb34188b338178b3444c485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2c47be6e9fb4dbc8b3311adaa659518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a622b71401274f2d83782df8056c2a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b5d251bc326469fb032bd077b2f4400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1477782451a9424091d01a31c177a599",
              "IPY_MODEL_e765494393b748c6975bb76f2bff5024",
              "IPY_MODEL_cffd82067082429f9cccf636be5ac86d"
            ],
            "layout": "IPY_MODEL_50cd402fadee4225bdcbba33e7561bbb"
          }
        },
        "1477782451a9424091d01a31c177a599": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95753bf271ed418b9c0bbe74e44d2780",
            "placeholder": "​",
            "style": "IPY_MODEL_d9c18a0e10d545cea49789a4005de1dc",
            "value": "vocab.txt: 100%"
          }
        },
        "e765494393b748c6975bb76f2bff5024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeab1eb8a48d4c389fef2bb762398772",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65a8ddfa00664ae69e977e5c4cb6c415",
            "value": 231508
          }
        },
        "cffd82067082429f9cccf636be5ac86d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_182900e6443a437e8a1ceecbe9a6cba3",
            "placeholder": "​",
            "style": "IPY_MODEL_d07ed0bfbffc49e08c32976815b1ed65",
            "value": " 232k/232k [00:00&lt;00:00, 1.39MB/s]"
          }
        },
        "50cd402fadee4225bdcbba33e7561bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95753bf271ed418b9c0bbe74e44d2780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9c18a0e10d545cea49789a4005de1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeab1eb8a48d4c389fef2bb762398772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65a8ddfa00664ae69e977e5c4cb6c415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "182900e6443a437e8a1ceecbe9a6cba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d07ed0bfbffc49e08c32976815b1ed65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88e75183cfaf4a89ab37d434408ed04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f5c3d38366045ea8be9958c168537fb",
              "IPY_MODEL_fc4184f532ff45e189ef920b224c082d",
              "IPY_MODEL_3cfec7a8205747118318cc814b9eeaba"
            ],
            "layout": "IPY_MODEL_cc444aae2aaa43be84b875c91c631559"
          }
        },
        "7f5c3d38366045ea8be9958c168537fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1792d67a0b4a47f4b52cbd95de38f02d",
            "placeholder": "​",
            "style": "IPY_MODEL_6ba89b6ef0694015a70f7212cf2cea0b",
            "value": "tokenizer.json: 100%"
          }
        },
        "fc4184f532ff45e189ef920b224c082d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cded92529774b6698e4f1c6636d04ae",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_959293859e3a474a92b413002f183e85",
            "value": 466247
          }
        },
        "3cfec7a8205747118318cc814b9eeaba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4addd4534c3549758f3dccc8dc4af1e6",
            "placeholder": "​",
            "style": "IPY_MODEL_61c226fc0f7440f496f41a47f657b030",
            "value": " 466k/466k [00:00&lt;00:00, 4.82MB/s]"
          }
        },
        "cc444aae2aaa43be84b875c91c631559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1792d67a0b4a47f4b52cbd95de38f02d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ba89b6ef0694015a70f7212cf2cea0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cded92529774b6698e4f1c6636d04ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "959293859e3a474a92b413002f183e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4addd4534c3549758f3dccc8dc4af1e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61c226fc0f7440f496f41a47f657b030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a295e03cc0304c56b2cade48ed882b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c8e3c1ca130481da10feb44f551cbc6",
              "IPY_MODEL_7aa8ef3cfaae4ccfb6f7896f47f22634",
              "IPY_MODEL_33a0d8ac9f7c46df9505d055b4847d15"
            ],
            "layout": "IPY_MODEL_5259feaa6bd942cc844ca6bcfc80f1d4"
          }
        },
        "5c8e3c1ca130481da10feb44f551cbc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b44c2a2659f34d529d76ca72c80a8e72",
            "placeholder": "​",
            "style": "IPY_MODEL_c1c9684a6d7c45c6a519d7d27bd6dd7f",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "7aa8ef3cfaae4ccfb6f7896f47f22634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae3e90a14b1848bca90bf43f2b89c301",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce4ed14b96a14896a10052e961026c54",
            "value": 112
          }
        },
        "33a0d8ac9f7c46df9505d055b4847d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d1df2f3ec9d4fbfac6cfc995e273818",
            "placeholder": "​",
            "style": "IPY_MODEL_52ad327400fa404fb3c2f0fc704bcde8",
            "value": " 112/112 [00:00&lt;00:00, 9.81kB/s]"
          }
        },
        "5259feaa6bd942cc844ca6bcfc80f1d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b44c2a2659f34d529d76ca72c80a8e72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c9684a6d7c45c6a519d7d27bd6dd7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae3e90a14b1848bca90bf43f2b89c301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce4ed14b96a14896a10052e961026c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d1df2f3ec9d4fbfac6cfc995e273818": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ad327400fa404fb3c2f0fc704bcde8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b44514b80cc4a42994c19211c3b03d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8a261f47be74fec89e24cca8431b590",
              "IPY_MODEL_4c10e961a73b48c18c1e2a16741ddb1b",
              "IPY_MODEL_4bc945f2ea984dbb8620dd50dfb037dc"
            ],
            "layout": "IPY_MODEL_5793980ffe6c4c06a56d18418cba3a07"
          }
        },
        "e8a261f47be74fec89e24cca8431b590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf21a4c82ad84bca96cafbe94f9aa6d9",
            "placeholder": "​",
            "style": "IPY_MODEL_6b9856ad421648568509414d337edaf0",
            "value": "1_Pooling%2Fconfig.json: 100%"
          }
        },
        "4c10e961a73b48c18c1e2a16741ddb1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8631b1bbedfc416ea59aff2542caddf2",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3f6a0b9769e4bdf81dab8afe7c73719",
            "value": 190
          }
        },
        "4bc945f2ea984dbb8620dd50dfb037dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a87fde87f1e64800875f9f0212903da1",
            "placeholder": "​",
            "style": "IPY_MODEL_2d06999fb26f4096a168752680b5407a",
            "value": " 190/190 [00:00&lt;00:00, 13.3kB/s]"
          }
        },
        "5793980ffe6c4c06a56d18418cba3a07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf21a4c82ad84bca96cafbe94f9aa6d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b9856ad421648568509414d337edaf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8631b1bbedfc416ea59aff2542caddf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3f6a0b9769e4bdf81dab8afe7c73719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a87fde87f1e64800875f9f0212903da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d06999fb26f4096a168752680b5407a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}